Раз, два, три, четыре, пять. Всем приятного аппетита. Давайте собираться. У нас начинается, значит, та часть, в которой мы начинаем раскрывать содержание представлений. Я напомню, у нас ближайшие два дня будут, Мы идем последовательно. Вчера мы побольше говорили про данные и зашли в процессы. Сегодня мы будем говорить про искусственный интеллект как про таковую сущность, из чего она устроена, что там внутри, какие виды бывают, как развивалась и куда-то развивалась. И будут какие-то инструменты, практически работы, с которыми можно будет двигаться. Завтра мы будем говорить про агентные среды, как мы уже анонсировали с коллегами компании Яндекс. Дмитрий тоже, кстати, значит, соответственно, с нашими коллегами из Яндекс.Клауд работает вместе. И, соответственно, мы его попросили, спасибо большое, что согласился рассказать, как его первая часть. Ну и дальше мы, соответственно, в последний день про архитектуру тоже немножко поговорим. Безопасность архитектуры, вот такая логика. Значит, итак, сейчас погружаемся в тему, связанную с искусственным интеллектом. У нас здесь аудитория такая, как сказать, неравномерная, есть люди сильно продвинутые, есть те, кто только начинает разбираться, но мы постарались так подобрать контент, чтобы интересно было всем. Если нужны будут какие-то вопросы, уточнения, углубления, вы, пожалуйста, их дозадавайте, потому что мы, в общем, можем на любую глубину, так сказать, уходить. Но я буду, обещал Дмитрию, что буду где-то регулировать, делать связки с тем, что уже говорилось в предыдущих модулях и, может быть, обострять какие-то вопросы, которые мы здесь уже обсуждали и хочется, чтобы они подсветились. Ну и ваши вопросы тоже нам очень важны. Ваша задача, как всегда, попробовать инструментально посмотреть на то, что будет говориться, и себе на планшет вынести те решения, инсайты, тезисы, которые вам покажутся важными, интересными и полезными в вашей работе. Дмитрий Сошников, слово тебе. Спасибо большое. Ну, я действительно не знаю, о чем вы уже слышали и что вы знаете. Поэтому, если начало будет каким-то чуть-чуть покажется скучным, ну, вы как-то меня, наверное, останавливаете, сигнализируете, если я буду что-то скучное рассказывать, ну, например, там, каким-нибудь неодобрительным мычанием начинаете раскачиваться, типа, нам плохо, мы страдаем, и я тогда буду понимать, что я говорю что-то не то, надо убыстриться. У меня, в принципе, слайдов много, да, я могу говорить долго про искусственный интеллект. Но несколько слов обо мне. Я искусственным интеллектом начал заниматься где-то в 95-м году еще. Занимался, занимался, но в какой-то момент работал в компании Microsoft. Меня туда позвали евангелистом. Это такая профессия мечты, когда ходишь, рассказываешь всякие вещи интересные. Собственно, то, что я вам сегодня буду делать, рассказывать всякие интересные вещи. 16 лет я там работал. Какое-то время работал на внедрение искусственного интеллекта в разные крупные европейские компании. У нас была такая команда мечты, мы приезжали на неделю в какую-то компанию и помогали им сделать прототип, ну такой очень, конечно, за неделю можно сделать простенький прототип, который доказывает, что искусственный интеллект там применим. Это было где-то в 2015-2017 году, когда компьютерное зрение очень сильно развивалось, но об этом я как раз расскажу. Поэтому я так примерно понимаю, как оно из первых рук внедряется. Ну а как бы сейчас больше, когда Microsoft ушел из России, я подумал, что надо работать меньше, и занимаюсь там преподаванием, всякие лекции. Ну и вот с Яндекс.Клаву сотрудничаю, много чего делаю. Но немножко еще истории. Вот в 95-м году, когда я начинал заниматься искусственным интеллектом, искусственный интеллект был другой. Мы тогда приходили к людям и извлекали из них знания. Я приходил к врачу из Боткинской больницы и извлекал из него знания за чаем. И вот как-то я прихожу, у него стоит портрет, ну вот не такой, но похожий, который ему благодарный пациент нарисовал. Я посмотрел на это, думаю, это же вообще очень прикольно, тоже хочу свой портрет в полный рост маслом, где бы мне такой взять. Мне не пришло в голову почему-то пойти к художнику. Я отдал дочь учиться в художественную школу. У меня дочь училась 10 лет в художественной школе, но она отказалась рисовать портрет маслом мне. Сказала, это устаревшая технология, нас такому сейчас не учат. Но, к счастью, на помощь пришел искусственный интеллект. Искусственный интеллект пару лет назад появился в Table Diffusion, можно ее было на фотографиях обучить, и у меня появился портрет маслом, у меня появилось еще много красивых изображений. И вот к чему я это все рассказываю вам. Вот если бы 5 лет назад такое мне попытались продать на Арбате, я бы сказал, это талантливый художник рисовал, потому что стиль какой-то, кубизм сохранен, и черды лица сохранены, и вот как это вообще так можно сделать? Это, наверное, человек талантливый, редкий. Оказывается, вот это делает бездушная нейросеть, не нужно быть талантливым человеком, чтобы такое делать. И это чуть-чуть, наверное, заставляет нас пересматривать вообще там какие-то жизненные ценности. Вот мы всегда думали, что там креативность, какое-то вот такое вот творчество, это самое сложное, искусственный интеллект никогда это не сможет, а оказалось, что вот да, он это может, а не может какие-то совершенно такие другие вещи, там, типа простенькие детские задачки, у Маши две сестры, и один брат, и сколько сестер у брата. И вот такого рода вещи вызывают сложности, а рисовать картины вообще не проблема. Это выглядит, конечно, как магия. Артур Кларк сказал, что магия – это то, что пока большинство людей не понимают. Когда фокус вам показывают, вы же пока его не понимаете, вы думаете, о, магия. Потом, когда посмотрите, как это делается. Почему никогда не надо смотреть, как делаются фокусы, потому что магия исчезает. Ну вот мы как раз сегодня чуть-чуть поговорим про то, как это все работает, но начнем немного с более ранних вещей, про то, как вообще искусственный интеллект появлялся и в каких областях он в бизнесе применялся. Это полезно, потому что он до сих пор применяется, не только генеративный искусственный интеллект, который рисует картины и пишет тексты, и делает агенты, не только он применяется, но и классические модели тоже. Мы начнем с того, что поговорим про эти классические модели, дальше посмотрим, как устроены вот эти сложные уже генеративные модели, откуда в них это творчество берется, и поймем вообще, насколько они творческие в сравнении с человеком. Ну и немножко я затрону в Prompt Engineering какие-то тонкости, как разговаривать, и посмотрим, как можно сделать нейросети помощниками в своих делах. Ну вот давайте с самого начала начнем. Искусственный интеллект это про то, чтобы в компьютере решать задачи так же, как человек. Вот есть какие-то задачи, которые человек решает лучше компьютера. Ну вот, например, врач, он смотрит на пациента, и несмотря на то, что у него есть какой-то алгоритм поведения, во многих случаях врач действует как бы очень часто по какой-то интуиции. Вот он смотрит на больного и говорит, да, ну это понятно, это вот такая-то болезнь. А он не по полочкам это раскладывает, он не вспоминает все страницы учебника, которые его учили, а у него в голове просто как-то сразу картина возникает. Ну, тут можно спорить, может быть, кто-то там как-то думает и рассуждает, как в докторе Хаусе красиво там показано, как они рассуждают всегда. Но есть какие-то вещи, которые вообще человек не может объяснить, как происходит, как вот мы кошку от собаки по картинке отличаем. Мы же не можем описать алгоритм, смотри на усы сначала, потом на уши и сравнивай. Как-то само получается. И вот такие вещи, которые у нас на подсознательном уровне сами получаются, их же хочется, чтобы компьютер тоже научился решать. Картины рисовать, решения принимать. И чтобы это сделать, появилась наука искусственный интеллект. И начинали с того, что думали, а как вообще сделать такое? Можно было пойти попытаться смоделировать мышление человека. Ну, потому что понятно, вот еще Аристотель, там у него был труд наука логики, он говорил, что там силогизмы, человек мыслит логически, наверное, вот какие-то общие паттерны у людей есть. И вот, собственно, первый искусственный интеллект, он был примерно таким, пытались извлекать какие-то знания из людей, закладывать их в логику, моделировать рассуждения, там сложностей куча возникало, типа, а как моделировать индукцию, как моделировать всякие логически нестрогие рассуждения. А второй путь, который был, это попытаться смоделировать работу мозга. Типа давайте вот мы на самом низком уровне, мозг, там в нем какие-то нейроны, какой-то ток течет, вот мы это смоделируем и будем кормить это все данными, а вось оно начнет думать. И вот эти стоп-сноба пути, они оформились в самом начале, где-то в середине 20 века, вот там, когда люди собрались, начали думать, вот несколько школ и направлений пошло. Посередине между этим есть еще такое важное направление, как машинное обучение. То есть машинное обучение, когда мы не говорим, что мы сразу мозг будем моделировать и какой-то интеллект возникал, а мы просто возьмем данные и на основе данных будем делать какие-то умные выводы, которые изначально не очевидны. Типа того, что мы возьмем из магазина данные о продажах и внезапно выяснится, что люди, которые покупали чипсы, еще покупали пиво, особенно если это пятница вечер. Это может быть не очевидно, но из данных такие зависимости можно извлечь. А можно даже не извлекать, а просто построить модель, которая будет предсказывать, а что человек скорее купит в пятницу вечером. И вот это машинное обучение. Это вроде не совсем искусственный интеллект, но близко к нему. Ну и нейрофити это тоже машинное обучение, потому что мы кормим компьютер данными, и он чему-то учится. Ну вот какие основные задачи в рамках машинного обучения возникают? Это немножко терминология, чтобы было проще разговаривать потом. Ну вот первая половина методов это обучение с учителем, когда мы показываем какие-то готовые примеры решения задачи. Ну, например, мы хотим почту классифицировать на спам, не спам, мы показываем тысячу сообщений, не спам, тысячу сообщений, не спам. И вот компьютер как-то учится с учителем, потому что мы говорим, это спам, это не спам. Ну и тут два класса основных. Есть классификация регрессии, классификация типа спам, не спам, а регрессия, когда мы число предсказываем, например, тональность текста, насколько грубо это сообщение, или сколько будет стоить квартира в каком-то районе города. По параметрам собираем, и модель просто говорит, сколько это будет стоить. Классификация регрессии. Есть еще анализ временных рядов, это когда мы на бирже что-то хотим предсказать. У нас есть временной ряд, и мы что-то прогнозируем вперед. Вторая группа методов – это обучение без учителя. Здесь какие есть интересные методы? Есть, например, кластеризация. Это про то, чтобы взять какие-то объекты и разбить их на близкие по какому-то параметру группы. Ну вот, например, у нас есть какое-нибудь агентство новостей, сыпятся кучи входящих новостей. Мы хотим поручить редакторам разным в этих новостях разбираться. Но мы можем, понятно, сказать, что есть спорт, есть что-то еще, есть какие-то темы. А можем сказать просто, типа, давай разобьем все эти новости на пять близких по смыслу потоков и их направим пяти разным людям, они там пускай разбираются. То есть мы не знаем, какие потоки, у нас нет заготовленных сообщений с учителем, у нас просто мы разбей на 5. Кластеризация в этом смысле очень удобна, нам не нужно никаких обучающих данных, нам нужно только как-то описать эту метрику близости, как понять, что какие-то объекты близкие. В случае с новостями, кстати, это неочевидная задача, как понять, что два текста близкие по смыслу. Ну, можно по словам смотреть, сколько там одинаковых слов, а можно по-хитрому, это вот как мы попозже поговорим, как нейросети понимают текст. Значит, есть задача еще очень прикольная, обучение с подкреплением, класс задач. Обучение с подкреплением это когда есть некий симулятор, вообще обучение с подкреплением это про то, что есть некая такая длинная задача, типа вот игры в шахматы, да, вот мы играем, играем, играем, и только в конце мы узнаем, а хорошо ли мы играли. Вот в отличие от обучения с учителем, когда есть пример четкий, вот эта квартира, сколько это стоит, или это письмо, это спам. В обучении с подкреплением есть некий процесс длинный, и в конце мы получаем подкрепление. И почему это очень важно? Потому что мы можем сделать симулятор какой-то, и на этом симуляторе гонять модель, чтобы она сама училась. Вот почему в шахматы научились обыгрывать человека, и как? Ведь вначале пытались заложить в эту шахматную программу эти партии, как играют люди. Потом пытались предсказывать поиском, предсказывать на сколько-то шагов вперед. Это не работает, потому что слишком большое пространство поиска. А потом взяли и сказали, давайте мы заложим в нейросеть только правила игры, и пускай она играет сама с собой, без всяких партий людей, просто с нуля. И вот этот AlphaZero поиграла-поиграла и стала обыгрывать людей. Обучение с подкреплением очень круто, потому что она позволяет компьютеру самому исследовать вот это вот пространство вариантов. И везде, где удается внедрить хорошо обучение с подкреплением, сразу все становится в перспективе лучше человека. Вот сейчас вот как бы есть надежда, что в нейросети, в рассуждающих нейросетях как раз-таки где-то получится применить обучение с подкреплением, они тогда в чем-то станут лучше человека. Ну, программы писать будут, там уволят всех программистов, например. Ну и как бы в машинном обучении, в классическом, есть какие-то кейсы, я вот привел несколько ссылок на разные кейсы с сайта Яндекс.Клауд, что общего у всех этих кейсов, что прежде чем делать машинное обучение, нужно собрать данные, поэтому как бы во всех кейсах обсуждается, а как мы собираем большие потоки данных отовсюду. Вот, там хранилище данных, все это мы наполняем, наполняем, наполняем. Когда данные есть, мы можем, во-первых, применять машинное обучение, во-вторых, в общем-то, и глазами посмотреть и принимать какие-то осмысленные решения. Вот, это, значит, вот машинное обучение. Вот если смотреть по времени, как развивались разные новые методы, как они внедрялись, то вот машинное обучение, оно где-то до 2012 года, ну, понятно, оно сейчас не менее актуально. Всем нужны модели машинного обучения. Любой палатке, продающей мороженое, нужно предсказывать, сколько мороженого они продадут в определенный день. Потому что если не предсказать, то как бы много мороженого закупишь, оно пропадет, мало закупишь, будет упущенная выгода. Но вот где-то в 2012 году произошел прорыв в области компьютерного зрения. Прорыв как произошел? В 2010 году ученые напряглись и собрали такой датасет, который называется ImageNet. 2 миллиона или 20 миллионов, я уже забыл, честно. Изображения из интернет разбитых на тысячу классов, скорее 20 миллионов. Напряглись и разложили 20 миллионов фотографий по тысяче разных классов. Тысячи классов это очень много, там 10 разных пород кошек, 15 разных пород собак, людей нету, потому что с людьми работать опасно, там персональные данные и все такое. И дальше начали каждый год проводить соревнования на точность распознавания. И в 2010 году, ну, точность прям вот, как точность, чтобы точно угадать класс, это в принципе, ну, как бы сложно, ошибка большая. Поэтому там мерили топ-5 accuracy, то есть то, что в 5 классов наиболее вероятных предсказанных моделью попадает настоящая. Вот тогда это считается правильно распознанной картинкой. Вот ошибка в 2010 году была 30%. Ну, это как бы много, 30% ошибки. Ну и как бы это были классические модели машинного зрения, еще не нейросетевые. А в 2012 году стали использовать нейросети. С 30% упала ошибка до 15% где-то. А потом еще за 3 года стало лучше человек. То есть нейросети очень быстро внедрились в компьютерное зрение. И вот в 2015 году и вот дальше пошло много-много проектов с компьютерным зрением связанным. Хотите, я вам интересную байку расскажу про компьютерное зрение. Вот один проект, который мы делали во Франции с компанией, которая роет метро. Типичный пример проекта с компьютерным зрением. Оказывается, метро роет специальная дорогая машина, которая под землей едет и вот как-то там роет и укладывает бетонные блоки по диаметру. И эта машина, она настолько дорогая, что там секунда ее простая, стоит много денег. Она роет метро, а точка входа под землю, она где-то в 20 минутах езды, потому что она уже прорыла какое-то расстояние, эта машина. И вот как все устроено, что в этой точке погрузки загружают бетонные блоки, которые нужно уложить, грузовик едет к этой машине, загружает на машину, машина укладывает. И вот если перепутать порядок этих блоков, они все должны укладываться в определенном порядке. Они не одинаковые, они разные, они точно рассчитаны под форму туннеля. И вот если ошибиться и блок положить неправильно, внутри уже нет места, чтобы их поменять местами. Соответственно, машина останавливается, грузовик 20 минут едет назад, их перекладывают, и 20 минут он едет снова как бы рыть дальше. И вот этот 20 минут простой, это бешеные деньги, сотни тысяч долларов. Ну и вот очень простое решение. ставится камера, которая просто контролирует за погрузчиком порядок блоков на грузовике, который едет. Но задача звучит просто, технически она не очень простая, потому что блоки очень похожие. И их между собой различить тоже не так все просто. Но мы такую задачу пытались решать где-то как раз это был 2017 год. Но в чем прелесть этой задачи, что нам очень дешево по сравнению с этими миллионами долларов, которые простаивает машина, такую систему сделать. Мы просто вешаем камеру и компьютер, и она начинает гудеть, когда погрузили неправильно, без участия человека. Ну и вот такого рода проектов их можно много придумать, где из картинки можно извлекать полезные какие-то данные, их проверять. Дальше в 20-е годы пошла мода на боты, потому что научились хорошо работать с текстом. Текст оказывается чуть сложнее, чем картинки, с ним работать надо чуть по-другому, но у текста есть громадное преимущество. Текста очень много в интернете, на нем можно много чего учить. Картинок в некотором смысле меньше. Поэтому научились хорошо работать с текстом. А последние годы уже появился генеративный искусственный интеллект. генеративный, ну, значит, что он может что-то такое вот новое создавать, не только решать задачи вот типа классификации и регрессии. Ну, вот такая табличечка у меня в голове в какой-то момент возникла. Мы можем попытаться вот эти методы разложить на разные вот эти вот домены, классическое машинное обучение, компьютерное зрение, обработка естественного языка. Ну, понятно, что помимо этого есть еще там работа с аудио, но как-то вот работа с аудио не так много интересных задач. Аудио в текст преобразовать назад и так далее. Дальше работаем как с текстом. Вот, например, регрессия в классическом ML – это некая предиктивная аналитика. В компьютерном зрении регрессия, то есть предсказать число, это, например, возраст по фотографии у человека предсказать. В тексте регрессия – это тональность текста. Классификация, ну, понятно, распознавание изображений, классификация тем. Для картинок есть еще, например, какая задача? Есть сегментация. Есть картинка, нам нужно четко понять по площади, какие пиксели относятся к тому или другому объекту. Типичный пример – это мечта любого стартапера – сфотографировать еду и сказать точно сроков в ней калорий. Для этого нам нужно четко определить границы каждого блюда. Правда, все равно непонятно как, можно же пюре положить так вертикально, чтобы оно при фотографировании давало мало калорий. Но в принципе, это задача, когда нам нужно точно пиксели на картинке выделить. Эта задача называется сегментация. И по сути дела это задача классификации пикселей. То есть мы классифицируем не всю картинку, а каждый пиксель мы говорим какого он класса. Один объект, второй объект, третий объект. Для текста есть аналогичная задача выделения смысловых сущностей. NER это Named Entity Recognition. Когда мы, например, говорим, выдели из текста все имена собственные. Это значит, мы каждому слову ставим соответствие, это имя или не имя. То есть классифицируем отдельные токены. Для кластеризации, например, кластеризация в изображениях, как может применяться? Например, у нас есть какой-нибудь фотоальбом домашний, мы говорим, выдели все похожие картинки, чтобы удалить, например, лишние. Или выделение еще опорных цветов. Вот такая задача, если есть у нас картинка, и мы хотим подобрать к ней красивый цвет рамочки. И вот нам кажется, что давайте возьмем какой-нибудь средний цвет и сделаем, чтобы рамочка контрастно смотрелась. А вот как понять, какой средний цвет у картинки? Если взять просто средний цвет, то обычно получается серая какая-то грязь. Поэтому разбивают на несколько кластеров цветовых и из них уже какие-то выбирают. Но это как бы вот так вот просто удобно, наверное, глядя на такую табличку, думать, какие вообще задачи могут решаться искусственным интеллектом, таким классическим дип-лёрнингом. Дип-лёрнинг, кстати, я не сказал, но, наверное, слышали такое слово, это означает более современные нейросети, чем до 2012 года. Все, что после 2012 года, это дип-лёрнинг, потому что в них много слоев. Как бы нейросети, она устроена по слоям, и до 2012 года не умели учить нейросети, в которых больше, чем 2-3 слоя. А в 2012 году у этой сети, которая распознавала изображение, было 19 слоев, это был прорыв. Еще один пример такой типовой задачи, как в классическом искусственном интеллекте, во что все упирается. Это задача, которую коллеги из Микрософта тоже делали. У них была задача, есть такая скала, на которой гнездятся какие-то чайки. Им нужно посчитать, как меняется популяция этих чаек со временем. То есть они улетают там куда-то, не улетают, вымирают, не вымирают. То есть по сути дела нужно просто посчитать чаек. И задача посчитать чаек сама по себе очень хорошо изучена. Это называется задача Object Detection. Типа нужно обнаружить все объекты, обвести их в квадратик. И чтобы обучить модель вот так сделать, нужно дать ей примеры, где каждая птица обведена в квадратик. И таких примеров, ну там, 5000. Это очень, конечно, мучительный процесс. Поэтому возникает вопрос, а как бы попроще эти данные разметить. То есть если мы данные разметим, если мы посадим, условно, индусов, которые разметят 5000 картинок, проблем нет, просто берется готовая модель, обучается на GPU несколько часов и все. А тут сделали такой хитрый ход, взяли видео вместо картинок, и на видео есть алгоритм, который позволяет примерно отслеживать, как объекты двигаются. Но не очень точно, иногда там это слетает, отслеживание, но это сильно упрощает разметку. Мы просто переходим к следующему кадру и поправляем все те птицы, которые случайно недоразметились. И вот с помощью такой помощи в разметке удалось быстро разметить датасет, обучить модели, дальше понять, что с этими чайками. Я, к сожалению, не знаю, что с чайками, они вымерли или нет потом в итоге, но их, по крайней мере, стали отслеживать. Еще похожий пример, это уже из Яндекс.Облака пример, кейс на сайте подробно описан, предсказание урожая яблок. Чем он интересен? Начинается все с того, что есть какой-то яблочный теплица. Студенты сделали робота, который по этой теплице катается и сфотографирует яблоки и позволяет подсчитывать их количество. Дальше по этому количеству яблок и по степени созревания можно делать какие-то прогнозы уже с помощью классического машинного обучения. То есть вот это вот такая типичная связка, когда мы сначала с помощью каких-то классических методов извлекаем данные, потом по этим данным уже делаем какие-то более обоснованные предсказания. Ну, опять же, да, будет интересно, по ссылочке можно почитать, какие там технологии. Там в Яндекс.Облаке обучали модель, там есть соответствующий инструмент дата-сферы, который позволяет это делать. Ну, вот это все, что касается классического искусственного интеллекта. Но в последние годы появляются так называемые фундаментальные модели. Что это такое? Я на примере картинок сначала покажу. Предположим, нам нужно сделать self-driving car. Как это по-русски? Самая ездящая машина. Ей нужно распознавать дорогу и всю ситуацию, которая вокруг нее. Как это обычно делается? Обучается специальная модель сегментации, которая разделяет все объекты на кусочки. обучается на куче данных автомобилей. То есть автомобиль сначала едет, снимает, дальше люди это размечают, и на этом всем обучается. Соответственно, такая модель может делать только вот эту задачу, только сегментация дороги. Она ничего другого сегментировать не может. Но мы же можем сделать что? Мы можем взять много разных данных вообще и научить одну модель сегментировать все, что угодно. И вот это как раз сделал Facebook. у них появилась модель, называется segment anything. Сегментируй все, что угодно. Она может по текстовому запросу или по клику. То есть мы можем указать, вот этот пиксель, вокруг него выдели весь объект, который вокруг него есть. И она сама понимает по форме, что это автомобиль, и его выделяет. Или мы говорим, выдели автомобиль, дорогу, здание, деревья. И выделяется только то, что нужно. То есть модель получается универсальная под любую задачу сегментации. Это вроде бы хорошо, но, естественно, такая модель сильно более сложная, и учить ее нужно на очень большом количестве данных, но зато учить ее нужно один раз. И внутри такой модели возникает как будто бы синергия, то есть когда модель видит много похожих задач в сегментациях, пусть даже это не автомобили, все равно она учится лучше сегментировать автомобили, скажем так. Ну вот как у человека тоже, когда он понимает язык, ему не важно, для чего этот язык использовать. Писать письма, читать тексты, читать книгу художественную или техническую. Он как бы просто научился читать. Вот так и модель научилась сегментировать все. И плюс в том, что эту фундаментальную модель может обучить кто-то очень богатый, типа Фейсбука. Мы можем только ей пользоваться. Можем взять ее готовую и сказать, вот у нас есть модель, давайте мы ее просто к себе воткнем и будем сразу уметь все сегментировать. Нужно посчитать количество людей, пришедших в магазин. Втыкаем модель, говорим, сегментируй людей, получаем сегменты, и по ним считаем сколько людей. Вот, окажется, что жизнь стала лучше, но есть моменты, естественно. Такая модель медленнее, потому что она большая и сложная, и дороже в использовании. Потому что она вот, когда работает, она большая, и нужно много вычислений. Поэтому, значит, ну хорошая новость для стартапов, если чтобы сделать какой-то прототип, можно взять какую-то модель, сказать ей, сделай это, и она сделает. Не надо обучать модель, которая считает тональность текста. Мы берем чат GPT, но любую GPT модель, говорим, посмотри, насколько это грубое сообщение. Ну и GPT отлично с этим справляется. Но долго и дорого. Поэтому если мы хотим ставить какой-то такой массовый продакшен, то, наверное, нужно обучить уже свою какую-то классическую модель. Ну и да, естественно, языковые модели, типа чат-GPT, это тоже пример фундаментальных моделей, они могут делать много что. Можно сказать там GPT, посмотри на текст и скажи, какой категории. То есть можно использовать для классификации текстов, можно использовать для тональности текста, можно использовать для выделения сущностей из текста, можно использовать для машинного перевода. Вы знаете, что GPT-сети лучше переводят, чем специальные сети, обученные переводить только. Это правда, потому что они лучше понимают тонкости. Типичный пример, который я всегда даю системам перевода, чтобы посмотреть, насколько они продвинуты, это, сейчас я по-русски вспомню, у меня signature dishes по-английски. Какие это блюда? Signature, ну это как бы, блин, я забыл русский язык, авторские блюда, да, вот, спасибо, авторские блюда по-русски это. И, соответственно, модели, если ты говоришь, переведи авторские блюда, она часто пишет authors dishes, да, это как бы неправильно, вот, это по-английски signature dishes. И вот GPT-модели почти все сразу правильно переводят. А обычные модели перевода, они вот сейчас потихонечку переводятся на более умные, поэтому еще полгода назад они все писали Ossers Dishes. И, соответственно, получается, если нам нужен массовый перевод, там очень дешевый, мы берем модель машинного перевода специализированную, если нам нужен очень хороший, мы берем GPT и переводим им. Ну вот еще один пример, значит, система, как бы это система Dialogica, компания Dialogica, которая специально заточена под обработку аудио с целью извлечения оттуда каких-то полезных инсайтов. Ну и, соответственно, вот когда такую систему применяют в какой-то конкретной области, в данном случае ее попытались адаптировать для задач автодилера, То есть беседы были на какие-то автомобильные темы. Оказывается, что можно взять готовую систему, которая там умеет уже распознавать текст, умеет выделять оттуда все нужные вещи с помощью GPT-подобной модели, но если ее чуть-чуть дообучить на данных, вот именно конкретно связанных с этой автотематикой, то растет качество, ну и анализа речи, и растет качество, собственно, выделения там нужных сущностей. То есть вот это тоже важная вещь, что мы можем взять фундаментальную модель и ее чуть-чуть дообучить под наши нужды. Дообучить модель чуть-чуть намного дешевле, чем обучить модель с нуля. Обучить модель с нуля, современную фундаментальную типа чата GPT, естественно, никому почти недоступна. Большинство крупных российских компаний, которые делают свои GPT-модели, тоже они, как правило, берут какую-то открытую модель и ее доучивают. Ну, правда, не чуть-чуть, а существенно, но все равно доучивает. Совсем с нуля, ну, очень дорого. Вот, поэтому вот важность, опять же, можно начинать такие системы внедрять с прототипа, то есть мы берем просто GPT-модель и смотрим, как она работает. А дальше, чтобы улучшить качество, повысить точность, можно ее уже дообучать. Ну, и как бы бизнес пользы от этого существенная. И что еще интересно здесь, что дообучать модель самому, это значит, во-первых, иметь какие-то свои вычислительные ресурсы дорогие, во-вторых, иметь какого-то специалиста, который это может делать. Не каждый Data Scientist возьмется хорошо дообучать модель. А в облаке делать это проще, потому что, во-первых, в облаке есть вычислительные ресурсы, которые можно на время взять, дообучить модель, а дальше только использовать ее. А во-вторых, в облаке есть специальные инструменты, в том же Яндекс.Клауде есть специальная fine-tuning модель. Мы просто загружаем датасет в нужном виде и говорим «да, обучись». Ну, плюс-минус. И получаем модель дообученную, в которой качество растет. Вот, это я, значит, к чему рассказываю. Ну вот если представить себе такую картинку, как эволюционировал подход к моделям, что вот изначально модели нужно было учить самим, потом появились предобученные модели, ну вот, например, когда я про ImageNet рассказывал, картинки разбитые на тысячу классов, естественно, появилось много моделей, обученных на этом ImageNet, но дальше, чтобы, например, научить модель распознавать какие-то нам важные детали, там, я не знаю, на конвейере, гайке, там, гаечных ключей отличать, готовых таких классов не было в ImageNet. Мы могли взять вот модель и ее чуть-чуть дообучить. Это называлось transfer learning. Соответственно, вот можно взять готовую модель, почти под все найти какую-то, и сделать этот transfer learning, перенос знаний из одного домена в другой. Дальше появились фундаментальные модели, которые как бы вообще не надо дообучать, но если их чуть-чуть дообучить, будет еще лучше. Ну и вот последняя тенденция последних лет, это еще, поскольку везде очень много языковых моделей, типа GPT, как к этим GPT-моделям прикрутить что-то полезное, Что бы стало лучше? Ну вот всякие там знания, как добавить, Retrieval Augmented Generation, ну вот об этом мы уже сегодня ближе к концу поговорим, ну а завтра вы прям погрузитесь в это уже как следует. Вот, и вот тоже все это, к тому же, очень удобно погружать в облако, потому что, например, в облаке под какие-то типовые задачи, ну типовая задача там взять текст звонков и перегнать в текст, чтобы оттуда извлечь не текст звонков, а взять голос звонков и перегнать в текст. Типовая задача. Для этого в облаке есть просто готовый сервис, который хорошо это делает. Взять документы, перегнать в текст, тоже есть готовый сервис, который хорошо это делает. Ну и как бы вот модели типа GPT, они, конечно, тоже для них облако очень важно, потому что такую модель развернуть самостоятельно – это, в принципе, большая головная боль. Эти модели, они большие, они не помещаются на один большой компьютер. Ну, как правило, можно, но простые модели помещаются, сложные не помещаются. Поэтому тут, конечно, облако очень важно. Вот, это был такой первый блок вводный про искусственный интеллект и его историю, какие варианты есть, может, какие-то есть вопросы. Гена И в самом конце, сейчас мы про него поподробнее. Гена И это, по сути дела, синоним фундаментальных моделей почти всегда, Потому что фундаментальная модель делает что-то такое умное, но вот как правило, если это обработка текста, то она должна уметь генерировать на выходе что-то такое хорошее. А в какой момент пришли к вычислению на ГПУ и почему? Пришли достаточно быстро. Почему? Потому что для обучения нужно делать очень много параллельных операций. Вот я сейчас про нейросети буду рассказывать, как они устроены. Там по сути дела матричное умножение. И это же матричное умножение есть в трассировке лучей. То есть когда пиксели, они же тоже все одинаковые, нам нужно параллельно рассчитать все пиксели всего экрана. И поэтому оказалось, что вот эта вот параллелизация, ее очень легко делать на GPU. GPU уже готовые были, поэтому их как бы под это дело взяли. Есть еще там специализированные нейронные процессоры. Тот же Google делает свои TPU, Tensor Processing Unit. Но вот широко на рынке как-то оказалось, что их даже незачем делать, потому что GPU очень хорошо подходит. Вы показывали слайд, на котором нейронка рисовала ваши портреты, и сказали, что если бы это художник сделал, то было бы талантливо. Но, насколько я понимаю, нейронки все это рисуют, потому что когда-то был талантливый художник. А есть понимание, что будет с ними происходить, когда подавляющая доля контента станет уже изначально сгенерированной нейронкой? Да, будет все плохо, но не очень. Потому что, как правило, тот контент, который остается в интернете с генерированной нейронкой, он проходит какую-то валидацию людьми. То есть человек, когда что-то такое генерирует, он не всегда просто берет и первую попавшуюся генерацию оставляет в сети. Он там иногда что-то дописывает, иногда отбирает лучшую, ну, по крайней мере, столько стоит с картинок точно. И это как бы означает, что все-таки в этот контент приносится что-то от человека, да, что потом нейросеть подхватывает, и она учится на более хорошем, чем просто вот сгенерированный ей же самый контент. Но проблема такая есть, да, поэтому как бы картинки, например, стараются по возможности помечать как-то, чтобы их там можно было, например, потом отфильтровывать из датасетов. Вот, спасибо, да. Но мы еще про творческие вещи поговорим ближе к концу. Давайте я перехожу к тому, как все устроено. И начнем с простого, как бы нейросети, это аналог человеческого мозга. Как люди считали в середине прошлого века, что мозг состоит из нервных клеток, которые получают на вход некоторые импульсы электрические и передают импульсы на выход. Сейчас люди думают, что мозг посложнее устроен, там разные хитрые штуки есть, но тогда было такое понимание, придумали модель искусственного нейрона, и, собственно, куда-то делись, а, кружочки просто не видны, они такого нежного цвета, что здесь вот кружочки. Вот, если вы приглядитесь, вы увидите, что тут есть кружочки. И, соответственно, получается, что вот один нейрон, он может быть представлен таким кружочком, у него какое-то количество входов, по ним поступают сигналы, каждый нейрон просто складывает внутри себя все и передает на выход. Но складывает не просто, а через какой-то весовой коэффициент. То есть вот нервные клетки, они условно соединены между собой не жестко, как провода скрученные, а там на самом деле нейротрансмиттеры, там вещества бегают между соединением нервных клеток и передают сигнал, либо усиливают, либо ослабляют. Но если очень просто сказать, то вот так. И с математической точки зрения это означает, что мы как бы просто берем и все сигналы, которые на вход такому нейрона поступают, умножаем на какие-то весовые коэффициенты. То есть вот каждый кружочек нейрон, у него там n входов, он их умножает на n чисел, складывает, передает на выход, но пропускает еще через какую-то нелинейную передаточную функцию. Если вдруг кто-то математик есть, то вы понимаете, что пропускать все время через линейные функции, это все равно что через одну линейную функцию. Когда там добавляются нелинейные, получается, можно как ряд фурье такой сделать и аппоксимировать все что угодно. Это я сложные слова сказал, просто чтобы вы поняли, что там какая-то теория есть, люди работают, стараются. Не просто все. Вот. Но, соответственно, вот на практике мы как можем такую нейронную сеть использовать? Можем взять, например, хотим научиться отличать кошек от собак. Берем на вход, подаем фотографию. Вот основное отличие классического машинного обучения от глубокого обучения, что нейронным сетям мы на вход подаем неструктурированные данные, вот просто картинку, звук, текст. А классическому машинному обучению на вход мы подаем табличку. Ну то есть вот там все понятно, где что. А здесь мы просто подаем кошку на вход. А как мы ее подаем? Ну вот, например, мы можем договориться. Все картинки мы масштабируем к размеру 200 на 200 пикселей. Маленькую. Обычно, кстати, картинки для классификации не очень большие. 200 на 200 пикселей — это 40 тысяч пикселей. Вот 40 тысяч входов будет у такой нейронки. Это если мы в черно-белый переведем кошку. Если не переведем, будет еще умножить на три цветовых канала. Дальше 40 тысяч входов. Например, мы хотим сказать, что на первом слое у нас будет пускай 100 нейронов. 100 нейронов на 40 тысяч, это получается 4 миллиона весов будет на этом первом слое. Ну и дальше второй слой. На втором слое может быть, например, два нейрона и два выхода, кошка и собака. Мы хотим, чтобы нейросеть на выходе сказала, с какой вероятностью это кошка, с какой вероятностью это собака. Ну и вот, например, показываем ей кошку. Если веса случайно как-то подобраны, то на выходе будет какие-то случайные два числа, там 0,5, 0,5, 0,6, 0,4. Мы знаем, что это кошка, значит, мы ей говорим, давай подправим веса так, чтобы это стала кошка. Чуть-чуть подправляем веса, дальше показываем следующую картинку. И вот так много-много раз, там 10 миллионов картинок, она научивается распознавать кошек и собак. Как она примерно это делает? То, что у нейрона есть какие-то веса на входе, это, по сути дела, как бы такой фильтр, который накладывается на картинку. Ведь с каждым пикселем какой-то вес связан. И поэтому каждый нейрон, он как будто бы просто какие-то признаки в этой картинке улавливает свои. Но какие, мы не знаем. Мы же учим, мы не вмешиваемся в работу. Алгоритм обучения, он хитрый математический алгоритм, называется обратное распространение ошибки. он же градиентный спуск, значит, вот мы делаем так, чтобы ошибка в этой классификации минимизировалась. И веса сами подстраиваются. И нейросеттель сама понимает, какие признаки ей нужны, чтобы отличать кошек от собак. Но, в принципе, каждый нейрон – это некий паттерн. Дальше вот 100 нейронов мы сделали, 100 паттернов каких-то она из картинки выделяет, а потом их еще раз смешивает на выходе и решает по этим паттернам, кошка это или собака. Но самое главное, что нужно запомнить, нейросеть хорошо распознает паттерны. На самом деле для компьютерного зрения чуть сложнее все устроено, потому что человек, когда ищет кошку, когда вам показывают фотографию, говорят, это кошка или собака, вы глазами ищете признаки. Вы как бы пробегаете глазом по картинке. Поэтому хорошая нейросеть, она точно так же устроена, она берет и выделяет, например, признаки в разных местах картинки. Она, например, сначала бежит по картинке и выделяет разные штрихи, там наклонные штрихи, горизонтальные штрихи, вот как бы говорит, здесь наклонный, здесь такой-то, здесь такой-то, здесь такой-то, вот как бы выделяет такие базовые признаки. Дальше на следующем уровне она смотрит, как эти штрихи складываются в что-то большее, там, например, два штриха наклонных может означать кошачье ухо, да? Вот, а дальше еще такие же фильтры, два уха может означать кошачью мордочку. Ну и вот как бы вот так вот иерархически все это складывается. И вот такая сеть называется сверточная сеть. Это вот как раз то, что в 12-м году придумали. Ну придумали это раньше, в 12-м году смогли это применить, чтобы в реальной жизни классифицировать картинки. Вот. Примерно так. Если при этом посмотреть, как же нейросеть внутри себя видит кошку. Как мы это можем сделать? Можем ей подать, например, какой-то шум на вход и сказать, а давай ты этот шум так исправишь, чтобы на выходе получилась кошка. Значит, вот идеальная кошка, получается, выглядит вот так. Это сиамская кошка, кстати. Почему? Возможно, вас это изображение чуть-чуть шокирует. Вы думаете, какого черта, значит, вот почему так? Но смотрите. Вот видите здесь сколько кошачьих признаков. Вот глаза, вот ухо, вот еще глаза, и вот еще ухо. То есть вот здесь на самом деле в этой картинке очень много кошачьих признаков. И когда нейросеть же, помните, там нейрон просто складывает, то, что приходит на вход. Когда ей приходит много кошачьих признаков на вход, она говорит, ну да, конечно, кошка. А то, что вот эта кошка там одна должна быть, ну, а в этом же никто не говорил. И то, что кошка должна как бы не может накладываться на другую кошку, ну, это как бы мы понимаем, а нейросеть-то нет. И неважно. Как бы, чем больше кошек, тем лучше. Это я к чему? Я очень эту картинку люблю показывать, чтобы подчеркнуть, что нейросейки думают совсем не так, как люди. У них в голове какое-то свое увидение мира. И вот когда вы с GPT разговариваете, тоже у нее свое видение мира. Она как бы вот слова выплевывает, они все разумные, но почему она их выплевывает, никто не знает. Ну как, примерно. Вот еще есть одно животное, вы угадаете, кто это? Слон, зебра. Угодно, может, да. Вот, павлин. Но вот зебра, кто сказал зебра прав, это зебра. Значит, вы уже научились кто-то думать, как нейросеть, видеть, как нейросеть. Зоопарк, да. Вот. Ну, это, кстати, имеет интересные последствия, вот эта вот идея, что мы можем попросить нейросеть подогнать чуть-чуть пикселей так, чтобы это стало какое-то другое изображение. Можем взять теперь собаку и сказать, подогони чуть-чуть пикселей, чтобы это стала кошка. И вот это вот справа кошка, видите, у нее там такие ушки как будто чуть-чуть, они почти прозрачные, их не видно, но распознается уже как кошка, но распознается конкретно одной нейросетью. Чтобы подогнать вот эти вещи, нужно прям иметь готовую нейросеть и под нее это подгонять. Другая нейросеть скажет, нет, это все-таки собака. Это называется adversarial attack, атака на нейросеть. И на самом деле это некая небольшая проблема была раньше, потому что можно было, например, взять дорожный знак, его чуть-чуть подклеить. Вот этот знак справа, это уже знак ограничения скорости становился, да, типа 100 км в час. И если машина видит такой знак и не понимает, что это стоп, она может не остановиться, и это вызовет аварию. Поэтому нужно с этим как-то уметь бороться, ну и научились с этим бороться, там есть разные методы. Но в целом вот это интересно очень, что за счет того, что человек и нейросети видят все по-разному, можно их так чуть-чуть взламывать. Ну и вот чуть-чуть уже подходя к генеративному ИИ, мы видим, что нельзя просто сгенерировать кошку, например, сказав нейросети, нарисуй такую картинку, чтобы это была кошка. Поэтому нужны какие-то специальные методы. И здесь вот, собственно, сети, которые появились, вот, может быть, слышали, с Table Diffusion там есть сеть, я ее уже упомянул, которую я дообучивал рисовать свой портрет. Это так называемые диффузионные модели. Идея их в чем? Что мы берем хорошую картинку и ее чуть-чуть зашумляем. И учим не рисить, а удалять шум. Удалять шум намного проще, чем рисовать с нуля, как бы, да? Но это тоже требует понимания смысла картинки. То есть вот, например, когда мы видим там какую-нибудь, например, зашумленную картинку, то есть волосы человека, да, мы должны понять, что нужно шум убрать так, чтобы волосы остались, ну, паттерн волос остался, а паттерн шума ушел. Поэтому нейросетики, когда их учат удалять шум, они реально понимать начинают, как выглядят объекты мира, да, они как бы отличают их от шума. Но эта задача как бы не очень сложная. А дальше мы еще зашумляем картинку и снова учим нейросетику удалять шум. И вот так вот мы учим, учим, учим, пока нейросетт не учится удалять шум из чистого шума. То есть в итоге мы можем дать ей просто шум и сказать удали шум. И тогда нейросетт в этом шуме как бы видит что-то и говорит, ага, ну вот я удалю, вот получилось чуть-чуть кошка, а теперь еще удали, еще удали, еще удали, и вот так вот 50 раз удали, и получается картинка хорошая. Вот так устроены диффузионные модели. Возникает, конечно, вопрос, а как ей сказать, что мы хотим кошку, потому что она же в этом шуме все что угодно может увидеть. Вот как сказать, что мы хотим кошку, я чуть попозже еще расскажу. Но можно, да, вот Яндекс.Арт, видите, очень красиво рисует кошек. Яндекс.Арт вообще очень красиво рисует, но не очень, зато ей можно детально сказать, как рисовать. Но по умолчанию всегда получается хорошо. Вот, но, собственно, теперь про текст. Что вам смешно, расскажите нам тоже. Интересно. А, всегда получается кошка, да. Ну, кошка это всегда хорошо, согласитесь. Да. Да, это, кстати, интересно. Что нужно отсюда убрать, чтобы получилась собака. Или наоборот, мне кажется, нужно добавить шлем, который сплошной, тогда точно собака. Вот, значит, ну давайте теперь к тексту перейдем. Вот, текстовые нейросети, да, что они делают? Вот GPT, как GPT устроен? На самом деле GPT делает одну вещь, это он научен продолжать текст. То есть ему дают некое начало текста и учат его продолжать, дописывать текст. Ну вот пример, это еще старенькая GPT-3 русская. Мне просто нравится пример, я его как-то давно сгенерировал и теперь показываю всегда. Британские исследователи университета имени Джона Леннона в Ливерпуле на прошлой неделе закончили исследование, посвященное влиянию вируса на музыкальные предпочтения английской молодежи. Они обнаружили, что изначально там было коронавируса, но коронавируса нейросети не знали, потому что они были обучены до коронавируса в те времена. Поэтому просто вирусы. Ну и вот тут дальше продолжает нейросети. Они обнаружили, что у людей, зараженных вирусом иммунодефицита человека, музыкальные вкусы изменились. И дальше, видите, там какие-то цифры, цитаты профессора Гаварда Майкла О. Саливана с хорошим британским именем. И вот, как бы, текст очень правдоподобный. Правда ли это? Ну, никто не знает, правда ли это. Вот нейросеть написала такое, наверное, вроде как нет, а вдруг и правда. Ей же лучше знать, да? Она же умная. Но, значит, что делает нейросеть? Нейрисей пишет очень правдоподобный текст на те, что она видела в процессе обучения. И поэтому смысл этого начального абзаца красной нитью проходит через весь текст. То, что британские ученые, то, что Соливан должен быть, а не Иванов какой-нибудь ученый. Вот это все в тексте учтено. И возникает вопрос, как это сделать. Понятно, что нужно, наверное, как-то понимать смысл для этого. Как понимать смысл? Ну, во-первых, сразу поймем, что для того, чтобы продолжить текст, нам не нужно сразу весь текст продолжать. Нам нужно научиться предсказывать вероятность следующего слова. Одного. Потому что если мы одно научимся дописывать слово, дальше мы можем еще одно, еще одно, еще одно. И вот так вот весь текст уже написать. А почему именно вероятность предсказывать? Потому что мы точно никогда не знаем, какое слово следующее. Потому что если есть фраза «Вася пошел на улицу, чтобы играть в футбол». Не в футбол, просто «чтобы играть в». Какое самое вероятное следующее слово? Вот я его даже уже назвал. Футбол, наверное, если есть такая фраза. А если мы говорим, гроссмейстер Вася пошел на улицу, чтобы играть в... Он, в принципе, тоже мог пойти играть в футбол, но мог еще пойти играть в шахматы. И вот слова неоднозначные. Поэтому нам нужно, чтобы нейросеть, она говорила, какие варианты там самые вероятные. И поэтому на самом деле нейросеть предсказывает именно распределение вероятности следующего слова. Прямо по всему словарю. То есть это такой большой вектор вероятности, почти всегда равный нулю. Но при этом им нужно понимать смысл, а это значит, прежде чем предсказывать вероятность, они должны, например, понять, что слово «они» означает британские ученые. Например, это только одна из вещей, которые нужно понять нейросети. То есть как-то вот весь смысл этого всего начального текста извлечь. Значит, как это делается? Ну вот раньше как бы делали нейросети, которые читают текст слева направо. Здесь, если вы не поняли, очень красивые нежного цвета квадратики. Вот, эти квадратики, это одна и та же нейросеть, которой просто на вход подается очередное слово и некоторый вектор смысла. То есть мы, как бы вообще в нейросети все же это числа, да, вы поняли, картинка подается на вход как числа, и текст подается на вход как числа. Изначально, например, подавались просто номер слова, там, да, вот брали большой словарь, как это известно, словарь Уильяма Шекспира насчитывает 50 тысяч слов, да, там, словарь Л-очки 30 слов, значит, соответственно, ну вот брали какой-то средний словарь между Шекспиром, и L, и все слова номеровали, и подавали на вход номер слова. И вот ожидали, что некий вектор смысла в итоге сформируется. Это не очень хорошо работало, тогда придумали такую вещь. А давайте все слова будем упаковывать в такие вектора, которые уже будут показывать смысл слова. А что значит смысл слова? Ну вот похожие слова, чтобы были близкими точками в этом пространстве. Вот вектор, я слово вектор когда произношу, я надеюсь, я вас не пугаю. Вот это некая точка в многомерном пространстве. Вот если пространство двумерное, это координаты x, y, трехмерное x, y, z. Многомерное пространство, у него там координат, например, 1024. Вот обычно там 1024, 512, примерно столько берут координат. То есть это некая точка, но несмотря на то, что координат там много, и представить это визуально сложно, мы можем понять, что точки близки друг к другу, потому что у них координаты похожи. Вот пространство такое, когда похожие по смыслу слова близко друг к другу, называется имбедингом, да, имбедингом слова. Имбединг это, я не знаю, как это перевести хорошо, это мы берем как бы разнообразный словарь слов и впихиваем его вот в это вот бесконечно многомерное векторное пространство. Ну вот это пример, как это примерно выглядит, вот видите там blue и red, они вместе, вот this, the вместе, это в английском языке почти одно и то же, ну и всякие еще там другие похожие слова, тоже school education вместе. Вот есть специальная процедура, учат специальную нейросеть из слов делать имбединги. Как учат? Учат, например, предсказывать просто среднее слово в некотором наборе слов. И если, например, слово там мяч, может быть, синий и красный, то похожим словам начинают соответствовать похожие вектора, потому что, ну как бы, может же мяч быть и синий и красный, они разные слова встречаются в одном и том же контексте, тогда они получаются похожими. Но это тонкости уже. Главное, что вот так устроено понимание смысла слов. И у человека оно, кстати, точно так же устроено, потому что у вас же наверняка бывает, что у вас какое-то слово крутится на языке. Вы не можете его быстро вспомнить, а вы думаете, я же знаю, знаю, как это сказать. И что вы начинаете делать? Вы начинаете синонимы какие-то придумывать. Синонимы – это слова, которые близко в этом пространстве. Вы ходите, ходите в голове, потом бабах и вспомнили точное слово. Но до этого у вас только в пространстве смыслов была координата. Вот это вот что значит. И вот как-то вот думайте, думайте, вспоминайте. Вот. Соответственно, стали подавать на вход такой вот нейросети, читающей слева направо, сразу вектора смыслов, имбединга, в надежде, что они из этих смыслов отдельных слов сформируют смысл всего текста. Но это тоже плохо работало. Почему? Потому что есть то, что я люблю называть синдромом переводчика. Вот синхронный переводчик, он как действует? Ему говорят, говорят, говорят текст на каком-то языке. А потом ему становится сложно. Потому что ему уже много наговорили, ему нужно бы уже это выдать на выход, а нельзя. И вот он тогда забывает начало, и все, катастрофа. И вот так же нейросети, только у них длина этого контекста, который они могут помнить, была сильно короче. Потому что в один вектор впихнуть все сложно. И тогда придумали магическую вещь под названием механизм внимания. Но я вот до этого еще сразу скажу тоже и забудем, что на самом деле нейросети оперируют не словами, а токенами, кусочками слов. Почему? Потому что по двум причинам. Первая причина, что слова очень с разной частотой встречаются в тексте. И слово дезоксирибонуклеиновая кислота очень редко встречается в тексте. И поэтому, когда что-то очень редко встречается, вообще алгоритмы машинного обучения очень плохо это предсказывают. Но они просто видят, что это почти никогда не встречается, и об этом забывают обычно. И поэтому разбивают слова на кусочки так, чтобы у каждого кусочка была примерно одинаковая вероятность появиться в тексте. А во-вторых, когда мы большое слово бьем на части, у нас смысл, как бы, вот слово дизокси-либо-нуклеиновая кислота, оно же состоит из отдельных строительных блоков. Там дизокси-окси значит кислород, нуклеиновое значит в ядре. И вот лучше этот смысл переиспользовать в других местах, чем это будет как бы отдельный какой-то вектор смысла. Пускай он будет переиспользован. Поэтому бьют на токены. Но для простоты лучше нам сейчас думать, что бьют на слова. И вот механизм внимания, что это такое. Собственно, придумали такую вещь. Говорят, а давайте мы не будем смотреть слева направо на текст, А пускай нейросеть смотрит на весь текст и смотрит, какие слова с какими связаны, какие слова с какими могут обменяться смыслом. Ну вот, например, там, Вася любил овощи, поэтому он заказал там что-то, нужно понять, что он значит Вася. Вот давайте, например, от слова Вася чуть-чуть смысла перейдет к слову он. Он поймет, что оно значит. Непонятную фразу сказал, но неважно. И, значит, вот в итоге механизм внимания вещь вообще сложная, Потому что, например, можно взять два предложения, там, да, животное, там, лягушка не перешла дорогу, потому что она была усталой. Или лягушка не перешла дорогу, потому что она была широкой. Кто она? Там, это разные. Она дорога, она лягушка. По смыслу, да, разрешение анафоры дело сложное. Но вот механизм внимания, когда он учится на этом тексте, он начинает понимать, что, как бы, ну, вот, исходя из структуры предложений, надо слову «она» посмотреть на дорогу, там, или на лягушку. И в итоге, это вот у меня самый сложный слайд сегодня, значит, как происходит обмен смыслами в GPT-подобных моделях. Вот на вход подается некий большой текст. Вот все, что вы пишете на вход в GPT, это некий большой текст. Дальше поэтому считаются имбеддинги. И дальше начинается обмен смыслами. Обмен смыслами начинается так. Вот на примере слова on. Слово on формирует некий вектор запрос Q, который говорит, я хочу что-то типа подлежащего понять. Вот есть какое-то главное слово, которое мне нужно взять и понять, что это я. Причем это подлежащее, это не какой-то там словарик, ключик или тег. Это некий вектор, который просто примерно показывает это понятие. Дальше у Вася есть ключ, который тоже примерно показывает, что я главное слово. Но не точно, но как-то показывает примерно. И вот когда мы видим, что эти вектора похожи, мы вектор value от слова «васи» передаем на место слова «он». Вот происходит такой как бы обмен смыслами. Это я показал только на примере одного слова, а на самом деле все слова со всеми в предложении одновременно обмениваются. Почему у нейросетей проблема читать длинные тексты? Вот вы, может быть, слышали слово «контекст», там и все гордятся, у нас контекст 1 миллион токенов, Но это не совсем правда, большой контекст плохо работает все равно. Потому что, чтобы идеально понять смысл текста, нужно, чтобы все слова во всем тексте со всеми провзаимодействовали. А все со всеми значит квадрат. Если у нас во входном тексте миллион токенов, и мы миллион возводим в квадрат, это становится очень много. Я не знаю, сколько будет миллион в квадрате. Но больше миллиарда, потому что миллиард это миллион на тысячу. И в итоге, а как вообще миллион-миллионов даже слов сопоставить? Это нереально. Поэтому какие-то хитрости приходится использовать для этого. Но в целом идеально нужно, чтобы понять текст, чтобы все слова со всеми взаимодействовали. И вот они взаимодействуют друг с другом, обмениваются смыслами. Получается некий новый набор векторов. А дальше как бы снова происходит то же самое. И вот таких слоев в самой первой GPT-сетке было 6 штук. Сейчас их больше. Они много раз обмениваются смыслами. В итоге получается некий общий вектор смысла всего текста, по которому уже предсказывается вероятность следующего слова. То есть текст, вектор смысла, по нему вероятность слова. Очень-очень много вычислений. Для того, чтобы только одно слово предсказать. А дальше? А дальше, чтобы предсказать следующее, нужно еще столько же вычислений. Вот. Да. Как-то она появилась. Но колбаса это только вероятность какая-то. А еще мок с помидорами. Да, но вполне возможно, что очень много людей, которые любят овощи, все-таки заказывали с колбасой. Это не точный пример. Это я придумал цифры из головы. Да. Интриган, да. На самом деле любой человек, который говорит, что любит овощи, колбасу тоже любит. Это зависит от модели. Очень сильно, потому что какие-то модели предпочитают взять очень большой словарь, тогда размер токена побольше. У ламы у нее словарь, там сколько-то, 2 миллиона токенов. Какие-то модели предпочитают взять поменьше словарь, тогда токены покороче. Вот раньше была такая проблема, что токены русскоязычные были в международных моделях сильно короче, чем англоязычные. Почему это происходило? Потому что, помните, я сказал, что токены делаются так, чтобы каждый следующий токен был примерно равновероятен. И вероятность токена зависит от количества текстов, которые модель видела. Если модель училась на очень большом количестве английских текстов, она сильно больше английских токенов видела и выделяла более длинные английские токены. И на русском им было говорить невыгодно. Вот. В какой-то момент что-то сделали, я даже заостряюсь точно, наверное, сказать что, но вот что-то сделали, чтобы русские токены стали тоже достаточно длинными, и модели стали хорошо говорить и на русском тоже. То есть вот сейчас, в принципе, кажется, что не очень важно, на каком языке говорить с моделью, потому что получается плюс-минус одинаково. А, точно. На польском, на втором месте русский. А может быть это шло с того момента, как вот раньше в смске 130 на английском и 70 на русском? Да, да, это очень похоже, кстати, да, спасибо за аналогию. Но не совсем вот прям точно поэтому, но по похожей причине, как бы, да. Английских она видела больше, чаще, поэтому английские кодируются более длинными токенами. Вот, да, насчет польского была просто статья недавно, которая, ну, правда, она исследовала одну конкретную проблему, там, да, работы с большим контекстом, вот, и выяснялось, что с большим контекстом работать на русском и на польском языке почему-то лучше, чем на английском. Еще была одна статья до этого, за год еще, наверное, когда было показано, что учить модель неважно на каком языке, то есть условно там сравнивали две модели, одну, которую учили на большом количестве китайского, а вторую, которую учили на очень большом количестве английского, английского все-таки в мире сильно больше, чем китайского, и небольшом количестве китайского, ну не совсем маленьком, но как бы сильно меньшим, чем для первой модели. И оказывалось, что модель, которая видела очень много английского языка, была лучше. То есть модель учится думать, неважно на каком языке, примерно как человек. Когда вы начинаете учить язык, то вы вроде как просто переводите на русский язык, а потом уже этот текст понимаете. А когда вы начинаете понимать английский напрямую, ну как бы у вас английский транслируется в какие-то имбеддинги в мозге, и русский транслируется в те же имбеддинги. Дальше уже на этих имбеддингах идет рассуждение. неважно на каком языке. Поэтому, в принципе, язык не так критичен для модели становится. Смотрите, как модели учат. На чем? Вначале их учат на всем интернете. Берут весь текст, до которого можно дотянуться, и сваливают модели в кучу. Как-то его чуть-чуть фильтруют, конечно, но профильтровать его тщательно невозможно. Невозможно весь интернет прочитать и отобрать только хорошие тексты. Их там слишком много. Поэтому учат на всем. Получается так называемая базовая модель. Но базовая модель, она может только продолжать текст. Она не факт, что будет отвечать на ваши вопросы и вообще будет вести с вами диалог. Потому что, например, вы пишете ей текст, когда были придуманы первые компьютеры. Она продолжает его так, как будто это некий текст в интернете. А там могло быть написано, когда были придуманы компьютеры, кем были придуманы компьютеры, зачем были придуманы компьютеры. Она может продолжить вопросом. Поэтому базовая модель, она не подходит для разговора. Поэтому ее доучивают на специальных инструкциях, которые пишут люди. Ну вот многие компании, там, может, слышали пару лет назад, там, Яндекс, Сбер, они нанимали специальных людей, и яйтичеры, которые писали датасеты для моделей, чтобы их учить. Набирали людей с разными бэкграундами, с литературными бэкграундами, с историческими, чтобы человек в своей области мог написать очень грамотные вопросы-ответы. И вот с любовью десятки и сотни тысяч таких вопросов скармливают нейросети, и после этого она учится отвечать на вопросы уже. То есть ее стиль становится более рафинированным. Она отвечает очень гладко. Если вы говорите, как мне лечить простуду, говорит, я языковая модель, я не буду вам отвечать на этот вопрос, типа мне нельзя. Вот это все дотюнивается как раз на этапе вот этих вот инструкций. Дальше, чтобы еще больше улучшить качество модели, делают такую хитрую штуку. Берут и просят людей выбрать из нескольких ответов модели лучший. Но на первом этапе это делают те же EI-teacher, а в принципе в какой-то момент это даже пользователям давали. Может помните, был такой у чата GPT период, когда он выдавал два варианта ответа и просил проголосовать, какой лучше. Но вот на этом дополнительно доучивают модель, чтобы она выбирала ответ, который пользователи от нее ждут. Ну и наконец, уже самые последние идеи, которые возникли, это рассуждающие модели. Я про это еще чуть-чуть попозже, когда буду про prompt engineering говорить, расскажу. Но в целом идея в том, что вот когда человеку дают сложную задачу, что он делает? Думает. Да, как проще всего думать? Список записывать. Вот я какой ответ хотел от вас услышать? Что обычно вы берете бумажку все-таки, да? Вот когда делают мозговой штурм, когда делают любое обсуждение, встают к флипчарту, начинают рисовать. Вот видите, как здесь красиво все нарисовано. Вот. Почему это делают? Потому что в голове держать сложно. Нужно выбросить что-то на бумагу, дальше смотреть на это, и отталкиваясь от этого, думать дальше. А модель же не может так внутри себя думать. У нее вообще она как бы очень ограничена в думании, она только слова сопоставляет. Поэтому ей очень нужно... Да, но когда она начинает генерировать следующее слово, она видит все предыдущее. Поэтому ей очень полезно промежуточные вот эти свои мысли относительно решения задачи тоже записывать. Да? Это аналог такой бумажки. И вот как бы изначально был такой принцип промт-инжиниринга, который назывался chain of thought. Я сразу про него чуть-чуть расскажу, раз речь зашла. Цепочка рассуждений. Вот если модели написать, пожалуйста, рассуждай по шагам, и она начинает писать, типа, а, вот, наверное, надо так решать, вот так, вот так, вот так, то решение получается правильней. Ну, я потом покажу пример просто на арифметических задачах, как модель ошибается, если ее просят сразу написать ответ, и решает правильно, если ей говорят, пиши по шагам. Вот, и, соответственно, но решение, когда ты говоришь, пиши по шагам, оказывается дороже, потому что каждая генерация токена – это вычисление, да, там, тык-тык-тык-тык-тык, Это для этого нужно мощный GPU, работает, греется и так далее. Вот, поэтому, ну вот, это поняли люди и подумали, а давайте мы будем специально учить модель всегда думать по шагам. И вот reasoning модели, это такие модели, которые учат либо на специальных датасетах, с любовью написанных людьми, которые пишут, как рассуждать, либо пытаются учить reinforcement learning. То есть, например, есть такие задачи, Для того, чтобы учить reinforcement learning, нужно, чтобы был какой-то способ проверить, правильный ответ или нет, хороший или плохой. И в задачах программирования, например, это сделать легко. Мы говорим нересты, напиши код для решения такой-то задачи по программированию. Дальше мы этот код выполняем, решение правильное нет, соответственно, мы говорим, ага, неправильное, надо лучше. И она вот таким образом учится лучше, лучше, лучше рассуждать. Вот это вот reinforcement learning, его дипсик как раз применила эффективно, и DeepSig R1, почему вокруг него такой шум поднялся, но помимо того, что он китайский, китайская модель очень хорошая внезапно появилась, еще ее научили очень хорошо рассуждать. Вот, значит, ну, соответственно, в итоге получаются все более и более продвинутые модели. Дальше, значит, что еще очень важно про такие модели знать, что вот когда мы беседуем с моделью, например, там, сейчас GPT, у нее диалог с нами, И получается, как будто он помнит все начало диалога. Но он как бы его на самом деле не помнит, просто каждый раз на вход модели подается вся переписка. Вот чтобы предсказать одно следующее слово, вся переписка, которая выше, подается на вход, и попарно сравниваются все слова. Представляете, как продают модели внутри компьютера. Что это означает для нас? Для нас это означает, что, во-первых, если вы хотите решать новую задачу, всегда лучше начать новый диалог, чтобы лишнее вот это вот ничего не мешалось. Если вы решаете очень сложную задачу, то диалог может внезапно переполнить контекст модели. Это значит, она забудет все начало. Это тоже может статься. Ну и еще есть обычно такая штука, как системный промпт. Вот в начале всего этого еще добавляют некие специальные инструкции, которые говорят модели вообще типа как себя вести. Почему это важно? Ну вот представьте себе, вы хотите спросить у модели диагноз, вы плохо себя чувствуете, вы сказали ей, вот я там плохо себя чувствую, пожалуйста, сгенерируй мне, что мне делать. Значит, если модели ограничатся вот этим диагнозом, модель же она усредненное представление всех людей о том, как надо лечиться. Как многие люди считают, надо лечиться. Там подорожник приложить, колбу. И вполне возможно, что модель скажет, ну вот вам нужно гармонизировать свои энергии, для этого приложите подорожник к колбу. И вы скажете, блин, почему модель так ответила? Но вы же ей не сказали, что ей нужно притворяться доктором. Поэтому если вначале написать, представь себе, что ты врач такой-то категории, то модель, прежде чем писать подорожник к колбу, посмотрит на вот эту инструкцию, и это с подорожником не вяжется, и она не будет подорожник предлагать. Поэтому инструкцию указать в системном промпте достаточно важно. Не обязательно в системном, большой разницы между системным промптом и несистемным нету, просто системный никогда из диалога не выпадает, он всегда в начале остается. Вот в любой системе типа чата GPT уже взошит большой системный промпт. Это гигантский текст, где написано «будь вежливым», ни в коем случае не говори что-то плохое. не допуская расовой дискриминации. Вот это вот простыня текста, в которой все это написано. И модель каждый раз это читает. Если вы какую-то свою модель, если, например, вы модель в облаке используете, вы можете задать уже полностью свой системный промпт. Пускай она допускает расовую дискриминацию. Она совсем не допустит, потому что она обучена на хороших фразах. Но тем не менее. Какие модели бывают? Есть, в принципе, большое разделение. Есть модели закрытые, то есть есть компании, которые делают модели для того, чтобы ими владеть. Вот OpenAI, Anthropic. У них есть свои модели, которые они никому не дают. Ну какие-то там Яндекса модели тоже недоступны. Они в облаке доступны, можно ими пользоваться, но нельзя ее себе утащить и установить себе на компьютер. Проприетарные модели. Есть открытые модели. Открытые модели, которые компания обучила модель и говорит, вот держите, используйте, если хотите. Например, DeepSync, Qwenn, какой-то Яндекс.ДпТ тоже есть открытый, одна из версий модели. Это значит, что открытую модель вы потенциально можете унести к себе, хотел сказать домой, но нет, домой нет, но куда-то к себе унести в дата-центр. Может быть и домой. Модели, они измеряются обычно объемом. Объем — это количество весов вот этих. Они еще параметрами называются. Веса, параметры одно и то же. Соответственно, у маленьких моделей может быть там миллиард параметров. У больших моделей их там 400 миллиардов и больше. Соответственно, ну вот если помнить, что как бы видеокарты, которые продаются в магазине, Nvidia 4090, там 32 гигабайта памяти. Значит, вот 32 гигабайта – это примерно сколько весов войдет. Ну, их там можно уменьшить, их можно… Вообще вес обычно занимает 4 байта, поэтому по-хорошему нужно поделить на 4, но можно и не делить. Ну, в общем, вот примерно понятно, как размер модели соотносится с тем, что вы можете установить у себя дома. Вот 1 миллиард параметров можно развернуть дома на видеокарточке. Но эта модель, как правило, будет очень тупой. И вы такие после общения с чатом GPT придете к ней и будете очень расстроены. Ну, как бы общаясь с такой простой моделью. Соответственно, совсем маленькие модели, они могут даже какие-то на мобильных устройствах запускаться, какие-то могут на домашнем компьютере запускаться, а какие-то могут запускаться у вас в дата-центре. То есть если у вас в дата-центре стоит большой компьютер с четырьмя видеокартами, вы можете какой-нибудь большой, не самый большой, но какой-то разумный взять квен или дипсик и у себя развернуть. Но вообще говоря, большие модели, как правило, всегда в облаке. Потому что помимо того, что вы, даже если вы у себя развернете такую модель, у вас возникнет экономика проблематичная, потому что одновременно же нельзя, чтобы все ей пользовались. Потому что когда 10 человек приходят, она по очереди обслуживает запросы. И если придет 10 человек, будет долго. В облаке это все как-то решается, потому что в облаке много серверов, много людей приходят, и ночью это все не простаивает, Потому что в облаке есть специальный режим, например, обработки по требованию. То есть вы говорите, я хочу обработать вот эту вот кучу текстов, но мне не важно, когда, лишь бы за 24 часа уложиться. И вот в этом случае ваши тексты как бы ночью прогоняются, когда мало желающих беседовать с моделью в диалоговом режиме по уполовиненной цене, например. Во всех облаках, в Яндекс Клауде есть тоже такой режим ассинхронный. И он позволяет сильно экономить. Очень часто бывает вам в вашем модели эти нужны не только, чтобы с ними общаться в диалоговом режиме, а, например, эта модель может анализировать тексты, выделять ключевые слова, выделять какие-то смыслы из текстов. И вот это все можно делать, как правило, ночью, обрабатывать кучу данных. Поэтому у облака экономика сходится намного проще, чем у отдельно взятого дата-центра в компании. Поэтому если можно отдать это облаку, проще отдать это облако. Иногда бывает, что нельзя отдать это облаку, или вам очень не хочется. Но очень часто бывает, что вам не хочется, а на самом деле это просто некая такая иллюзия. Недавно тоже общался с университетом, они говорят, мы хотим сделать рекомендательную систему по нашим курсам, чтобы рекомендовать, какой курс там нужно человеку обучиться. Но мы хотим у себя, типа все у себя развернуть. Я говорю, а почему? Ну вот, типа это наши данные. Я говорю, ну ничего, что они на сайте, в интернете лежат, как бы и так. Что вы боитесь, как бы, да? И к тому же облако их в принципе не раздает налево и направо, и облако часто бывает сертифицировано очень хорошо в плане защиты, лучше, чем дата-центр домашний. Но возможность такая, тем не менее, есть. Если говорить про то, чем можно пользоваться, ну вот вы, наверное, все знаете, чем можно пользоваться. Ну вот, недавно у Яндекса сильно обновился бренд Алиса, и появился Alice Яндекс.ру, в котором можно примерно как в чат GPT загрузить документ, включить режим рассуждений тоже можно. Видите, скоро можно будет попробовать еще и агентов. Поэтому Alice Яндекс.ру – это вот такой хороший пример, куда можно идти, чтобы еще там и картинку сгенерировать тоже, и пообщаться про какой-то файл. Вот добавить фото или файл, что это значит? Ну, как бы модели, они с текстом работают, да, поэтому если вы добавляете какой-нибудь файл PDF, например, да, то он сначала распознается в текст, потом текст как бы кидается просто на вход модели, и вы можете с этим текстом что-то делать, например, говорить, напиши краткое содержание статьи, да. Вот, а есть еще режим работы с фото, это когда модель смотрит на фотографию, и вы, например, говорите, что сделать, там, распознай текст на фотографии, там, Или, например, вот человек выглядит так, скажи, хорошо ли он одет. Я вот недавно спрашивал у нейросети, прилично ли носить футболку под рубашку, если рубашка расстегнута. Кто-то мне сказал, что это очень нехорошо. Я решил спросить у нейросети, нейросет говорит, ты молодец, нет, все хорошо. Но они, правда, часто так говорят, потому что нейросет не любит обижать своего владельца. Соответственно, вот еще вторая рекомендация – это DeepSeek. Естественно, DeepSeek очень хорошая китайская нейросеть. Она не очень сильно цензурирована, это как бы тоже очень хорошо, наверное. Про китайский говорить не надо, а вот про все остальное можно. Есть режим рассуждения, есть режим поиска в интернете. И вот из последних еще хорошая штука есть – Perplexity, в которой есть разные интересные штуки. В частности, есть режим Deep Research, он в чате GPT тоже есть. Это режим, когда нейросеть входит в такой агентский режим. Я про это еще в конце расскажу. Мы вчера как раз подробно разные инструменты разбирали. И Manus, и OpenAI, и QAN. Мы, короче, здесь всю десятку, наверное, просто расковыряли полностью, посмотрели в интерфейсах. Хорошо. И скинули, так что это, как это называется? Попускаем. Знакомый контент, может быть, если кому-то захочется доспросить. Спросите, но в целом мы прям весь топ, наверное, вчера посмотрели и в доступе у всех есть. Может быть, если ты на какие-то особенности нацелишься, ну, например, на повышение агентности этих сетей и на их такую мультитуловую работу, вот, наверное, вот в этой стороне можно. Я про агентность расскажу в конце еще. Спросить хочешь? Перплексити вчера, ну, можно вот про перплексити чуть подробнее. Про Perplexity, наверное, чем Perplexity хорош, в нем есть режим Deep Research, который даже в бесплатной версии 5 Deep Research в день, в отличие от ChatGPT, у которого 5 Deep Research в месяц. Поэтому Perplexity, в этом смысле ей удобно пользоваться. А Deep Research, я кратко расскажу сейчас, наверное, что такое. Это когда вы задаете какой-то более сложный вопрос. А, рассказывали тоже, да? Мы вчера как бы спорили, может ли она галлюцинировать на депрессерче и выдавать не те ответы. Коллеги сказали, что может. Я ни разу не сталкивался. Не знаю, может быть, ты здесь как-то комментируешь. Да, давайте расскажу про это тоже. Значит, вот галлюцинации. В принципе, у меня там дальше слайды тоже про галлюцинации есть. Давайте я вот потом расскажу, а если что, мы в конце еще раз обсудим. Значит, вот про мультимодальные чуть-чуть тоже буквально один слайд. Вот если давать ей фотографию, то можно просить разные вещи. например, про эту фотографию узнать. Вот, например, напиши комплимент человеку по этой фотографии. Как это работает? Вот это называется мультимодальные сети, когда они сразу и с текстом, и с картинками работают. В этом случае просто к тексту добавляются специальные картиночные токены. То есть картинка тоже бьется на кусочки, как бы они представляются как текст такой линейный. И вот эти токены подсовываются просто в общий вот такой контекст модели. И дальше попарно точно так же сравниваются вместе с текстом. И учат ее на каких-то задачах типовых, конечно, ну там распознавание текста, там еще чего-то, опиши картинку словами. Но помимо опирать, опиши картинку словами, вот такие разные вещи типа скажи комплимент тоже в итоге работают, потому что нейросеть понимает принцип, вот как бы что на изображении. Вот, теперь чуть-чуть перейдем к тому, как правильно с ними говорить. Ну вот первое, вы, наверное, устали, но сейчас мы чуть-чуть дойдем до небольшого упражнения, и там просто немножко будет возможность отдохнуть. Вот самое главное про промпт-инжиниринг, что важно знать, я его называю первое правило промпт-инжиниринга, что не бывает плохой задачи, бывает плохой промпт. Не надо отчаиваться с первого раза, нужно просто попытаться нейросеть, убедить в том, что вам нужно. Ну вот типичный пример, я же много со своими знакомыми популяризирую, и говори, пользуйтесь, пользуйтесь, пользуйтесь нейросетями. И там бывает, например, люди приходят, говорят, ну вот мы попробовали попользоваться, мы ее спросили, как нам увеличить продажу, она сказала снести цену, типа, ну глупая нейросеть, мы это и сами знали. Вот, ну вот это плохой пример использования нейросети, потому что нейросети нужно дать полный контекст. Нужно сказать, как бы, вот у нас я выращиваю яблоки у себя на балконе, например, да, они по себестоимости дороже, чем в пятерочке. Как мне их продать, учитывая, что я живу в районе, где много молодых семей, бла-бла-бла. И тогда нейросеть сможет учесть вот эти тонкости, может придумать что-то хорошее. Она там скажет, давайте вы их будете заворачивать в комиксы, которые будут люди покупать, смотреть комиксы, есть ваше яблоко. Ну, это я сейчас сам придумываю, но нейросеть может придумать много хорошего, если ей четко поставить задачу. Это как бы самое главное, четко поставить задачу. То есть если мы говорим просто, типа, напиши какое-то описание, то получается какое-то описание. А если мы, например, говорим, что вот ты маркетолог в магазине игрушек, сгенерирую описание игрушки, ориентированной на детей, такой-то длины по таким-то данным, и даем какие-то данные из базы данных всех игрушек, то у нас получается уже вот такой текст примерно, который, наверное, нам и нужен. То есть, во-первых, начальная установка, вот эта роль модели, она важна, как я уже вам рассказывал на примере с подорожником. Значит, даем задание, говорим, какой должен быть результат, то есть какая длина, в каком формате, на какую целевую аудиторию. И еще интересная тонкость, это вот я сказал, ориентируйтесь на данные в тройных обратных кавычках. Вот использование всяких разделителей, оно помогает модели понять, а где точно, вот начало того, куда ей смотреть. И поэтому форматирование промпта, разные разделители, это помогает модели понять смысл. Дальше еще один важный пример называется few-shot prompting. В чем здесь идея? Shot означает количество примеров, которые мы даем модели в запросе. Мы можем модели дать пример. Это такой глупый, достаточно простой пример. Переведи с русского на английский собака-стрелочка и дальше ждем ответа. А можем дать ей несколько примеров и дальше попросить дополнить. И в этом случае модель будет, ей намного проще решать задачу. Она видит шаблон, и она же видит всегда весь контекст. Она просто копировать начинает этот шаблон с изменением смысла. Вот более интересный пример. Мы даем такой запрос, ответить на вопрос ребенка в похожем стиле, продолжив диалог. Ребенок говорит, расскажи мне о терпеливости. Родитель терпеливости, это как рекат, бла-бла-бла. Вот это все вход нейросети. Все до последнего квадратика Дальше мы пишем ребенок, расскажи мне об искренности И просим это дополнить И вот видите, получается текст, который Ну и по длине похож И по стилю похож И тоже как бы с водой связан То есть вот попросить, например, сгенерировать такое С помощью промпта Не фьюшота, а просто словами описать Напиши абзац, который в аллегорической форме Описывает там что-то Было бы дольше, чем показать пример Да, вопрос Так, у меня вопрос по поводу фьюшота. Количество примеров, которые мы закладываем в промт. Насколько это коллерирует с качеством выдаваемых ответов за счет расширения промта, количество токенов, которые залетают? Потому что я недавно столкнулся на таком примере, там единственное, что должен был пример вывода в Джейсоне от агента, и я задал ему несколько примеров, из-за этого ухудшилось качество. Вот, и где здесь вот эту грань понятия, так скажем. Экспериментально, если коротко. Да, предсказать достаточно сложно вообще поведение модели. В целом обычно качество не то чтобы ухудшается, обычно просто упираются в то, что зачем делать очень длинный промп, если и так работает. Поэтому рекомендуется, например, если мы делаем классификацию на три каких-то класса, давать три примера по одному на каждый класс. Если очень разные могут быть входные данные, может быть тоже на каждую разновидность какой-то пример. Но в остальном дальше, наверное, нужно просто смотреть на статистику вручную. То, что ухудшилось, это может быть связано с разными вещами. Может быть, модель слабенькая. Слабенькая модель может быть просто длинный промп входной. Она может быть из-за этого начинает плохо себя вести. То есть разница бывает. Насчет JSON, кстати, я вот об этом забыл. Мне кажется, нигде не говорю про слайды. В слайдах у современных моделей есть такая штука, которая называется структурный ответ. Дело в том, что очень часто, когда мы говорим с GPT, мы читаем ответ, и нам нормальный естественный текст хорош. А часто мы эту модель хотим поставить куда-то внутрь, это я просто предваряю, хотим поставить куда-то внутрь компании какой-то pipeline, например, чтобы она читала все входящие сообщения и выдавала нам, кому это нужно переправить, краткое содержание, позитивное и негативное. И вот эти структурные ответы, их удобно представлять для компьютеров в неком специальном формате JSON. И как бы мы можем попросить модель, пожалуйста, представь ответ в формате JSON. Но если мы ее попросим, нет гарантии, что модель выдаст правильный ответ. В принципе, всегда, когда мы имеем дело с языковой моделью, никогда нет гарантии, что она выдаст что-то правильно. Вероятность высока, что она даст правильный ответ, но никогда нет гарантии. Это всегда вероятностная модель. И вот структурный ответ – это такая хитрая штука, которая на этапе генерации проверяет, соответствует ли ответ некой схеме. Петерсионечные этапы генерации. Помните, модель у нас генерирует распределение вероятности слов. И по умолчанию мы берем какие-то вероятные слова, но мы же можем учитывать грамматику того, что должно получиться, и структурный ответ берет только то, что может подойти под правильный ответ. То есть это нам гарантирует, что ответ будет правильный по форме, но не факт, что по содержанию. Поэтому в JSON всегда лучше структурный ответ использовать. Ну, это вот да. Да, это боль, я вас понимаю. Вот, значит, фьюшот, вот он часто помогает, если вам нужен какой-то определенный формат ответа, ну даже вот в этом случае тоже вам нужен определенный вид ответа, вот очень просто показать модели пример. Почему работает, вы тоже, да, поняли, она видит, когда пример, она просто берет, как бы копирует примерно то же самое, но меняет смысл на ходу. Вот ей проще видеть образец модели, Как и человеку, в принципе, тоже. Вот, ну вот, chain of thought я уже, в принципе, рассказал, да, вот пример, что если мы говорим просто реши задачу по математике, напиши только ответ, ответ получается неправильный. Если мы говорим реши задачу и рассуждай по ходу дела, ответ получается правильный, но вот это рассуждай по ходу дела можно либо фьюшотом задать, то есть написать пример рассуждений, а можно задать просто фразой рассуждай по ходу дела. Я вот решаю детские примеры в школе, проверяю решение, фотографирую и проанализирую изображение, реши задачку. Не всегда правильно решают по изображению, но по тексту всегда правильно решают. Вот в чем тут проблема? Почему это работает, когда не должно? Не, оно должно в идеале работать. Просто большинство современных моделей их уже таким образом учили, что когда она видит задачу, она начинает писать рассуждения. Вот если вы попробуете написать ей в инструкции «напиши только ответ», например, то часто ответ будет неправильный. То есть именно надо решить. Да. Но именно дело в том, что она не может, как человеку, дай сложную задачу, сказать без бумажки и решай. Он будет страдать и может ошибиться. Вот так же и модель. Модель вообще очень похожа на человека. Они плохо считают. Например, человек не может в уме складывать большие цифры. Вот модель сама по себе тоже не очень хорошо может. Другое дело, что есть понятие инструмента, но вот в конце чуть-чуть про это поговорю, а завтра подробно вы рассмотрите. Модель может дергать калькулятор, так же как человек. И тогда она будет считать лучше. Ну и в завершение я про галлюцинации чуть-чуть поговорю. Вот мой любимый пример, это еще, правда, года полтора назад я ЧАД-GPT спрашивал, почему число π больше 5. Знаете, π это 3, 14, 15 и так далее. И она писала, что π это иррациональное число, оно записывается бесконечной дробью, и раз дробь бесконечная, то она, конечно, больше пяти. То есть она нашла в некотором смысле такую логичную аргументацию, почему это так. Но, значит, фактически, конечно, это неправильно. И вот галлюцинация это такая штука, которая фактически неправильная, а модель ее написала. Почему галлюцинации возникают? Это такой резонный вопрос. Ну вот человек, почему, если его спросить, в каком году основан город Пермь, не всегда ответит правильно? Он не помнит. То есть он как бы не ответит 2000 год, потому что он понимает, что это бред. Но какой-то вот ответит приблизительный. Он, в принципе, мог бы ответить, не знаю. Но модели, как их учат? Их учат, ну сравнивают модели обычно на каких-то таких датасетах, как бы тестирующих. набор вопросов, и поскольку это датасет типа Multiple Choice часто, им выгоднее ответить, чем сказать «не знаю», потому что когда говоришь «не знаю», балл точно не засчитывается, когда ты отвечаешь какой-то ответ, ну типа «а вот повезет». Поэтому модели в принципе всегда стараются что-то ответить, но когда не знают, отвечают самое правдоподобное, до чего могут додуматься. А почему, вот кажется, почему модели не знать, когда основан город Пермь? Да, и человеку тоже. Ну, человеку понятно почему, потому что ему сложно помнить много. А почему не сделать так, чтобы модель помнила все, она же в компьютере, там ее... Ну, во-первых, как бы да, интернет большой, весь интернет, когда мы учим модель, впихивается вот в эти вот там 400 миллиардов параметров, то есть модель меньше интернета. Но самое главное, что если бы модель могла помнить все, что ей хочется, она бы не училась. Так же и человек. Почему человек учится? Почему мы вообще какие-то формулы, принципы придумываем? Потому что нам дают решать много-много одинаковых задач, и мы не можем запомнить все эти задачи, но нам проще запомнить принципы решения, чем сами индивидуальные задачи. И вот нейросети точно так же, если ей давать мало примеров, она запомнит дословно эти примеры. Это называется переобучение в машинном обучении, такое прям есть понятие, когда мы даем мало примеров, но много раз. Она прям их запоминает и говорит, да, вот на эти примеры я даю правильный ответ, а на все остальные какие-то рандомные. А если ей давать очень много примеров, так что памяти у нее не хватать начинает, она пытается извлекать какие-то общие принципы из данных и учится думать. Не может модель думать, если ей дать много памяти. Поэтому галлюцинации неизбежны. Поэтому, когда мы говорим, когда Москва была основана, скорее всего, ответ правильный, она видела это много раз. Когда основан Крыжополь, ответ будет, скорее всего, неправильный. Как с этим бороться? Ну вот уже упоминали поиск в интернете. И я показывал в инструментах, есть кнопочка поиск в интернете. Что это такое? Это модель перед тем, как выдавать ответ, идет в интернет. Не сама модель идет, а вот эта вот сама система идет в интернет. Смотрит на топ-10 страниц, читает их, вбрасывает их в контекст модели, и модель дальше отвечает уже в виде текста. И, конечно, в виде текста, в котором есть правильный ответ, она ответит, скорее всего, правильно. Гарантировано правильно или нет? Никогда не бывает никакой гарантии у нейросети. Нейросеть выдает вероятность следующего слова. Следующее слово выбирается, ну, как бы она в зависимости от вероятности выбирается, но может выбраться не самая вероятная. Ну, я не помню, я понятие температура там дальше рассказываю или нет. Есть такой параметр температура. Давайте, наверное, расскажу, чтобы не забыть. Значит, вот модель на выходе выдает распределение вероятности слов. И можно выбирать слова пропорционально этой вероятности. То есть самое вероятное будет очень невероятно выбрано, но могут быть выбраны и другие. И вот иногда нам хочется, чтобы модель была более разнообразна. Мы, например, хотим, чтобы... Ну, смотрите, если бы модель всегда выбирала самое вероятное слово, то в ответ на фразу «я памятник себе воздвиг» Какой нерукотворный, потому что она видела это, это самое вероятное слово. Но если я хочу, чтобы модель была более творческой, придумала мне какой-нибудь еще памятник, да, я памятник себе воздвиг из пластилина, например, да, то мне нужно, чтобы невероятные слова тоже выбирались. Я могу это распределение вероятности чуть-чуть сгладить в сторону менее вероятных слов. Вот это называется температура. Когда я повышаю температуру, ну почему это называется температура? Потому что случайно в комнате, когда температура выше, газ начинает двигаться, да, активнее. Вот так же и тут, когда температура выше, активнее выбираются слова менее вероятные. Но чем это чревато? Если слишком сильно поднять температуру, начнут выбираться слова вообще рандомные. Бесконечная температура — это просто рандомный порядок токенов. А температура 0 — это означает всегда выбирать самое вероятное слово. Вот. Температура, как ее менять? Ну вот в чат G5 нету ручки температура. Но вот вы будете работать завтра с моделями в облаке, там прям Есть ручка температуры. Можно установить 0, можно установить 0,7, можно установить 2, но не нужно, потому что в ответ на 2 будет бред, как правило. А вот 1, 0,7, 0,3, 0,1. Можно играться с этим в зависимости от того, насколько креативный ответ вам нужен. Но креативный – это хорошее слово, к сожалению. Но вот смотрите, креативность, она находится на грани между бредом и смыслом. Как креативные люди добиваются своей повышенной креативности. Они принимают вещества, которые изменяют сознание, и в измененном состоянии сознания они могут бред написать, а могут что-то хорошее. Никогда не угадаешь. Модель точно так же себя ведет при повышении температуры. Соответственно, да, дальше важный момент, когда мы пользуемся такими моделями, а когда, собственно, их применять. И вот основное правило, наверное, что, во-первых, человек всегда должен сохранять контроль, наверное. Говорить, напиши что-нибудь, а я это не глядя выложу в интернет или пошлю кому-то, это плохая идея. Писать длинный текст, как бы тоже плохая идея давать модели писать «Войну и мир», потому что они не обучены писать длинный текст. Они могли бы, если взять вот эту базовую модель, обученную на интернете, она может генерировать бред до бесконечности. Но их же доучивали на фразах, написанных людьми, на вопрос-ответах, дописанных людьми. А у людей вопрос-ответы, дописанные они, ну, все там 2-3 странички максимум. Поэтому модель по умолчанию пишет какое-то ограниченное количество текста. И с этой точки зрения идеальные моменты для использования модели, во-первых, это в самом начале какого-то проекта, когда вам нужно придумать что-то новое. Мы об этом еще поговорим. Модели очень творческие, даже с температурой нормальные. Они придумывают, если... Да, да. Придумать. Главное, что-то придумать, синтезировать вместе, напиши план, который вы потом посмотрите глазами. Вот это вот на первом этапе модель очень хороший помощник. Наверное, еще сюда можно добавить изучение предметной области. Вот если вы хотите коротко познакомиться с ядерной физикой, вы можете сказать, объясни мне ядерную физику для трехлетнего ребенка. И получите некие первые приближения. Потом можете сказать до 15-летнего, и вот в какой-то момент дойти до уровня сложности, которого вам достаточно, и на этом остановиться. Когда вы говорите общие вещи, модель не галлюцинирует, как правило, потому что вряд ли она будет писать бред, зачем. Она про ядерную физику в принципе знает достаточно. И вторая половина спектра – это манипуляции с текстом. У вас есть какой-то уже документ, вы говорите, проверь грамматику, переведи на другой язык, напиши более формальным текстом, напиши менее формальным текстом, или извлеки данные. Очень частый пример использования извлеки данные, когда просто есть документ длинный, а вы говорите, ну, типа, напиши по пунктам основные предложения, которые там были сделаны. И тогда просто тык-тык-тык-тык-тык вы получаете то, что нужно. Да, есть риск галлюцинации, но тут уж вам взвешивать, насколько это ответственная вещь. Если от этого зависит судьба компании, лучше отдать юристам. Пускай они в чат GPT занесут, получат ответ, а дальше будут хотя бы отвечать за это. А если это нужно просто посмотреть, оценить, то вполне себе законное применение. Но еще есть разные интересные стратегии применения, например, реверсивный диалог, когда мы говорим в сети, мне нужно составить какой-то документ, спрашивай, задавай мне вопросы, которые тебе нужны, чтобы составить этот документ. Модель начинает тогда сама спрашивать, это полезно. Для чего не надо использовать модели? Анализ данных, вот есть такое ощущение, что это же компьютер, он же хорошо анализирует данные, я загружу туда табличку гигантскую, дальше спрошу прогноз по продажам, еще чего-нибудь. Вот так напрямую делать не надо. потому что считает модели плохо. Как можно делать? Можно загрузить табличку, сказать, напиши код на языке Python, который произведет анализ этих данных. Вот ChatGPT, он в принципе делает это сам. Он иногда, когда вы его там просите, построить какой-нибудь график или что-то, он на самом деле генерирует код, который выполняется прямо в этом же окошке и рисует вам график на выходе. Perplexity Depressure делает то же самое. Он выполняет код на Python и рисует вам график. Но нужно понимать, что это делает не сама модель, это вот некие дополнительные инструменты. Если вы спросите там у дипсика, который так не умеет проанализировать данные, будет очень плохо. Да, и вот длинные тексты за один проход. Я чувствую, что нам нужно ускориться. Давайте я про картинки чуть-чуть пропущу. Вот, есть такой у меня документик, шпаргалка. Я вам ее закину, наверное, в чатик. Меня добавили на время в ваш чатик, я туда ее просто закину в конце. Ну или как можно вот по ссылочке ее скачать. Да, тут просто короткие такие инструкции по промт-инжинирингу, я про них подробно про все не рассказывал, потому что иначе будет долго. Вот, значит, я предлагаю проделать нам в качестве прелюдии к перерыву небольшое упражнение, или после перерыва, или на перерыве. Значит, упражнение такое, значит, вот есть документы, да, упражнение, значит, такое. Представьте себе, что у вас компания по производству планшетных компьютеров. Планшетные компьютеры – это такой странный форм-фактор, который, в принципе, никому не нужен, кажется. Но стоит понять вообще, там у них продажи как идут, увеличиваются, уменьшаются. Вот попробуйте очень быстро это понять. Я закину два документика в чат, где про это немножко написано, кажется. Но можно еще с помощью поиска в интернете поискать. С учетом этого отчета и каких-то других источников вы пытаетесь понять, насколько имеет смысл заниматься производством этих планшетных компьютеров и как вообще, на кого ориентировать. Какая там аудитория должна быть, как там повысить продажи. Ну и придумайте название для компании, сгенерировать рекламный плакат. То есть вот ожидается что-то типа такого на выходе. Я предлагаю это делать по группам, чтобы было веселее. Можно объединить группы, наверное, два стола, первый и второй ряд, развернуться и объединиться в группу. И вот что-нибудь такое потом закинуть в чат. Мы не будем очень подробно на это потом смотреть. Если мы будем на каждый результат смотреть, мы до вечера просидим и будет не так весело. Просто кидайте в чат, я выведу на экран, будем смотреть, что у кого получается. И можно, наверное, прямо в режиме перерыва это сделать. Я думаю, что да, я как раз хотел предложить. Давайте сейчас сделаем перерыв. Вот у нас он будет чуть больше 15 минут до 16.00. Сейчас 15.42. И мне кажется, за это время можно сделать. И после перерыва в 16.00 мы продолжим, посмотрим, что у кого получилось. Перерыв. До 16.00. Задание можно сводкать, да. Вернуть можно. Давайте, да. Если я закину документики в чат. Thank you. Thank you. Субтитры создавал DimaTorzok Thank you.