Невозможно оттуда это выковырять. Нет, у них какая-то страцессия внизу, и они тут находятся. Так. В любом случае, давайте, как это называется, начнем... А где у вас все? Обожали? Значит, смотрите, коллеги, давайте немножко, пока у нас есть время, поговорим про завтрашний день. Завтрашний день у нас с вами, во-первых, напомню, чтобы вы просто были в курсе, у нас два разговора больших, прям с самого утра, я так помню, у нас в 10.00, да, в 10.00 мы начинаем, в 10.15, значит, это будет разговор, соответственно, с Денисом Ковалевичем, он будет онлайн, но разговариваем мы про венчурный бизнес. Мы решили, что это международная стартап-студия, они инвестируют в проекты, связанные с искусственным интеллектом. И мне показалось небезынтересным посмотреть, как принимаются решения людьми, которые вкладывают бабки в искусственный интеллект. На каких основаниях они вообще выбирают эти решения, что за структура, как портфель формируют. Про портфель сегодня говорили. Вот, собственно, прям венчур-венчур, как они управляют этим самым портфельм. Это то, что у нас с вами будет завтра. Значит, вторая часть у нас будет про наши коллеги, знакомые уже нам из компании Яндекс. Соответственно, мы попросили их рассказать про их версию, тоже важно, про их версию карты зрелости искусственного интеллекта в компании. Это вот несколько версий уже мы в этом модуле видели, и там от МТС банка, и, соответственно, еще отдельных товарищей. Но, в общем, это будет еще одна версия как раз от Александра Долбнева, по-моему, у нас был на прошлом модуле, если не ошибаюсь. Соответственно, нет, не было. Ну, значит, я просто уже как-то немножко запутался в программу. Короче говоря, карта зрелости компании тоже от компании Яндекс. Это, грубо говоря, история, по которой можно следить за тем, где мы, ставить какие-то чекпоинты и, соответственно, в эту сторону смотреть. После вечернего, ну, после, собственно говоря, утреннего слота у нас есть послеобеденный спринт. Значит, я хочу сказать, что все, кто не выступил за эти дни и все остальные, у нас, как всегда, традиционно заканчиваем короткими питчами. Каждая свою часть организационную рассказывает из присутствующих, ну, из тех, кто работает над ней. Мы завтра послушаем всех, потому что это важно высказывание сделать. И оно не будет так подробно разобрано, как мы разбираемся, соответственно, здесь на пленарах. Но мы в любом случае должны будем такую экспозицию снять, потому что это, собственно, важная часть. Поэтому готовьтесь, мы попросим со всех организационную часть предъявить. Это важная штука. Мне кажется, у нас материала уже более чем достаточно для того, чтобы собрать свою конструкцию. Будет еще три целых спикера. Вот наконец-то у нас Алексей до нас дошел. Что же вы, Алексей, опаздываете? Значит, и, соответственно, у нас еще два спикера будут. И хочется, чтобы вы... Мы дадим завтра шаг после того, как спикеры поработали, переработать. Хочется, чтобы вы свою версию сказали. Мне кажется, важная вещь, которую нужно помнить, высказываться завтра позиционно. Здравствуйте, Алексей, мы так рады вас видеть. Я уже думал, что не даем. Вы елочку ради тебя нарядили, а у тебя все нет и нет. Значит, все. Мы, значит, давайте теперь, короче, думайте про завтрашнее выступление. В обязательном порядке мы всех послушаем. Важный момент, соответственно, надо будет подготовить это высказывание и сказать. И позиционное высказывание. Так, сейчас мы тут пока настраиваемся. Мы уже говорили вам сегодня и анонсировали выступление Алексея Макина. Соответственно, если вы, Алексей, уважаемый, не торопитесь, то мы все время, которое было запланировано, мы его и займем. То есть в этом смысле не это самое. Мы не будем срезать углы, значит, и поговорим. У нас есть возможность поговорить. Мне кажется, что компания RedMetRobot, одна из тех компаний в России, и она международная компания, RedMotorobot, надо скорее так сказать, которые наиболее интересно двигаются с точки зрения вообще организационного подхода. Это нетипичный организационный подход, то, как компания двигается, а нетипичная бизнес-модель, вот совсем нетипичная, и уже тоже, Алексей, то, что мы сегодня говорили, тоже заход в венчур. Но заход, не венчурная компания, но как бы есть туда история. Мне хочется, чтобы вы эту, тоже экспозицию, как двигается компания, увидели. И, соответственно, в сфере искусственного интеллекта, ну, я думаю, что точно входит в топ-5 компаний в России с точки зрения понимания глубины и возможности развертывания, добегания до результата. Вот. Мы про искусственный интеллект уже договорились, что мы с тобой поговорим, в смысле ты развернешь. И как бы про организационные условия. Вот у нас сегодня широкая такая палитра, значит, от, так сказать, одного из лидеров, но не то, чтобы, как это называется, сильно перехайпованного. Вот так. Значит... — Меня слышно, да? — Тебя слышно. Да. Спасибо, что дошел до нас. Здорово, значит, начинаем. Поехали. Как всегда, с понятий, все понятно, с понятий искусственного интеллекта. — Ну да, всем привет. — Алексей Макин, поприветствуем. Сумас, грустно. Давайте, если позволите, я уверен, у вас сейчас так прям хорошо плотно идет модуль. Можете, может быть, пару слов кто-то скажет, о чем важно было бы мне проговорить. Николай так очень широко представил. Давайте с микрофоном. RedModer Robot славится своими решениями, что вы всегда делаете нестандартно, как вам нравится и прочее. Интересно, куда вы сейчас в эту сторону идете, когда нет никакого рынка, на что можно ориентироваться, на чем фокус? Потому что кажется, что вы там раньше мобильное приложение сайта конструировали, а и это не мобильное приложение сайта. Как здесь направление выглядит? Я расскажу. С кем себя сравниваете или куда идете? Да, мы точно про это поговорим. Я у вас второй раз, вы у нас на практику выступали. Про зональное управление можно будет остановиться? Но если у нас сегодня будет времени достаточно, мы в орг часть залезем тоже. Дайте смотреть сейчас по таймингу. Или это на следующем модуле будем? Залезем, все, хорошо, да, без проблем. Да, все, хорошо, ну, все, принято. Еще? Тут тебе группа поддержки пришла. Да, да, да. Ты не очень справляешься. Команда? Хорошо, ладно. Подсказывать будут, если что. С карточками, знаешь, на заднем. Да, будут врываться. Еще есть у кого-то запрос? Или на что стоит обратить внимание? Все, нет? Ну что, погнали тогда. Давайте тогда так. У меня сейчас будет первая часть про именно понятие и вообще про искусственный интеллект, какие-то базовые вещи. Уверен, что вы на модуле, вообще в принципе время учения вам много или чуть ли не каждый про это все рассказывали, но я так в надежде на то, что какой-то некоторый набор вещей я вам принесу полезных, которые вы до этого не слышали. А вторая часть уже будет как раз про кейс построения стратегии управления компанией, там мы как раз больше посмотрим. Давайте-то, у нас сейчас до перерыва сколько есть времени? Мне за сколько надо уложиться в первую часть? Вообще всего два часа? А, то есть первая часть два часа. У тебя, да, у тебя есть... Спокойно можешь... У нас до 17.00 предполагалось, что ты начнешь. Ну, давай как бы ориентироваться. Все, хорошо. Давайте мы часа полтора, наверное, по искусственному интеллекту поговорим, потом сделаем перерыв, а потом уже уйдем в содержательные вещи. Ну, откуда я на самом деле про… сейчас буду говорить именно про историю с искусственным интеллектом. Ну, во-первых, я потом про компанию еще подробнее расскажу. Ну, то есть сейчас мы говорим о том, что мы как компания где-то за три года перестроились практически полностью в холдинг. У нас вообще только искусственный интеллект. То есть мы сейчас с точки зрения экспертизы, у нас несколько R&D команд, В своих собственных у нас в России сделано совместное предприятие с МФТИ, с физтехом, как с командой самой сильной экспертизы в российском рынке. У нас также есть совместные предприятия в Лондоне и в Китае. Мы практически в мире сейчас опираемся на самые основные центры экспертизы вообще по искусственному интеллекту. В Китае это пекинский университет, это вообще сейчас считается топ-1 лабораторией в мире. В Лондоне это Cambridge Royal Institution, там еще несколько. Это раз. Два. Я сам в 1924 году закончил в Лондоне, получил, защитил диссертацию Master of Science по искусственному интеллекту. Так, сейчас тоже там уже сейчас в следующем 2026 году начну PhD уже делать по этой теме. Поэтому достаточно хорошо, как мне кажется, в этом разбираемся. Поэтому, если надо будет, можем прям вообще на любую глубину зайти. Но так как мы говорим все-таки про управленческую программу, поэтому я здесь буду давать все, что касается понимания искусственного интеллекта, вам скорее изгласнее как технический, то есть вы не LP инженеры, вам это не надо знать на такой глубине, но как управленцам надо в этих темах разбираться, я такие базовые понятия именно в этом разрезе дам. Давайте погнали сразу в содержание. В чем, ну и наверное моя часть этой рассказа, будет сочетаться с одной стороны с базовым пониманием, а с другой стороны с каким-то убиранием мифов или непониманий в том числе. Потому что, конечно, рынок искусственного интеллекта сейчас вообще понимание всего - это скорее больше рынок непонимания, чем понимание. Я бы так это назвал. Первое такое вводное, что важно понимать про то, когда мы говорим сейчас слово искусственный интеллект, что скорее сейчас два больших сдвига происходят. То есть первое, на самом деле, очень огромный сдвиг идет, перехода от информационных систем к эре интеллектуальных систем. Но в чем это выражено? Я могу, наверное, как пример привести. Кто-то из вас, если слышал или видел историю 60-х годов, когда компьютеры только появлялись, и вот в тот момент, представьте просто люди, которые только умели трогать электричество, понимали, что такое электроприборы, а им тут начали рассказывать, что появились первые компьютеры, которые стояли как здание и все такое. И вот на самом деле у человека в этот момент, и сейчас это тоже такая похожая история, что категорийно очень тяжело осознать, что компьютер это не электроприбор. Потому что прям очень прикольный пример. То есть если спросить человека в 60-м году, какого-то специалиста, когда объясняли, что такое ЭВМ или компьютеры, То есть люди говорят: «Ну, это же электроприбор, я типа электротехнику». Ну да, это электроприбор, но компьютер, он очень сильно отличается от чайника в этот момент. Да, даже от электроприбора с какими-то схемами и вещами. И сейчас, когда мы говорим про системы, которые внутри себя, внутри построены базово на генеративном искусственном интеллекте, на больших языковых моделях, Их категорийно можно относить уже к тому, что да, это в основе своей использует программный код, и это использует, что мы пишем код, когда их создаем, но на самом деле категорийно это другой уже уровень систем. И у них есть прям очень глобально отличающиеся свойства, которые пока мир еще не понимает до конца, поэтому мы сейчас будем про это говорить. Но почему мы так про это говорим? Потому что у интеллектуальных систем, построенных на базе больших языковых моделей, у них свойства есть, которые просто их радикально и драматически отличают от обычных классических информационных систем. К примеру, мы привыкли к вам, когда мы пишем ПО, какую-то разработку, что это называется детерминированные системы. Что это значит? Что любой разработчик, когда он пишет программу обычную, то на самом деле внутри нее зашита жесткая логика, которая всегда понятна. То есть мы можем проследить как от входа, так до выхода, как себя будет вести эта информационная система. Когда мы говорим про системы, которые в базе своей используют большие языковые модели, она называется недетерминированной системой. Потому что мы, как обычными нашими средствами, не в состоянии, на самом деле, все вариативности сценариев того, как себя будет вести эта система, сформулировать. И она себя ведет, это специально называется недетерминированная система. Сейчас потом в детали буду лезть, но у нас такой прям большой глобальный переход. При этом, наверное, второе, что сейчас важно, какая путаница сейчас происходит. Есть мир до появления больших языковых моделей, ну и в него внутри входило в понятие искусственного интеллекта достаточно большие другие сектора. Это машин леонинг, это NLP системы, natural engine processing и так далее. Вообще кто более-менее в этих темах понимает? Вы можете руку поднять? Хорошо, класс, спасибо. Наверное, одной из основных сейчас таких точек проблемы или заблуждения, это когда мы говорим про категорию системы с искусственным интеллектом, когда не то, что путают, а я в машин-ленинге хорошо понимаю, поэтому я и в больших языковых моделях тоже хорошо понимаю автоматически. На самом деле это не так. И мало того, даже мы по опыту общения видим, что команды или люди, которые очень круто секли в NLP или в машин-ленинге, чем круче они в этом понимают, тем тяжелее им врубаться, как бы в отличие. И это прям видно. И мы видим даже в самых больших корпорациях российских, то есть ребята, которые очень много всего делали в машин-ленинге, они прям, я так и называю, у них их известность или самомнение о себе в предыдущих поколениях искусственного интеллекта мешает им сказать, что я ничего не понимаю в больших языковых моделях. Поэтому, когда мы говорим сейчас про искусственный интеллект, все, что касается машин леонинг, NLP, это все классно, оно все присутствует, этим можно пользоваться, Но мы про эти типы решений не говорим, я буду говорить только про большие языковые модели и генеративный искусственный интеллект. Надо пояснить почему или нет? Можно вопрос задать? Как вы думаете, с большими языковыми моделями связывают то, как Nvidia выстрелила, и все, что касается графических карт GPU, которые, как у нас же самое главное, капитализируется, это Nvidia, это та компания, которая производит графические карты. Почему, знает кто-то, почему вообще, как это связано? Как считать на них? На этих чипах считают, на этих картах. Что считают? Перенажение матрицы, там хорошо считается, где много параллельных операций, как раз GPU для этого делали. Изначально, для графики. Почему она в ML использовалась? Почему именно в генеративном искусственном интеллекте произошел взрыв? Да, вы правильно говорите, что там технически считается. Почему GPU карты оказываются? Ну да, почему? Ну, сейчас еще раз. Это тот же ML. Его нужно и обучать, и инференсить, то есть и исполнять эти модели. Они, чтобы их обучать и чтобы их исполнять, нужны огромные матричные операции, которые быстро делаются на видеокартах, потому что видеокарты могут делать параллельность вычислений, которые позволяют ускорить перемножение этих матриц. Понятно. Такой ответ подходит? Нет, не подходит. Он как раз, нет, спасибо, это на самом деле как раз очевидно, когда мы не прошли внутрь и не разобрались. Я на самом деле сейчас буду вам такие вещи подсвечивать. Не поленитесь, пожалуйста, разберитесь. Есть, во-первых, сам чат GPT вам в помощь, помучайте, и он вам все ответит. Или почитайте. На самом деле один из очень важных факторов при реквизитах к генеративному искусственному интеллекту, на самом деле это то, что в отличие от ML как раз обычных алгоритмов, Там тоже используются всякие нейронные сети, тоже используются вычисления. Но на самом деле почему называется большая языковая модель? Давайте еще по-другому. Вот этот второй вопрос задам, а потом мы уже с вами полезем внутрь. Почему LLM? Откуда вообще? Да, оно как бы начинает работать со смыслами. Но почему она большая и языковая? Параметров там очень много, миллиардов. Памяти много всегда есть. Кластер нужно, чтобы спустить. Может потому, что обучался на естественных корпусах языка, и поэтому, собственно, большая языковая на всем интернете естественного языка. Да, да, вот именно. На самом деле, в чем как раз категорийное отличие от машин леонинг или от обычных нейросетей, нейронные сети им реально уже много лет. То есть ими пользуются довольно давно. На самом деле, основной прорыв произошел в том, что вообще-то первое было такое открытие побочное, это когда Google пытался сделать новую технологию по переводу из одного языка на другой. И они на самом деле взяли за основу, вообще там интересную, просто мы тоже недавно еще дополнительно копали, они взяли за основу работу, которая была сделана в Кембридже еще в каком-то чуть ли не 56-м году, в котором одни из математиков сказали, что на самом деле нужно попробовать взять из языков, Ну, языки наши, английские, ну, как это называется, натуральные языки, да, как это на русском, правильно. Ну, естественные языки, да, вот. То есть как-то надо взять и попробовать перевести в математический аппарат, чтобы, ну, вот сами значения слов еще, они были математически выражены, да, и можно было потом в другой любой язык это переводить. И вот раньше из-за того, что не было таких мощностей, то есть математический аппарат на самом деле был написан. Он был еще, оказывается, в 56-м году сделан. Не было вычислительных мощностей, которые бы позволяли это делать. И что сделала команда Google? Они взяли и сделали вот это, то, что сейчас называется трансформерами, но там перед ними даже тип архитектуры нейронных сетей, на самом деле сделали очень простую вещь. Они смогли перевести в многомерную матрицу, ну просто как фразу или текст, сформулированный на естественном языке. Многомерную матрицу, картинка вот здесь, они взяли эту работу 1956 года и смогли ее реализовать технически. Что имеется в виду? Что они практически смогли сделать так, что если на английском языке, они сначала взяли английский язык и взяли словари англо-русский, англо-немецкий, и смогли перевести в векторное представление практически весь корпус языка. Что это значит? Что это стало не написано: кош, котенок, кошка, собака и так далее. Это определённые стали такие матрицы многомерные, и в них оказалось, что если я написал кошка или котенок, то эта матрица, условно, вот эти выражения, они на самом деле очень близкие друг к дружке, и я могу не просто перевести из одного языка в другой, а на самом деле ещё оказывается, что я могу теперь, если выражение животного, кошка, еще что-то, оказывается, они матрики, как в этом векторном пространстве, очень близки, я могу их, используя определенную математику, легко находить или использовать вообще с другими возможностями. И когда они в итоге смогли сделать так, что они взяли словари, Google команда, словари всех языков, перевели в векторное пространство, оказалось, что вот это даже пока тут нет больших языковых моделей пока еще. То есть оказалось, что вот эта векторная, как бы большая матрица, ты можешь условно в нее положить слово cat на английском и из этой матрицы обратно вытащить, она вам на другом любом языке, ну, собственно, это вот это циферное математическое представление этого слова может в любой другой язык перевести. То есть сам по себе формат перевода стал работать по-другому. И потом оказалось, что если я возьму все 33 языка, больших языковых групп, которые на самом деле очень представлены в интернете, сначала словари, потом просто корпуса текстов из Википедии, и смогу их перевести в векторное представление, то есть я сделал первое, а потом к этому добавились уже архитектуры нейросетей. Почему они называются языковые? Потому что по факту это модель, в которой уже вложены огромные корпуса текстов на всех 33 языках больших мировых. И получается, что дальше, если я в нейросеть запихал условно эти все корпуса текстов, то она из себя представляет скорее носитель языка всего. Так как это обучалось на корпусах текстов не только на словарях, а на самом деле там огромное количество текстов из Википедии, из Reddit, дальше стало подготавливаться определенное массиво этих текстов, художественная телеатура и так далее. Почему сейчас, когда вы в модель пишете какой-нибудь вопрос, она в принципе усредненное знание про все на свете вам отдает, потому что в нее все знания запиханы, и там определенным образом они в ней обучены и хранятся. И поэтому это стали называть большой языковой моделью, потому что это является моделью языка, всех языков в мире, которые сложены в векторном математическом представлении. То есть в какой-то степени это все, что знание человечества накопило. Только единственное, сейчас они именно учатся на открытых корпусах текстов. То есть имеется в виду, что если вы где-то там проходили, кто-то из вас учился на гидроэнергетика и есть учебник по гидроэлектростанциям, которого нет в интернете, то там этих знаний уже нет. Это надо понимать. То есть это то, что научено. Но почему GPU карты оказался энейблер к тому, чтобы это все работало? Потому что в картах, которые делались для 3D-игр, там используются математические алгоритмы, которые позволяют считать, по факту 3D-игрушки же все видели, там вот эти 3D-движки, там специально написаны математические формулы, которые в параллели позволяют делать очень сложные многомерные вычисления, чтобы по факту перестраивать постоянный мир. И вот оказалось, что GPU-карта суперкруто справляется с тем, чтобы считать в параллели именно эти математические формулы, которые позволяют пересчитывать многомерные матрицы. Потому что условно обычный компьютерный чип, который работает в компьютере, у него нет таких формул, и он условно, Даже супермощный суперкомпьютер с обычными чипами CPU, он считает определенные вычисления за сутки, а одна GPU-карта то же самое вычисление делает за несколько секунд. То есть там просто колоссальная в тысячи раз разница скорости. Поэтому, в принципе, оказалось, что эти GPU-карты, они для вычислений многомерных матриц, по факту, дали возможность просто за какие-то очень маленькое время делать вычисления или обучение то, что называется, моделей. Но это дало возможность, почему дальше называется большая языковая модель. Теперь слово «большая» еще другой разрез. Потому что когда инженеры, которые начали собирать эти нейросети, поняли, что у них есть возможность с этими вычислительными картами GPU-шными реально делать сложные большие вещи, то они стали собирать вот эти архитектуры. То есть если посмотреть, то там, если мы говорим про архитектуру нейросетки, какого-нибудь там GPT-3, даже там не пятый, все равно в нем там какие-то колоссальные миллионы этих маленьких нейрончиков собраны, технически собраны. То есть если мы говорим, это очень сложная, большая архитектура, которую раньше, если бы не было серверов на GPU-картах, то это просто невозможно было ничего посчитать, то есть просто не было инструментов. А когда получилось так, что мы сейчас берем кластер из 100 тысяч видеокарт, как это делается у Грок Илон Маск, у которого вообще не было никакой нейросети, он пошел, купил там сколько листов или 200 тысяч карт, у него инженеры сели за месяц, собрали архитектуру этого GPU, взяли там эти все корпуса текстов, И в принципе оказалось это не научная инженерная задача, теперь сделать следующую большую языковую модель. Это когда-то считалось наукой и сложностью, но сейчас в принципе если у тебя есть возможность купить 100 тысяч карт, то да, да, все, на самом деле да, иметь свою большую... Если у тебя есть бабки, если у тебя есть несколько миллиардов долларов, и ты друг SEO NVIDIA, чтобы он тебе сразу отправил эти карты как бы вне очереди. Да, ну вне очереди, потому что Илон Маск, он это же и сделал, он просто вне очереди реально выкупил у них там огромный кластер карт у NVIDIA без очереди. И то ты можешь в принципе все, посадишь там, ну пару десятков NLP инженеров, они тебе соберут большую языковую модель. Но еще важно иметь доступ, собственно, вот эти все тексты большие, потому что большая языковая она работает, когда у тебя есть 200 тысяч карт, у тебя есть инженеры, которые собрали эту архитектуру, но плюс у тебя еще должны быть корпуса текстов собранные огромные. Из этого получается уже, то есть ты можешь запустить эти алгоритмы и получить большую языковую модель, как вы видите. Дипсик, наверное, это, если кто-то читал про этот кейс, то есть пример, что китайские умные ребята на запасах серверов, собственно, вот это прям тоже хороший другой пример, как они это сделали. Но что здесь важно? То, что вам дальше, наверное, в бизнесе важно знать, что большая языковая модель, когда она обучилась, это не программное обеспечение. Это вам может показаться контруинтуитивным, но сама большая языковая модель, когда ее инженеры обучили, и, допустим, Вот если вы слышали, говорят, что есть open-source модели, которые квены или китайцы делают следующую модель, и они ее выкладывают в open-source, ее можно забрать. На самом деле сама по себе большая языковая модель, подготовленная нейронная сеть, это не программное обеспечение. То есть это на самом деле, если прямо не поленитесь кто-то, попросите своих разработчиков или кто понимает, чтобы вам скачали и показали, как выглядит в тексте, в файлике на компьютере большая языковая модель. Это вообще технически просто большой файл, в котором расписаны параметры цифрок. То есть как запускают большую языковую модель. Условно, китайцы сделали последнюю большую языковую модель, вы этот файлик себе выкачали, и на сервере, на программном обеспечении, условно, ее воткнули в серверное программное обеспечение, она начала работать, но это не программа сама по себе. То есть что это означает? На самом деле, когда ее обучили, эту модель, и нам ее отдали обученной, она в этот момент, когда мы уже с вами с ней взаимодействуем как пользователи, это как бы оно недообучается. Вот это прям супер важно. Что это означает? Это практически мертвый слепок нейронной сети, которая просто вот когда в нее там закинули вопрос, ввели какие-то циферки, она выплюнула ответ, какие-то циферки. но при этом внутри нее, допустим, ее условно обучили в мае 2025 года, загрузили все данные, новости на момент мая 2025 года. В этой модели в декабре 2025 года уже невозможно поменять ничего, то есть она просто работает как замершая штука. А дальше к ней уже пристроены определенные программные обеспечения, которые может условно какие-то новости из интернета подтягивать и ей загружать на вход. но сама она такой слепок. Это важно... А он там даже не терабайты, там он пару гигабайт, если я правильно помню сейчас. То есть там это не такой большой. То есть там как раз смысл в том, что так как это не прямой в лоб тексты, они когда переведены в многомерные матрицы, то на самом деле это практически нельзя назвать архивацией в чистом виде, но это прям суперсильное сжатие, потому что на обучение используются терабайты, по факту. Они, если честно, не сжимали, они немножко хитрее сделали. Они взяли предобученную модель GPT-чата, и на самом деле эти веса, которые у нее там были в математике, они их просто, как бы, они, получается, не с нуля обучали модели, они взяли уже вводные, готовые, То есть как, условно, Альтман с OpenAI уже потратил 3 миллиарда долларов на обучение, они взяли только уже эту готовую штучку, воткнули к себе и дообучили. Поэтому, когда они говорят, что у них 5 миллионов долларов это заняло, это как бы, ну, как сказать, это практически просто потому, что не надо было с нуля это все проходить обучение. Поэтому, наверное, в этом смысле. А можно, для уточнения, вот про DPSIC, правильно ли я понимаю, что им нужно было, во-первых, поднять такую же архитектуру, такой же набор по количеству слоев, а потом взять стыреные веса? Нет. А как? Ну, там немножко сложнее устроено, потому что я могу вообще не делать абсолютно... То есть моя архитектура, как я делаю свою большую языковую модель, я могу ее делать, как хочу. То есть у меня единственное только важно, что на примере в слоях тот слой первый, которому я подоткнул, могу только вот в этом моменте забрать веса модели предыдущих. То есть у меня по факту, ну как только точка соединения имеет значение, а дальше вся моя архитектура, она может быть такая, как я хочу. То есть веса, то что было в OpenAI, подавалось, грубо говоря, на вход? Да. Да. Веса же OpenAI должны на те же слои, как в OpenAI, лечь, а уже дальше уже свои слои со своими весами придумать, Они на вход просто зашли, то есть они взяли вот этот там, ну, условно определенные висажи, это даже не архитектура нейронки, это просто все. Они в первый слой сделали его совместимым, а дальше спокойно уже свою архитектуру делают. А, понятно, спасибо. Ну это давайте сейчас туда лезть не будем, я вам просто рекомендую почитать. Я зачем это, как бы, важные моменты говорю, они вам надо иметь ввиду, Первое, это векторизация данных, потому что эти системы оперируют в целом в большей степени внутри себя не данными файловых систем, как вы привыкли их видеть. Если кто-то из вас с UBD Oracle видел, то это табличное представление данных. Система интеллектуальная оперирует векторными многомерными матрицами. Это принципиально другой носитель данных. вообще другой, вообще все другой, новый тип. Это вот это важно. Это раз. Два, дальше. Это сама языковая модель не является программным обеспечением. И когда мы их используем, то мы используем внутри программного обеспечения, но они этим не являются. И она недообучается. Когда пишете запросы в чат GPT, или даже если вы у себя на сервере подняли, то сама модель ничему недообучается, когда она отвечает. и так далее. Там супер куча свойств, которые просто надо понимать, как они по-другому работают, не как программное обеспечение. Нормально, двигаемся дальше. Вопрос. Как бы дальше. Вот когда вы пишете в чат GPT, ну или там в DeepSeek или там куда-то, вот вы, ну как вы думаете, как бы с чем, ну то есть вы напрямую в большую языковую модель пишете? Кто вам отвечает? Какое у вас есть впечатление? Есть впечатление, что вы написали, сразу же это попало в большую языковую модель, ну и она вам ответила. Или что вы в Excel положили файлик в картиночку, то она как бы уехала в большую языковую модель. Есть такое ощущение или представление об этом? Как вы думаете? Непонятно, да? Я не понимаю, что я спрашиваю. Такое ощущение, как будто идет распределение. Если там про изображение, говорим, это условно в одну тузу ушло, если там текст, то в другую тузу ушло. До модели или после? Ну, до того, как эта модель получила эти данные или после? Хорошего вопроса, да, не знаю. Ну ладно, там идет управление контекстом для начала. Диалог нужно сохранять и прошлое сообщение тоже отправлять. Дальше все коллагирование, много всего. Вызовы инструментов прикручены, но если так коротко. Ну вот, в чем как бы идет, ну, наверное, ключевое заблуждение рынка 25-го года, что реально, если попросить любого из вас до этого, то, что я показал, нарисовать, а как вы считаете, как реально идет взаимодействие в чатовом окне с моделью, на самом деле складывается представление, как будто это реально внутри большой языковой модели все это и делается. Даже вот MCP, если мы говорим, например, тулзы и так далее. На самом деле это огромное заблуждение, потому что OpenAI, вот их веб-сервис или даже API, у него между моделью, которая считается движком и точкой входа пользователя, сейчас насчитывается архитектура больше 300 компонент. И на самом деле, когда мы говорим про какие-то работающие системы, даже если она не обязательно общается с пользователем, то это достаточно сложная архитектура. И, собственно, в чем сейчас чаще всего происходит прикол, когда у вас в компании рендишники говорят, ой, да мы все сейчас сами поднимем, сейчас все сделаем, покупают там серваки или их арендуют, разворачивают какой-нибудь квен и начинают напрямую втыкать в ваши системы опишку этой модели. И так чаще всего происходит. Я уверяю, если сейчас попросить кого-то из вас, чтобы вам показали архитектуру ландшафта этих систем, то там из того, что я сейчас даже здесь показываю, просто 70% названий компонентов никто не знает, даже просто не вникают в это. И когда нам говорят о том, что 95% внедрений, если помните такую классную статистику, проваливаются и не работают, на самом деле в чем особенность? В том, что в 2025 году все научились покупать API моделей OpenAI, но по API OpenAI отдает прямой доступ к модели. он не отдает доступ ко всем этим компонентам. И когда, если вы на сервере разворачиваете, вы разворачиваете чистую модель, которая просто генерит ответ, и у нее нету, а дальше примеры, что за компоненты там нужны. Вот, к примеру, модель глючит, она может реально ответить, у нее же нет ФЗ в голове, она может вообще что угодно вам наговорить, выдать экстремистские вещи, или реально, которые с точки зрения Роскомнадзора будут считаться нарушением закона. У нее же нет внутри этих ограничений. Она может мало того, почему модели, есть особенности еще, почему модели глючат. На самом деле, когда я называю это галлюцинацией. Это в ее природе заложено, что, к примеру, если вы спрашиваете про какое-то событие, которое очевидное, и оно было загружено в модель раньше. Если мы говорим про модель, которую мы используем, то оно, наверное, этот факт выдаст с большой долей вероятности, как вы попросили. А если вот когда человек пишет: "А расскажи про меня историю", это вот прям супер там прикольные классические кейсы. На самом деле в этот момент модель, почему она может про человека выдумать что угодно? Потому что у нее про этого человека нету данных. Что такое "расскажи историю"? Она чисто математически пытается в своих векторном пространстве найти максимально близкие, близко матрично математически близкие факты. Ей пофигу, что она и выдумала, у нее нет такого. Она просто находит максимально близкое математическое соответствие, и его просто отдает чисто в математике. Абсолютно. Да, причем там, когда ты еще пишешь: "Расскажи про меня, мою историю", то на самом деле там есть такие моменты: "Историю" - это "storytel". То есть это в смысле она просто тупо выдумывает. Ну, то есть там такие есть факторы, которые просто так как мы не понимаем свойства, как она работает, нам кажется, что мы называем это галлюцинациями. А это на самом деле и есть ее как бы суть работы. Ну и когда мы, это первое, второе, там нету никаких там же ни моральных, никаких вообще ничего нету. То есть вот в нее загружено все, в том числе и контент, который вообще дико непотребный, если по-простому сказать. Мало того, мы еще не понимаем за счет огромного количества слоев знаний, которые там загружены, как они на самом деле там дообрабатываются, достраиваются, и на самом деле какие еще свойства приобретаются этих знаний. И вот когда мы строим системы, которые реально работают, к примеру, здесь прям целая категория таких, называется Guardrails, если кто-то слышал, практически это компонент, это тоже определенного типа моделька, это не ПО в чистом виде, это тоже как моделька, которая на вход, если пользователь пишет какой-то запрос, она сначала смотрит и так, а вообще можно ли на этот вопрос отвечать или нельзя. Или если мы говорим про корпоративные данные, как сейчас говорят, взламывают систему. Потому что у нас был, мы там одно корпоративное мероприятие проводили для одного большого банка. И банк в этот момент как раз хвастался, распиарил, что он поднял чат-бота для консультации для клиентов. И вот они ровно, их рандишники, так и сделали. Они взяли, просто подняли большую модель, воткнули опишку в чат-бот, прикрутили небольшие данные. Мы им показали, как за минуту это взламывается. Мало того, что взломалось. Просто тупо за счет того, что там нет защитных механизмов, мы получили доступ к системной директории сервера. Просто за минуту. Там куча всего. Именно нюансов. Есть целые компоненты, которые конкретно помогают делать защиту как на вход, так и защиту на выход. Потому что модель тоже может определенным образом ответить, допустим, несоответствие ФЗ. Вот все, у нас должен быть защитник, который нам позволяет не давать это делать. И тут весь зоопарк большой дальше, к примеру, есть специально проработанные компоненты. Когда мы загружаем любой тип материалов, PDF, Excel, картинки и так далее, на самом деле есть специальные компоненты, которые берут Excel, ее специальным образом подготавливают, переводят в векторное состояние, чтобы в эту модель отдать. Это отдельная библиотека, которая должна быть. Я сейчас там все детали раскрывать не буду, но смысл в том, что если мы хотим, чтобы у нас эта система хорошо работала так же похожим образом, как OpenAI и ChatGPT в вебе, то на самом деле нужно очень упрощенный зоопарк этих компонентов поднять. И это, наверное, одно из таких базовых заблуждений, на которых все ближайшие два года рынок начинает дальше, когда мы слышим, это не работает, это плохо работает, или эти все системы, какие-то ай-яй-яй, их невозможно внедрить. На самом деле он выражен чаще всего в том, что просто уровень непонимания тех людей, которые это внедряют, даже в мире, даже достаточно большие корпорации, то есть оно очень там прям слабое. Нормально, двигаемся дальше. Ну, тут просто какие-то элементы простые, я их там буду показывать. В принципе, чтобы какая-то система, которую вы хотите встроить в бизнес-процессы или с пользователем, чтобы она работала, у меня есть определенные категории вещей, с которыми придется разбираться. Есть инфраструктура, ну вообще сервера и как это все разворачивать. Есть вопрос о том, а какие мы вообще поднимаем языковые модели, какие они, как их настраивать. мы их хотим по API взять или хотим их на сервер везнуть и так далее. Есть слой работы с данными, а как мы в эту систему поставляем данные, чтобы она работала. Ну и дальше на самом деле вопрос вообще самих интерфейсов и взаимодействия. Потому что если сейчас вас спросить, как вы относитесь к тому, что такое большая языковая модель, на самом деле, точнее, или сервисы на нем. На самом деле большая часть людей это воспринимает, что есть чат, в котором мы с ней общаемся, И максимум, в чем нам надо разбираться, это промты, какие мы пишем. Это прям вот супер важно, это самое главное, что из себя представляет модель. Ну и окей, кто-то, кто посерьезнее разбирается, видели там эти Nainton или Workflow системы, которые позволяют кубиками собирать несколько агентиков, но там точно везде все равно это моделька и промт. Это такое, но очень дилетантское представление об этом. То есть, когда мы говорим про интерфейсы, допустим, есть профессиональные интерфейсы, так называемые agentic first, в которых вообще UX или сам интерфейс работает абсолютно вообще по другим принципам. Когда, к примеру, он может генериться гибридный интерфейс, которым просто само, если кто-то разработкой понимает, может генериться веб-система, которая в вебе генерирует просто в онлайне навигацию, кнопки, вообще все, что мне нужно. И это тоже может делать система на базе вот этих инструментов по генеративному искусственному интеллекту. Когда мы понимаем под этим чисто чат-бот, в котором вы в чате что-то пишете, это на самом деле, ну только, я могу вам пример привести, это то же самое, как будто, если кто-то помнит, в 60-х годах первые, ну после перфокар, компьютеры были, и там сидели разработчики, и они в строчку в каждую вбивали, ну вот как это, программный код по строчкам, такой вот в зеленый, такие чат-ботовые. черно-зеленые, если помните экраны. И вот здесь как бы чат-ботовое, имеется в виду чатовое окно, это практически такой же уровень развития технологий. Они сейчас, прямо уже сейчас развиваются абсолютно в другой класс систем. Да, я вижу, хотели спросить. Да, а приведите пример недилетантского видения. Я приведу, я буду сейчас доходить до этого. Я пока, почему это называю базовыми понятиями, чтобы мы с вами проходили, я могу показать пример, как выглядит, это просто напугать вас, это не то, что мы сейчас будем разбирать, когда мы говорим, как выглядит серверная система, которая просто слой инфраструктурный в серверной системе. То есть там прям достаточно большое количество слоев, которые мы должны делать. Ну ладно. Я вам в раздатки потом пришлю, я не буду это скрывать. Давайте, давайте. Хорошо. Это мы сейчас просто… у нас один из проектов есть. Мы делаем NeoCloud с Neobius. И мы как раз разбираем, какие вообще там слои должны быть гиперскейлеры или клауды, которые AI-based. То есть какие в них должны быть слои, чтобы реально можно было агентные системы разрабатывать. Я, наверное, теперь как раз, вы правильно вопрос задали про то, где не дилетантский подход должен быть. То есть на самом деле здесь, чтобы в этом дальше разбираться, есть еще такое принципиальное различие, когда мы начинаем, ну все, наверное, вы слышали истории, говорят, вот там, теперь все делают агентов. А еще агентов, еще и все называют, что каждый, вообще любой студент сейчас уже понаделал агентов, а уж не говоря про большие корпорации. И когда мы говорим про агентов, еще это виртуальные работники, которые еще классно рассказывают истории, что вот кто-то сел, собрал себе, значит, у него уже целый совет директоров из этих агентов, или у него уже вся команда работает, ему больше люди не нужны, он их сейчас всех уволит, или уже уволил, и вот он с этими AI-работниками работает. На самом деле есть такое хорошее категорийное развлечение, какого типа системы мы можем считать агентными, где мы все-таки используем так называемые копилоты. Что такое копилот? Это когда я имею рядом, если я разработчик, ну все, наверное, пользовались кодексом или курсором, ну или видели, по крайней мере, или код, который код пишет. Это называется копилот. Что это значит? Что это все равно мой интерфейс, я в нем пишу задание, он мне что-то делает, Он может долго что-то делать, но в итоге он все равно это задание отдает мне, и я дальше с ним что-то делаю. И копилоты могут строиться для разного типа профессий. Это может быть просто обычный универсальный копилот, как мы пользуемся ChatGPT. Это на самом деле, или ChatGPT, Gemini, Perplexity, это окошко взаимодействия, в котором мы в режиме копилота работаем. То есть он нам помогает по каким-то задачам что-то делать. Но есть другой класс систем. специально разделяют на два, наверное, ключевых класса систем, когда мы говорим про агента. Ну и называется агент. Мы как в профессиональном сообществе агентом все-таки называется система, которая может в состоянии быть какую-то часть бизнес-процесса выполнить автономно и уже скорее считаться частью бизнес-процесса, а человеку только в какой-то момент показать результат работы, Ну, чтобы дальше можно... Сейчас я покажу, что я имею ввиду. Ну и просто некоторые системы называют, на самом деле, интеллектуальными системами, которые просто как software работают. То есть, вот мы на сервере запустили какую-то автономную штучку, она работает, взаимодействует может быть там с клиентами или с каким-то бизнес-процессом, но у нее под капотом есть генеративный искусственный интеллект, который просто и помогает, скажем так, более вариативно отрабатывать разные сценарии. То есть, если там чуть попроще сказать. И различают, на самом деле, два типа агентов. Есть workflow-агенты. Что это означает? Что, на самом деле, вот это, наверное, если вы видели, N8N это называется, или NITAN, я не знаю, просто вы сейчас на модуле уже проходили эти вещи или нет, Коль? Да, да, видели. Мы в прошлый раз обзор инструментов делали. Да, вот, супер. Многие пользуются и NITAN, и, соответственно, это как, господи, лонгчейном, курсором. Да, да, ну вот. Ну то есть, как бы, Nathan, если правильно его называть, это пример как раз конструктора workflow агентов, когда вы можете собирать даже достаточно сложные сценарии какие-то, вариативные, но это все-таки еще считается, что вы этот workflow сами сели, руками собрали, настроили, и внутри в нодах воткнули эти генеративные инструменты. А есть агенты, которые, в принципе, называют уже с какой-то определенной степенью автономности. Есть даже матрица, которая позволяет смотреть, мы вообще агентную систему строим, или это все-таки чат-бот, или это workflow. Потому что есть примеры принятия решений. Интересно, потому что агентная система, она в какой-то степени может некоторые решения, опять же, заданные рамками, но принимать самостоятельно. А workflow, допустим, он работает все-таки детерминированно. То есть вы сами настраиваете весь процесс принятия решений. Или есть на самом деле принятие решения о том, как вообще должен выглядеть пошагово процесс. И вот допустим есть там системы достаточной степени автономности, они вообще в состоянии сами собрать workflow под задачу. То есть не то, что вы сели в NITN, собрали кубики, а на самом деле там автономные системы, они умеют сами такой workflow себе собрать. И так далее. Конечно, я покажу вам их. Ближе всего к тому, что ты говоришь, это то, что стоит под капотом у того же Manus, который потихонечку себе собирает этот workflow и выполняет эти задачи, грубо говоря, меняя методы, перепроверяя методы, соответственно, проверяя работоспособность того или иного метода. Да, там знаешь, как там можно разделить. На самом деле все сейчас Gemini, ChatGPT, C-клод, любые системы, которыми вы пользуетесь, у них под капотом уже встроены вот эти движки, собственно, выработки workflow. Если reasoning модели называется, reasoning это на самом деле и есть один из типов этих технологий. Я немножко… Да, у них понятно, у больших, а вот в наших реальностях есть ли такие фреймворки? Да, я расскажу, есть компоненты, это на самом деле, я сейчас про них расскажу, просто скорее я зачем вам про это рассказываю, чтобы вы… Понятно, что кто-то из вас будет пользоваться только веб-сервисами, кто-то будет сам разрабатывать. Но даже когда вы кого-то будете покупать или брать по подписке, вот эта штука важна именно сейчас для того, чтобы вы могли оценить степень профессионализма, когда вам кто-то продает агента. Вот это даже важнее, потому что сейчас 95% агентов – это тупо написанная опишка с промтом, пробитым от модели, еще условно 5% это N8N под капотом и все. И только там 0,01% реально автономных систем. Зачем я это говорю? Для каких-то сценариев это работает и нормально. Но на самом деле с точки зрения умности эти все системы, сейчас если посмотреть на профессиональный рынок, это все вообще не уровни профессиональных. Сейчас профессиональные команды собирают вообще другого класса системы. То есть это все такой дилетантский уровень, и просто сейчас в этом плане проблема огромного количества стартапов или даже некоторых корпоративных систем, потому что, в принципе, сделанная опишка с пробитым промтом, это все то, что выкидывается в мусорку. То есть это сейчас в течение года будет заменяться, ну и уже заменяется другими системами. И это не имеет ценности в этом плане, потому что любой из вас может взять промт, прибить, как бы прикрутить к модельке, и он будет работать. Поэтому это очень важно. Потому что когда вам рассказывают, что у нас тут есть классный агент-маркетолог или классный агент-писатель кода, это на самом деле, ну вообще пока по рынку в 95% случаев это ничего больше, кроме промта. А в этом плане нету ценности в этом, в этом как бы смысл. Это очень важно. Пример, что такое автономные системы. Я сейчас начну с ними выходить. мы делаем со Сбербанком, мы вместе с ними разрабатываем автономные системы разработки. То есть это Сбертех, это СБТ, это не Сбердевайсы. И у нас сейчас один из примеров, это часть процесса разработки, когда в Джиру проинтегрирован набор агентов с определенной архитектурой, которые сейчас в этой зоне конкретно что делают. Они берут из Jira тикеты с уязвимостями кода найденными и по факту делают так, что 75% уязвимостей система закрывает полностью автономно сама. По остальным 25% инцидентов она готовит материалы для архитектора или для старшего разработчика так, чтобы он мог просто быстрее это закрыть. Здесь вот, ну, собственно, показано, что это встроено в бизнес-процесс таким образом, что оно не работает в режиме копилота. Представьте, у меня, получается, берет этот агент один, он смотрит, разбирает уязвимость, и там в ситуации, если он сомневается, он отправляет тикет к жире, архитектору, чтобы тот ему подтвердил. То есть в этом плане для архитектора, что этот разработчик бы сделал, что агент, ему без разницы. Понимаете, да, то есть разницу? Да, да, да, да. И вот на самом деле, чем интересно вам как модель, чтобы вы поняли, как недетерминированные системы работают. Сначала мы с ребятами достаточно долго пикировались, потому что они пытались от нас добиться, чтобы мы давали стопроцентную точность. Ну как это привыкли в детерминированных системах. Ребята, давайте мы замерим, а сколько джун закрывает без ошибок задач, сколько мидл и сколько синьор. Мы прям замерили, а у них прям, слава богу, статистики много. Оказалось, June закрывает 50% делает ошибок, Middle делает около 70% точно, а потом, собственно, и Senior разработчик делает 80% с копейками, а в 20% ошибки делает. И вот наша система показала 85% точности. Что это значит? Что она просто точно лучше, чем Senior разработчик работает. Но при этом в чем прикол? Автономно эта система закрывает в сутки тысячу уязвимостей. А разработчик 10. Чувствуете разницу? И это примеры того, когда мы можем в бизнес-процессы вплетать куски автономных систем, но особенность в том, что мы не ожидаем, что она все будет делать сама. И мы в этом плане, если я сейчас покажу, в чем ключевая история. что мы идем от микрозадач, то есть практически смотря, какой уровень задачи может система закрыть автономно сама. Это может быть даже подзадачка. Если мы выделяем, допустим, пример процесса разработки ПО в корпорации, ну это круто, потому что если у тебя есть деплоймент процессного разработки, в котором все сидит, допустим, на джире, как на тасктрекере, то ты можешь микрозадачки брать. И вот мы пошли во всех типах процессов, где мы можем на самом деле степень автономности не дискретно, ну типа или автономно, или не автономно, а вот собственно какой тип задач система в состоянии закрывать между людьми. То есть чтобы оставшаяся часть задачи, она как бы называется human in the loop, по факту, ну как вот, как будто джун сидит задачку делает. Потом как будто мидл делает задачку. И сейчас у нас план к тому, что к концу 26 года практически довести до состояния, чтобы был практически только продакт, архитектор и бизнесовая команда, а весь остальной тип задач будут закрывать эти системы. Сейчас у нас на данный момент где-то уже около 40 процентов задач закрывается. Это уже дает эффект от полутора раз до два раза, до двух раз ускорения разработки. И на самом деле сейчас мы в 25 году показали эффективность, что с миллиарда рублей костов команды 200 миллионов уже экономия есть. Я понимаю, что если взять 10 миллионов долларов, годовой бюджет и с этими параметрами, то можно это все сделать за шестерку? Да, именно ровно так. Причем это собственно замеры в Сберовской команде, когда сейчас цифры называю, это уже именно результаты уже практической работы. Вот если вы слышали, что Сбер сейчас, я сейчас отвечу на вопросы, сокращает 6 тысяч работников, то вот конкретно по, это как, то там скорее единственное, Мы это делаем СБТ, это Сбертех, то есть это их компания, разработчик, который разрабатывает для самого Сбера ПО. И вот мы внутри них это все раскатали, и сейчас начинаем раскатывать уже на продуктовые команды, уже в основном Сбере. И открыток на Новый год, 6 тысяч открыток вам пришлют на Новый год. Это правда. Нет, там 6 тысяч они сокращают не разработчиков, но они их просто не нанимают сейчас, в этом смысл. Да, да, то есть просто что, да, давайте еще, да. А сравнивали вот эту систему как по эффективности, по влиянию на эффективность разработки по сравнению с курсором, с кодексом, вот этими, которые запрещены? Я сейчас отвечу, да, я отвечу на вопрос, я сейчас как раз просто развернуто отвечу, давайте, да. У меня такой философский большой вопрос, вот есть джуны, они нарабатывают ошибки, учатся, становятся медлами, потом становятся синерами, А если теперь появится нейросетка, откуда у нас возьмутся джуны, потом медлы, потом синеры? Я на этот вопрос тоже отвечу. Это не философский вопрос. Вопрос на уточнение. Я правильно услышал, система находит условно 20% ошибок и сама же их исправляет или только находит? Там SAST-анализаторы есть. Это системы не на генеративном искусственном интеллекте, которые выявляют статистические анализаторы. Они просто эти уязвимости генерят в джире тикетами. Это просто нормальный класс систем. А эта система берет эту уязвимость. В чем сейчас подвох саст-анализатора? Что он указывает место, но вообще не объясняет, в чем уязвимость. И вот там, на самом деле, первая ценность, которая вообще была принесена, что сначала как аналитик, AI-аналитик, он начинал брать и объяснять, а в чем проблема и что надо исправлять. То есть еще пока не реализовано само исправление? Не реализовано, почему? И исправление ошибок уже тоже автоматом, да? Видео, видели? Все работает. Да, да, да. То есть там как? Там почему это как раз разбито, что первое, там один агент, он на самом деле анализирует и формулирует задание, то есть что нужно исправить. И разработчик берет, смотрит задание, и там есть у задания, есть светофор, как бы зеленое точно надо исправлять, желтое непонятно, не уверен, то есть степень уверенности размечается, а красное точно я не смогу исправить, оно сразу же уезжает на синер разработчиков таской. А кто под капотом там? Какая модель? Гигачат? На самом деле без разницы, потому что сейчас я про это расскажу, потому что это как раз второй важный фактор. Сейчас отвечу на вопрос как раз про… То есть есть так называемые IDE, то есть это копилоты типа курсора и так далее. У Сбера свой IDE сделан, достаточно крутой. Это две невзаимозаменяемые системы, они дополняющие друг друга, потому что сейчас скорее из-за этих IDE, то есть вообще разработка с курсором условно, на самом деле с копилотом по разработке, она становится стандартом. Но это как раз когда мы что-то пишем, какие мы дальше, Ну, конечно, примеры, другие сценариев закрываем, да. То есть это значит, что Сбертех уже работает с курсором, и вы ускоряете поверх, или вы все-таки курсор никто не трогает? Да, да, да. У них я сейчас проникновение IDE, ну, аналога курсора не знаю, ну, да, конечно. То есть на самом деле у сейчас многих корпораций IDE встроены, разработчиков там это не стопроцентно… Это типа корпоративный курсор, да? Да, да, это не стопроцентное покрытие. Я имею в виду, что я не знаю, во всех ли подразделениях это делается. к сожалению, это не знаю, но мы с ними работаем, вот да, что идет копилот, это именно сам разработчик сидит с аналогом курсора, там есть нюансы, я сейчас хотел их рассказать. Агенты же внутри тоже есть, которые вот это могут делать. Да, вообще агенты-разработчики, это уже как бы вообще сделано везде, то есть вот этот агент-разработчик, здесь он как раз показан, вот пример, то есть вот эти агент-разработчики, они на самом деле, их у Тинька А не сделаны, у Альфы. Первый, если агент-разработчик, а если Айде. Что такое Айде? Это когда я по факту ставлю задачу как разработчик, и мне агент просто пишет код и потом его деплоит. Сейчас же курсор это больше. Там же и тестировщик, там же и архитектор встроенный. Там вот эти роли, которые сейчас обсуждались, там многие тоже встраиваются. Курсор, в чем его прикол? Это, я когда ID, понятно, что это такое IDE, это получается, ну, мое рабочее место, в котором я не сам пишу код, а я по факту, ну, в том, то есть смотрю, как пишется код. Дальше у курсора в этом плане, у него внутри вот эта вся среда автономной разработки развернута, это не как бы чистая IDE, это реально, ну, вот уже там сделано. Но в чем его подвох? Он не работает на корпоративной базе. Это ты как бы, то есть ты не можешь его развернуть, чтобы он у тебя был управляемый процесс разработки со всеми. То есть это есть некоторые нюансы, в этом надо понимать. Это то же самое, как веб-подписка на чат GPT. Ты не можешь ее сделать частью бизнес-процесса. Нет, просто не можешь. Это не нюансы. Это там на примере… В смысле не можешь? Это может быть, просто нужна как бы достройка к этому. Ты как ты делаешь это в режиме копилота. - Айда, я подключен к ГИТУ? - Конечно. - Я не вижу где. Да, конечно. Здесь почему надо в этом разбираться, потому что вот просто рассказываю кейс. Я там общался, общаемся с большими корпорациями, British Petroleum, большой, глобальный. Вот у них там архитектор, AI, литый архитект AI, главный человек по AI в БП в мире, девушка. И вот она на голубом глазу говорит: "Да мы вообще уже все AI-нейтив, вообще все, точно. У нас вообще уже все, мы галки свои поставили, трансформацию выполнили, у нас вообще все круто". Я говорю: "Расскажи". "Ну мы как, мы купили корпоративную подписку Anthropica, и у нас все разработчики сидят в курсоре. Расскажи подробнее". Ну как в смысле? Ну вот они сядут в курсоре, пишут код с курсором, он куда-то в гид льет потом результаты этого и все. Это все. То есть у тебя предел ускорения с курсором это копилот. То есть ты как разработчик не можешь им управлять как автономным процессом. То, что я сейчас показал, это другой класс систем. В этом ключевая смысл. Я не смогу сделать большую систему на тысячу человек, чтобы она реально в 10 раз быстрее писала код. Или в 100 раз быстрее. Там почему я сейчас хотел объяснить, потому что у нас сделаны дополнительные истории. Допустим, мы берем весь код в Сбере, и мы его определенным образом перегоняем в графовое векторное представление. Курсор также делает. На самом деле, когда мы пишем в репозитории код, он его создает. Но я сейчас, кому тяжело про разработку, я потом про другие бизнес-процессы расскажу. Но делаем так, что у меня есть слепок определенный кода в любой момент времени. И он именно получается в сбере, они сейчас снова обновляются. То есть каждое изменение кода, он меняет сразу именно графовое представление. И получается, когда я пишу в своей IDE, я хочу написать такую-то интеграцию, то у меня это ерунда, она сначала идет, смотрит на весь этот граф, и говорит, да слушай, уже 6 интеграций сделаны, не надо, давай, о, классно, все, давай, я вот эту возьму, она лучше всего подходит, ее допишу и тебе задеплой. Ты по факту жмешь окей и все, оно поехало. И в этом плане, когда ты правильно делаешь связанности, всякие справочники, вот эта куча барахла, которая на самом деле из мусорных данных, к которым ты никогда не можешь получить доступ, оно в итоге правильным образом в разработчиков в моменте самого, то есть в IDE получается точно все время доступ ко всему, что нужно. И он не сам руками ходит ищет, а делает. А с другой стороны то же самое, ты же подключаешь автономного агента, если у него уверенность в том, что дописать этот модуль он может сам, он по факту вообще без разработчика просто спокойно доделывает. Там сейчас разные эксперименты делаем, потому что кажется, что к концу 26-го года вот эти корпоративные системы на автономных, это называется SDLC, то есть это Software Development Lifecycle System, это будет другой класс, точнее это другой класс систем, который работает. То есть пример того, по крайней мере, как мы сейчас считаем, это типы дел или типы разработки, которые нужно делать. И тут как раз размечены разного типа агенты, которые это могут делать. Здесь выделено беленьким, это когда не требуется агента условно, это сейчас просто пишут. где-то есть отдельный самостоятельный агент, который не кодовый. Кодовый агент, и так называемый iBuddy, это те, кто позволяет тебе более сложно делать сценарий. Сейчас скорее я показываю это как иллюстрацию того, что это все на примере процесса разработки, все просто идет в таком развитии, и не одним курсором, единым в мире это все развивать. В общем, у Сбера сейчас вообще считается одной из самых автономных в мире систем, которая сделана. То есть она намного автономнее, чем практически у всех корпораций в мире сделана. Достаточно круто. Причем именно почему? Потому что у международных корпораций легкий доступ к корпоративной подписке к Антропику. Они поэтому считают, что они трансформировались, когда они купили подписку на курсор. И все. А у нас компании Тинек, Альфа, Сбер, ВК, из-за того, что мощный digital, они реально оказались где-то на передовой в мире по процессам разработки. То есть мы, зная это, общаемся напрямую с большим количеством корпораций и биг-теками тоже: с DeepMind, с OpenAI, с NVIDIA, мы видим разницу. Как мерить автономность агентов? На самом деле, это интересная история, что сейчас как их, в принципе, начинают замерять. Когда мы видим, что человек бы делал бы такую задачу какое-то количество времени это раз, и два агентная система с какой-то процентной эффективностью эту задачу закрывает. Из этого делаются замеры. Можно даже метрики успеха для агентных систем в ваших компаниях, если вы большая компания. Мы сейчас такие замеры эффективности агентных систем через эти метрики делаем. достаточно круто выглядит. Это, кстати, старая модель, надо будет ее найти новую. Там еще это уже Клоды 4.5 или какой-то. Сонет, да. Смысл в чем? В том, что в принципе сейчас уже допустим, Opus 4.5 он уже закрывает работу практически больше 10 часов разработчика. То есть это дикая скорость. И даже когда рисовали этот график в 2024 году, даже здесь они, я считаю, не угадали. То есть они думали, что медленнее будет развиваться. Но дальше на самом деле интересные есть моменты, а как могут еще работать системы, которые мы сейчас я вам про именно разработку рассказал. На самом деле можно представить, что такой же подход работает к другим бизнес-процессам. То есть это важно. Особенно если у нас есть какие-нибудь ERP-системы, типа 1S или SAP или еще что-то, то на самом деле вот эти автономные агенты, они могут работать и в других бизнес-процессах. У нас есть пример, когда мы со Сбером делали закупщиков, в системах закупок сделали такие же автономные системы подготовки закупочных процедур, в которых закупка, как человек в отдел пишет, хочу такие же скрепки, как вчера купил. Просто система берет, оформляет закупочную заявку, отторговывает поставщиков и закупщику только приносит, «Слушай, мне кажется, я отобрал вот этот закупщик, этот как бы оффер, он лучший. Соглашайся с ним, вот точно такой же зеленый, желтый, красный коридор по уверенности». И сократилось время на оформление закупки с пяти часов до пяти минут. И вот за 25-й год сейчас уже такая система, она отработала 20 тысяч человек дней. То есть сделала там вообще дикие цифры. Но единственное, только мы когда разбираем, что надо смотреть бизнес-вэлю этих систем, Потому что если это был бы не Сбер, то они бы разорились, потому что они поняли, что они просто это не закупали, ну и не тратили косты. А эта система просто там какие-то дикие цифры по торговке закупок показала, которая в принципе непонятно, это дала как это хорошо это или плохо, что столько закупок сделано. Но еще там просто пример, иллюстрация, это одна из технологий. Когда мы понимаем, что у нас есть точки интеграции в разные системы в компании, Это могут быть там или облачные системы, еще. Но на самом деле, как вы, если многие из вас на этом пользуетесь. Есть пример, что может быть тип другой интерфейса, когда мы говорим, что есть текст-то флоу системы, когда я могу собрать какой-то бизнес-процесс или workflow. Не когда я сижу его кубиками собираю, а когда я этой же системе написал, короче, собери мне какую-нибудь интеграцию или какой-нибудь бизнес-процесс по закупке. И по факту эта система, спрашивав тебя вопросы, пошла и сгенерила просто бизнес-процесс, в котором она, зная библиотеку интеграции или зная другие агенты, практически просто в режиме онлайна собрала уже просто работающий процесс, который ты нажал, запустил и пошел это делать. И это примеры того, как мы не деревянные корабли строим, а как мы делаем системы I-Native. Потому что N910 в этом плане это деревянный корабль. Потому что когда тебе приходится сидеть самому, как дураку сидеть, настраивать каждую ноду и выстраивать, ты как бы на самом деле берешь и делаешь, как будто ты делаешь детерминированную старую систему. А так делать не надо, потому что, например, я сейчас показал видео, Это реально работающая система, которая генерит просто flow по твоему, и она может ее изменить, если тебе что-то не понравилось, ты написал, она тебе ее поменяла. И все. То есть в этом плане это меняет парадигму, потому что в целом мы вообще начинаем менять отношение и подход к интеграции. Потому что сейчас у нас там RPA-система или еще что-то, они нас требуют, что там реально это долго, дорого, там надо прям сидеть каждый раз продумывать. А представляете, есть система, если ты хочешь, ты понимаешь, что есть набор бизнес-систем. И ты не сидишь, не заказываешь интеграцию, которая будет через три месяца, а написал, что тебе нужно, оно там пошло, тебе собрало и пошел дальше работать. Вот это? Это одна из наших технологий. Потом покажу. Нормально? Живые? Еще? Класс, хорошо. Сколько у нас уже времени прошло? Еще есть полчаса? Хорошо, круто. Про данные я много говорить не буду. Наверное, в целом, что важно знать, что для того, чтобы эти системы работали хорошо, они должны оперировать данными не таким привычным способом, как вы привыкли с табличными данными. Наверное, все слышали слово рак системы, я думаю. Не знаю, кто-то слышал уже, разбирались. На самом деле в этом плане тоже есть такая особенность, что когда технологии реально убегают очень вперед, а на рынке, продолжая использовать их как информационные технологии, начинают уже использовать устаревшие технологии. Что такое классическая рак-система? Сейчас, наверное, не буду про это детально рассказывать. Но что важно знать, что в больших языковых моделях в них загружены знания, так называемый common knowledge, это имеется в виду все знания про мир. Но если вы хотите, чтобы большая языковая модель оперировала знаниями про компанию или про индустрию, или знаниями какими-то вообще про конкретного пользователя, конкретную ситуацию, то на самом деле нужно иметь определенного другого типа системы, которые будут позволять эти данные в эту систему поставлять. Это оказывается сейчас для генеративного искусственного интеллекта, для систем вообще просто необходимым элементом. Если вы хотите, чтобы у вас что-то круто работало, то вам нужно специально делать другие системы, которые бы позволяли поставлять как источники знаний в большие языковые модели, какие-то корпоративные знания и так далее, определенным образом подготовленные. И сейчас, когда мы говорим про все RAC-модели, значит, ладно, давайте не буду это грузить, мне кажется, это сложно. Интересно? Ладно, хорошо, тогда простой скажу. Короче, когда мы говорим про данные, чтобы большая языковая модель могла ими оперировать нормально, то мы можем брать ваши обычные табличные представления, ну или текстовые документы, ну вообще обычно, где у вас хранится все, в конфлюенсе или в базах данных, или просто файликами на сервере, то мы на самом деле должны взять эти все данные и определенным образом перевести их в те представления, с которыми может работать большая языковая модель. если по-простому сказать. Классический в лоб подход – это взять и все это перегнать в векторные матрицы, которые я до этого рассказывал. На самом деле сейчас, когда делают рак системы, это просто тупо системы, которые берут все данные и перегоняют их в векторную базу данных, из которой уже дальше большая языковая модель может брать нужные ей данные, находить их, скажем так, более легко. На самом деле этот подход сам по себе, если его воспринять как систему, это не программное обеспечение. Когда вам кто-то говорит, что я вам сейчас продам RAC систему, он в этом плане или сам не понимает, или вас обманывает. Потому что просто подход к перегнать данный вектор есть, но чтобы система хорошо работала, нам надо еще, чтобы много разных вещей было. Первое, как делать так, что если у вас каждый час обновляются данные? То есть это должна система уметь не один раз перегнать вектор, всего, просто постоянно делать апдейты. Это первое. Второе. На самом деле, когда мы просто берем в лоб все данные, представьте, собственно, с чего мы со Сбером или еще с несколькими нашими… Ну, а там без разницы, их там несколько, квадрант, манго, там, манго или как это называется. В этом плане сами векторные базы данных, это как open-source сейчас в мире. Не, вообще, да, это там… Тут я как раз к чему сейчас веду, да, что на самом деле, когда мы начинали смотреть, то есть как сначала начинали делать. То есть брали все данные Сбера из конфлюенса и превращали в векторное представление, дальше к нему уже обращались. И там начали такие интересные эффекты всплывать. Оказалось, что, допустим, в Сбере есть шесть разных регламентов по одной теме, которые просто конфликтуют между собой. И эта модель, когда она вытаскивает из векторного представления, она просто любой ответ дает, как бы все время случайно выбирает, то есть это ненадежно. Или когда мы делали то, что, ну и там, к примеру, есть регламенты на разные периоды жизни. К примеру, у нас есть там закон, который был за 24-й год, он поменялся с 25-го года, стал другой. На самом деле, когда мы это все перегнали в лоб в векторное представление, в этот момент этой системе вообще без разницы, она не понимает как бы 25-й год или 24-й, то есть она будет делать разные ошибки. Оказалось, что архитектура, которая нужна, чтобы мы могли подавать системы с большими языковыми моделями, она чуть сложнее. То есть ее нужно тоже развивать. И сейчас, можно сказать так, что готовых решений, которые вы бы могли купить, нет. И на самом деле, пока по ощущениям, еще года два не появится. Потому что пока у нас есть некоторые игроки на рынке российском, как минимум, которые там ввалили недавно 300 миллионов, и вот разработали такую систему и уходят всем, продают как коробку. Она уже устарела, ее можно выкинуть в мусорку, потому что просто тупо категории технологий поменялись. И все. И вот эта интересная история, это просто надо держать себе в голове, что да, есть какие-то технологии, которые можно брать и с минимальными доработками к себе использовать, но такая скорость развития базовых технологий, потому что условно на Ачате, GPT-4 или на Квене предыдущего поколения один класс решений был доступен, А когда вышел сейчас GPT-5, к примеру, он дает вообще другой абсолютно уровень возможностей, и из-за этого приходится архитектурно менять систему. Пример это то, что мы архитектурный паттерн разработали. Это вот сейчас он один из стал стандартов в отрасли в мире. Когда мы специально раскладываем не в одну векторную базу все сваливаем, а мы на самом деле делаем векторные базы с определенными индексами, когда мы как раз, собственно, закладываем таймлэпс. То есть у нас… Домены? Да, домены, коллекции и обновления. То есть там еще плюс… Сейчас уже более сложные вещи идем. Сейчас покажу. Но на самом деле мы делаем специального агента, который, понимая под контекст запроса, то есть если он понимает, что нужно за 23 год, то он, на самом деле, вытаскивает весь нужный контекст именно конкретно по 23 году. Да, вот. Ну или там, на самом деле, в чем еще прикол оказался детерминированных систем, что можно давать специального агента, оркестратора, который будет принимать решение, как ему по доменам разложить. То есть не я руками предлагаю, а вот он прям еще сам принимает решение, как раскладывать. Ну и на самом деле, как бы очень важный элемент систем, которые должны работать... Да. Ну, вообще, да, ну, вообще, это, как бы, одна из задач, там даже интереснее на уровне, как бы, именно страны конкретно, да, то там три задачи надо решать. То есть, первая, это на самом деле, ну, языка, то есть, потому что в чем, как бы, ну, опасность больших языковых моделей чужих дипсик, Мы сейчас с Минпросвещением участвуем. Да, да, причем это прям серьезно. У них у АПНА это прям ЦРУ, отдел сидит, который грузит прям отдельные по куче разных событий и датасеты идеологические. У китайцев то же самое, на самом деле. У них там везде спецслужбы, просто тупо под контролем все большие языковые модели. И сейчас одна из задач это достраивать слои систем, которые бы выдерживали национальные интересы. Это помимо всяких регуляторки и всего. Я думаю, сейчас госсектор доедет, просто они будут давать свои системы, которые будут давать регламенты, документы, еще что-то именно в таком виде. То есть, по крайней мере, мы с ним просвещение, сейчас даже на одном примере мы с ними по истории сейчас первый такой проект делаем. То есть мы когда берем практически весь, кто в Мединске написал учебники истории, российский. В принципе, круто они сделали. Мы из него делаем практически векторную базу, как семантическое ядро, которое, в принципе, оно, причем в чем прикол, не просто для учеников или для исследователей, оно является точкой правды. То есть, когда тот же самый ЧАД-GPT отвечает на какое-то историческое событие, то эта система просто проверяет и может верифицировать, говорить, правда он сказал или нет. Прямо прикольно. Это сейчас будет во весь рост это все развиваться. Причем, это особенно у средних стран, ну, все, ни Китай, ни США, да, то есть это задача, которую придется практически всем решать в ближайшие, там, пять лет, вот. Но для компаний, то есть если вот заканчивать, да, что есть вот такой тип именно решений, которые на самом деле позволяют использовать все источники данных и определенным образом их подготавливать и делать так называемые AI-ready для того, чтобы дальше можно было использовать в бизнес-процессах. И это вот, ну, если мы хотим с вами делать профессиональные то такие классы систем надо уметь в итоге развивать. Теперь последний блок про агентов. Я почему-то показывал вам, что на самом деле, как сами бизнес-сценарии, они в итоге динамические, должны быть динамическими, потому что мы с вами живем в мире, так как когда мы пишем код, то нам приходится хардкодить сценарии в коде. Если мы это делаем, или ERP-системы, они нам дают какую-то вариативность, Но в целом это как бы, ну, почему детерминированность называется? Она в том числе в том, что мы продумали бизнес-процесс, переложили на кубики, кубики переложили в системы, и оно все как бы очень меняется с человеческой скоростью, там, годами и так далее. На самом деле эти системы, если их правильно настраивать, они позволяют, ну, практически менять процессы с дикой скоростью, с другой. И на самом деле, если мы говорим про системы, которые позволяют запускать симуляции или Digital Twins, не промышленные, а именно от бизнес-процессов, то есть категории агентов, которые на самом деле что делают? То есть мы говорим, что сейчас N8N работает на режиме, когда система собирает workflow, и дальше мы пользуемся. А если мы достраиваем модули, которые умеют давать фидбэк и оценивать эффективность этого процесса, потом есть агенты, которые накапливают лучшие практики. И на самом деле сейчас есть класс систем, который может отладить бизнес-процесс просто за минуту. То есть сделать его таким образом, чтобы он работал хорошо. Не когда мы людьми месяцами это делаем, а практически все это системы, которые могут динамически бизнес-процессы сразу делать их теми, которые должны работать круто. К примеру, я могу привести пример конкретно бизнесовый. Селеры продажи на маркетплейсах. Там есть одна из задач, это управление рекламными компаниями. Особенно, когда у селлера больше 100 СКЮ, но больше 100 товаров в личных кабинетах в Айлдбери, САЗОН, если мы про российский говорим, а в Амазоне, в мире абсолютно такая же ситуация. И вот там ты как бы, получается, сейчас, когда ты наручную управляешь рекламной компанией, то на самом деле сейчас это в голове у менеджера, который руководит категорией, он там сам как-то вручную пытается снизить стоимость, повысить, ну в итоге добиваться. Вот у нас сейчас сделан класс систем, который практически на себя забирает полностью отладку рекламной кампании. То есть получается, что у менеджера есть такой условно копилот, которым менеджер примерно просто говорит, ну куда ему лучше там маржу или остатки вымыть. И дальше эта система просто тупо в онлайне за несколько минут отлаживает и все время переделывает стратегию поведения на Wildberries. Пример просто такой. Это, наверное, где-то можно сравнить с роботами, которые делают торговлю на бирже. Например, сейчас же это алгоритмическая торговля акциями или ценными бумагами. Это уже всем привычно. Представьте, что то же самое можно сделать при торговле на Marketplace. Сейчас по факту делают люди вручную, принимают решения. У нас там есть такой класс технологий, и там в разных бизнес-процессах можно похожие вещи делать. Можно вопросы? Она, когда отлаживает, она симулирует и прогоняет? Или она прямо в бою смотрит, что происходит? Там у нас и так, и так. То есть, на самом деле, она в бою, в том числе, смотрит, но просто, когда она сначала отлаживает просто на опыте, смотря какая реакция идет, ну, там, опять же, если накапливается уже опыт, то она, когда ты ее в следующий раз запускаешь, она уже берет лучшую, ну, как бы она начинает не с нуля каждый раз, а по факту беря каждый раз из базы, а какая была до этого лучшая стратегия. Но в чем отличие от ML решений? Это, наверное, супер важно, потому что, в принципе, на самом деле роботы, торгующие на бирже, это все ML. Это все обученные модели предыдущего поколения, поэтому они работают хорошо на исторических данных, но какие-то отклонения, которые были не обучены в истории, они, собственно, на этом разоряются все. А эта система как раз смотрит не только на исторические данные, она, на самом деле, оценивает разные контексты, которые ты в нее загрузил. и может принимать решения, то есть уже не обязательно на исторических данных. Это, конечно, супер круто вообще. Это ощущения другие совсем. Нет, я не знаю. Я не в курсе, просто мы конкретно это не смотрели. Есть большие мировые кейсы, когда, допустим, такая система предсказывала, кто победит на выборах США про Трампа. Она же прикольная, она там только в двух выборщиках ошиблась. Она была прям очень красива. Ну вот. Ну, короче, если что, наверное, в детали вдаваться не будем, потому что есть определенного уровня то, как вы можете в организации настраивать у себя, ну там слово платформа громко звучит, но на самом деле, то есть как можно организовать инфраструктуру AI, чтобы если у вас там несколько команд или еще что-то, то есть как делать так, чтобы у вас, ну можно было эти сценарии втаскивать в бизнес-процессы. То, что мы сейчас видим, на самом деле, если правильно развернуть инфраструктуру, то это, конечно, дает, ну, во-первых, уже мы там видим по результатам, по внедрениям нашим, что это от 30 до 50 процентов экономия просто на стоимости внедрения этих, точнее, как бы на сценариях, имеется в виду, что мы потратили денег меньше на то, чтобы обкатать какой-нибудь бизнес-сценарий, ну, с используя им агента. И, ну, там супер большая скорость внедрения, все это тоже надо с этим разбираться. Вот, ну и, наверное, важная история про то, где сейчас там блокеры барьеры основные по внедрению систем таких, что на самом деле первое, это огромное заблуждение, что это IT-системы и на самом деле самое главное обычно, как блокеры, это IT-директора или R&D-отделы, но опять же там в зависимости конечно от майнсета, потому что у большого количества ребят они считают, да мы все сами разберемся, зачем нам находить кого-то эксперта снаружи, вот у меня NLP инженеры есть, мы во всем разберемся, все сделаем. На самом деле это огромная сейчас яма в компетенциях, потому что IT-команды, NLP-инженеры ничего в этом не понимают, точно так же, как и любой из нас с вами, но при этом у них очень большая, как у любого айтишника, желание все самому делать. На самом деле огромное количество каждую неделю выходит классных решений, интересных, которые, как спрашивали про векторные базы данных и так далее, там прямо есть целый ландшафт систем, которые или в опенсорсе выходят, или коммерческие, и в этом особенность, что сейчас это с очень большой динамикой каждую неделю меняется. И на самом деле R&D команда внутри банка, она не в состоянии успевать за этим всем. И вот надо как бы выстраивать, думать, а как правильно организовывать работу, чтобы реально все время знать, а как сейчас это будет. Потому что то, что мы видим на работе с большими корпорациями в России сейчас, с Билайном, с ОТП банком, на самом деле приходится их именно сворачивать с этого типа мы все сами, мы умнее всех, или там два варианта, или мы все сами напишем, или типа нам ничего не надо, мы сами все разберемся. Конечно, это так пока не работает. То есть это надо как правильные связки выстраивать. Ну как это, нормально, живые, да. По предыдущему тезису, то есть я правильно понимаю, что сейчас оптимальную стратегию вы видите, там внедрение, так скажем, АИ в компании, это вот как раньше было, когда про data governance, Сначала надо было набирать консультантов, которые бы все сделали, а потом же спустя некоторое время эта экспертиза станет общедоступной. Взращивать ее в конкретном контуре. То есть сейчас такой же подход. Да, но сейчас еще хуже подход, потому что консультанты точно так же ничего в этом не понимают. Надо понимать, что это как бы экспертиза. На заре всего этого ML, Data Quality, Data Governance тоже была одна книжка, Дэмбок. Да, да. Но тут скорее я бы назвал это именно правильно быть участниками профессионального сообщества. Потому что на самом деле, вот у нас в России, что сейчас получилось сделать, то есть есть команды Сбера, Тинька, там Альфа, еще несколько. И вот там как на уровне именно R&D лидов, которые открыты, но они достаточно круто сейчас. Вот у нас там ребята прям личной персоналии, то есть они даже какие-то некоторые фреймворки собирают совместно, еще что-то делают. Здесь просто надо скорее увидеть, а где вот это профессиональное сообщество, которое будет как минимум фронтир показывать, а потом уже от него дальше решать. Потому что, что важно сейчас, не большая тройка, не экса, у них нет этой экспертизы, потому что у них она была в прошлом переделе, а в этом переделе у них нет. Они при этом очень классно… С такими скоростями и с таким изменением как осуществлять архитектурный контроль? На самом деле сейчас есть два инструмента. Есть сейчас уже где-то определенный ландшафт, который по крайней мере мы его с командами большими и российскими и не российскими примерно сейчас поняли категория ландшафт. На самом деле, что это за тип компонент, как он встраивается в дата-слой и во все остальные системы. Уже он проявился более-менее. Я думаю, что он только... Компоненты будут меняться, но в целом ландшафт уже можно его видеть. А второе - это нужен просто архитектурный комитет, как мы, по крайней мере, сейчас решаем. В Beeline или в нескольких... Мы просто на архитектурный комитет точно вытаскивается кто-то из внешней экспертизы, но у кого мы понимаем, что он в этом сечет. То есть я думаю, если у вас есть, особенно в корпорациях, есть архитектурный комитет, вот, да, это прям очень хороший формат, нам нужно просто кого-то, условно, доверенного кого-то, то есть мы понимаем, что есть человек какой-то конкретный, или представитель компании, который просто позволяет приносить постоянно, там две функции, то есть одна это просто постоянно приносить и разбирать хотя бы раз в месяц, а что там поменялось, То есть из этого смотреть и второе, просто до фронтира догнать мы это называем. Независимый – это хороший рассказ. Да, да, да. Это сейчас очень… У меня просто сам возглавлял комитет по цифровизации в MR Group 5 лет. И знаете, это было очень классно работало, потому что мы, получается, вот устроили. То есть мы за счет того, что есть независимый, но с правильной мотивацией человек, то это прям очень круто работало, все хорошо. Я сейчас хотел, наверное… Да, давайте, да. Вы рассказываете все на примере каких-то грандиозных корпораций. Я тоже подумал, что надо так говорить. Если ближе к масштабам бизнеса более мелкого, не такого крупного. На самом деле, в чем интересная магия, что вообще я считаю, что, конечно, для малого бизнеса это даже более драматически улучшающая штука. На самом деле, что по факту это небольшой команде или небольшому бизнесу, у которого нет возможности кучу народу нанять, это скорее дает больше эффекта. И я здесь просто рассказываю корпоративные истории, ну там интерпрайзные, архитектурные, но в целом, если посмотреть на ландшафт систем, то он как бы агностик к стоимости. То есть это если как просто вам, наверное, меньше, то что корпорации надо ввалить деньги в он-премис структуру, то есть по факту сделать свои дата-центры, развернуть это в корпоративном контуре. А если у вас небольшой средний бизнес, то у вас нет таких ограничений и вы можете это построить все условно на облачной теме. Оно будет очень дешево в этом. Но именно ментально надо эти элементы все равно все понимать так же. То есть набор элементов такой же, только попроще. Да, просто вам не надо их все покупать. Вы спокойно понимаете, если увидите, условно вам какая-нибудь там история с тем, чтобы данные, ну, там, работать с данными, да, есть прям открытые облачные сервисы, вы условно подписку купили, прицепили к вашей CRM-ке и пользуетесь. То есть вот там просто надо скорее там понимать, как это работает. Я хотел прям вот перед тем, как в какие-то другие вещи залезть, рассказать, ну, там, резюмировать, на самом деле, в чем, в чем как бы суть того, что я рассказывал, ну, такая, вам, чтобы вы это смотрели как метафору хорошую. Если смотреть на персоналы с примером рынка электричества, представьте, как будто у нас с вами какой-нибудь 1910 год. Электричество мы уже вырабатывать научились, но предположим, что это гидроэлектростанции. Что такое в этом плане GPU и сами ЛЛМки? На самом деле GPU это условно турбина, из которой вырабатывается электричество. А большая языковая модель, когда генерирует именно ответы, это можно... А вы видите на экран, пожалуйста? Не видно. Не видно, что вы пишете. А я не знаю, когда. Это просит. Да, да, вот. Ну да, то есть получается, что, представьте, что ЛЛМ, как будто мы на турбине сгенерировали электричество, там же прямо на гидроэлектростанции. И оно это там, электричество, что такое? Это постоянный ток, нестабильный, непонятно как работающий. Но ты, как бы, слово inference, вы все знаете, да, это по факту, это когда большая языковая модель, отвечает токенами. Токены это не криптовалютные токены, а просто так почему-то одно и то же слово используют, по факту кусочки слов, ответов. И вот получается, когда мы получаем чистый ответ от LLM, это можно назвать, что это как будто электричество, которое прямо сгенерилось на вот этой турбине, на гидроэлектростанции. На самом деле тот класс систем, который я вам рассказывал, это класс систем, что нам нужно теперь взять и это электричество довести до розетки. И вот в этом плане нужен еще набор технологий, который как трансформатор сделал из постоянного тока переменной. Чтобы он сделал так, чтобы людей не убивало током, пока он туда едет. Еще, на самом деле, мы с вами не затронули очень важный тип технологий. Это один из наших орандицентров. Это стоимость этой генерации. Потому что, на самом деле, в чем еще, кстати, забыл про это сказать, что если вы у себя на сервере развернете в чистом виде большую языковую модель, или если вы покупаете из облака GPT-5 или GigaChat, то на самом деле, если вы попробуете сделать такого же разработчика, AI-разработчика кода, то вы разоритесь. Если он начнет 24 на 7 реально работать с той скоростью, которую он делает. Потому что вы на вычислительные мощности заплатите больше в 5 или в 10 раз, чем зарплата разработчика. Это на самом деле, если просто в лоб это делать. Есть специальная категория технологий, которая снижает стоимость этого инференса в 10 раз, в 100 раз. И тогда это начинает как бизнес-кейс складываться. К примеру, у нас сейчас есть такие технологии. Мы для Beeline Plan B, если видели рекламу, тарифы, но там у них под капотом ассистенты для обычных людей. Это наши технологии, это Plan B, это наш с ними тариф сделанный полностью. И там, чтобы вы понимали, 80% вычислений делается на наших серверах. То есть когда переписывается человек что-то делает, то это не улетает в облако в чат GPT, а по факту на наших дата-центрах работает. И вот мы сумели сделать сейчас где-то около 20 раз снизить стоимость этого инференса, и у нас в итоге складывается бизнес-кейс. То есть по факту мы на человеке зарабатываем больше, чем мы тратим на вычислительных мощностях сейчас. Поэтому это тоже важно, просто вы пока в масштабе с этим не сталкиваетесь, не видите, Но на самом деле, когда мы пытаемся строить бизнес на этих AI-агентах, если они у нас начинают 2-4 на 7 потреблять серверные мощности, то на самом деле в лоб экономика она убыточная. Это, собственно, еще один из серьезных барьеров, и его надо уметь и делать. Но если заканчивать, что есть категория технологий… А как вы меряете износ видеокарт? Что еще раз? Износ видеокарт как вы меряете? Мы пока амортизируем просто. Если мы говорим про расчет дата-центра нашего, то у нас понятно, что там есть более категорийные вещи. К примеру, мы можем определенный сценарий или модель запустить на B200. Это карты, сервер, который стоит 500 тысяч долларов. Можем тот же самый сценарий запустить на картах 40-90 на 2. Это понятно. Но пришло время обновлять H100 и B200. Нужно понимать, что он самортизировался. Ресурс, его надо как-то мерить. Интересно, как и хочется, чтобы было независимое измерение. Я думаю, там просто можно потом детально покопаться, потому что там просто идут модели амортизации. То есть когда мы просто каждый, условно каждый токен в него записывается. Я могу просто детальнее это показать. Но здесь именно важно, наверное, что, что есть этот набор технологий, когда мы просто пока большую языковую модель, inference, довели до розетки, имеется в виду до того, чтобы его подключить к какому-то бизнес-сценарию. Дальше, представьте, что если опять, давайте аналогию с электричеством приводить. Да у нас электричество где как бизнес используется? Ну в двух местах. Мы можем делать какой-нибудь электроприбор, не знаю, типа стиральной машинки. Ну или делать производственную линию, как Форд сделал. У Форда же, вот он сделал когда-то там в начале 20 века, конвейер, но в чем как бы был подвох, да, потому что у него конвейер работал на электричестве. Но смысл в чем? Или мы сделали производственную линию, И вот здесь аналог того, что я вам показывал по автономной разработке, это аналог конвейера, в котором мы как бы перестали, как это, каждый человек молотком делать что-то сам, а построился конвейер. В чем как бы смысл, что есть второй тип технологий, как везде нужен по факту тип технологий электродвигатель. Что-то, что движет электродвигатель. И вот в чем как бы смысл, что сейчас прям очень почти не понимает рынок плохо, ну и те, кто просто пользуется, что на самом деле большая языковая модель – это только электричество. Дальше его нужно сделать приемлемым по стоимости и качеству, а дальше на самом деле есть технологии, которые, скорее их можно назвать электродвигателем, и это не большие языковые модели сами по себе. Если вы как бы в AI-Shift сейчас, у нас программа с вами, вам нужно на выходе осознать это, что большая языковая модель – это просто генератор. То, что я вам до этого показывал системы, то когда мы говорим про то, чтобы сделать агентную систему, у агентной системы должен быть другой тип компонент, которые на большой языковой модели дают нам возможность написать код, сделать бизнес-сценарий. И эти компоненты не являются большой языковой моделью сами по себе. То есть они на них работают, как на электричестве, но как вот в мире, когда создавалось электричество, были отдельные компании, которые делали трансформаторы. Были отдельные компании, которые умели делать электродвигатели. И потом уже кто-то на этом строил бизнес какой-то, делал тот бизнес, который зарабатывал. И вот сейчас, когда мы с вами говорим, это три разных типов технологий. Надеюсь, это вам стало непонятнее, но хотя бы категорийно вам это развел. Норм? Сейчас мы как раз затронем, а можно обратно в презу вернуться? На самом деле, когда мы говорим не просто про усиление человека, а когда мы говорим про трансформационные процессы, как наши на самом деле AI, как именно технологии, связанные с этим, технологии связанные с искусственным интеллектом, генеративным, могут трансформировать бизнес. Мы сейчас для себя, по крайней мере, выделяем несколько вещей. То есть первое, до этого я вам говорил про инфраструктуру, которая нужна нам, и так называемый SDLC, но это именно процессы и разработки. Но есть еще другой тип. Это на самом деле работа, к примеру, с клиентом и какие-то именно по-другому работающие продажи. Что я здесь имею в виду? что когда мы говорим, представьте, если вы хотите обслуживать клиента, если вы потребительским бизнесом с потребителями занимаетесь, можно сделать систему, которая практически будет в онлайне обслуживать клиентов, но вообще по другим принципам. Опять же, это хороший большой эффект дает на больших корпорациях, потому что мы сейчас с одним большим оператором, у которого где-то около 50% обращений абонентов не обрабатывается вообще. Из этого очень понятные потери, огромные для бизнеса. И вот там такого типа системы позволяют вообще в принципе убрать такой класс, как не ответы на абонент. То есть каждый абонент точно всегда будет обрабатываться обращение и что-то с ним делаться. Или, к примеру, когда мы говорим про слой обработки дальше обращения, это прям совсем бизнес-кейс, что при помощи такого типа систем мы добиваемся, если раньше, ну, к примеру, там шел какой-то, ну, какой-то шел сбой в сети телекома. Ну, там что-то начинала, какая-нибудь сотовая станция плохо работает или еще что-то начинает. На самом деле в таких ситуациях, там, ну, прям за несколько дней, за неделю можно потерять, ну, прям сотни миллионов рублей. То есть там прям могут быть большие потери. И вот в старом процессе, на самом деле, система, которая начинает принимать обращения до начала исправления инцидента, замеряется от недели до двух. И вот за эту неделю-две идет потеря в какие-то сотни миллионов рублей. И вот мы сейчас делаем процесс, в котором в моменте, когда инцидент мы отлавливаем, человек жалуется или человек, или организация, то инцидент начинает за минуты уходить в обработку. То есть это, ну если вот мы с вами разбираем любой бизнес, представьте, что у вас там у кого-то, может быть это не критический процесс обслуживания клиента, а на самом деле у многих компаний это важная часть. И вы просто понимаете, какие потери вы несете. Вот такие системы позволяют вообще просто тупо взломать процесс, вообще сделать другим просто. Потому что вот в таких как бы больших компаниях там стоимость потерь на обслуживание клиентов, она просто колоссальная. У них это называется cost to income. Нормально или уже сложно? Сейчас прям последних пару пунктов и все. И есть другой разрез того, а как мы можем строить уже именно коммерческие отношения с клиентом. То есть, слышали, если вы такое понятие сейчас агентная коммерция или Agentec UX. Кто-то видел, как в чате GPT можно делать продажу, но сейчас в Амазоне можно что-нибудь купить через чат GPT или в Perplexity. Представьте, на самом деле смысл в том, что сейчас это агентная коммерция, агентная история будет просто стандартом. Мы уже видим, что если можно правильно построить с человеком, с потребителем именно так называемый agentic first UX, в котором или продажи, или его обслуживание сделать вообще абсолютно по другому принципу. Не когда он в чате пытается что-то в телеге писать, а когда вы практически выстраиваете проактивное взаимодействие. Вот, к примеру, у нас сейчас сделана уже технология, что на одной из наших поверхностей человек может спокойно во вкусвеле просто полностью собрать корзину, точнее ему агент собирает полностью корзину, которую нужно, делает чекаут, принимает оплату и организовывает доставку. Все это все делается примерно так же, как это в чат GPT работает. И вот там у нас еще в одном из проектов через такого типа системы у нас получилось добиться стоимости привлечения пользователей в пять раз ниже, чем обычная компания закупала трафик, привлекала клиентов. То есть у нас сейчас, мы в Казахстане в одном проекте у нас получилось добиться такой системы и в России. То есть у нас на одном из проектов, ну ты что, он пилотный был, мы не на очень большой аудитории, но мы уже увидели в 5 раз дешевле стоимость привлечения. И сейчас у нас там, условно, принято несколько миллиардов рублей рекламы. Просто представьте, раньше, условно, эта компания тратила 2 миллиарда рублей и получала условно x пользователей, а сейчас она на 2 миллиарда рублей получит x5 пользователей. То есть это вообще другого типа системы, которые сейчас только в мире осваиваются, как они вообще будут выглядеть, как они работают. Единственное, что понятно, что именно агентные системы коммерческие, это те, кто по факту являются разрушителями, атакерами на платформенные бизнес-модели. То есть на самом деле самые основные, кто сейчас теряет на этом, это маркетплейсы и e-com. Потому что, в принципе, можно делать достаточно серьезную большую часть CGM клиента, вообще не уходя в маркетплейс, а просто по факту используя только чекаут от него и все. Да, да, да. Вот я на примере вкусвилла говорил, мы просто с ними это построили. То есть мы, в принципе, все, закрываем весь путь выбора товара на e-com в вкусвилла. Просто в нашей поверхности он не ходит во вкусвилл. То есть я у себя, ну, представь, я у себя в аналоге чата GPT написал, хочу там кисленькие подгузники. И эта система собрала корзину, показала мне, меня в моем интерфейсе, сказала, вот смотри, я собрал, я говорю, да, мне годится, а дальше все, оплата по моей карте, доставка, все это уже дальше сделалось, и все. То есть я не ходил на вкус в этот момент. Или я то же самое сейчас делаю с Wildberries, то есть я просто перестану ходить на Wildberries и буду полностью подбирать себе товары. А промо и лояльность как в таком случае обыгрывает агент? Ну, то есть скидки на накидки, вот эти вещи, вы как побеждали? А это все, на самом деле, вот это все модели, это все как бы модели платформенные. А в агентных моделях там может быть вообще другая будет система лояльности и промо. А промо вообще не нужна будет, потому что это все, на самом деле, из прошлого века, да, то есть зачем мы делаем. Поэтому тут пока это все отлаживается, но точно, к примеру, особенно атаковаться будут те отрасли, где, как мы видим, два сейчас примера, это там, где нужно частотные делать покупки, ну как там, Яндекс.Го с Яндекс.Едой, вот там самый под ударом, на самом деле, одни из первых. И с другой стороны, наоборот, те отрасли, где надо было делать уникальный подбор, это там мебель, техника, там еще что-то, то есть это суперкруто, эти системы это все делают, делают подбор. А в Тревеле есть у вас какие-то примеры реализации? Я не вижу, где. А, вот, да. Ну, мы сейчас делаем с тревелом. Есть, есть. Нет, тревел, кстати, это вообще топ-1 отрасль, которая дисраптится. Ну, потому что это уже и так видно, что чат GPT с Gemini практически убивают Booking.com прямо в моменте. То есть там, если вы посмотрите сейчас, какой отток идет снижение трафика на Booking, то есть чекаут и бронирование отелей через Gemini идет и через чат GPT. Неправильно, выбор отеля. То есть, потому что они не на букинге делают, а по факту… Джейми не вообще просто по факту через Google Travel делает, потому что у Google же свой сервис по отелям. – Ты же заходил в эту сторону здесь, просто сейчас пока не показывал. Это тот концепт, который обсуждается, и я его поддерживаю. По-моему, даже в антигравите реализована какая-то штука, когда у тебя в этом смысле интерфейс, по большому счету, на лету настраивается, пишется под тебя. Причем помнишь, что у тебя был прекрасный проект Луна, я считаю, что он был уже не взлетевший То есть лично мне, как же персонально обидно, что он не взлетел, но там было про обстоятельства, там не про вас Это тот же самый подход, который ты говорил, что соответственно там приходилось ручками собирать индивидуализированный интерфейс А сейчас налетует индивидуализированный интерфейс, в котором будет банкинг, бронирование, все, что в приложении видите. Он будет настраиваться вами, голос настраиваться под вас. Вы даже суперапы будете убивать таким образом? Да, конечно. Суперапом, да, кирдык. Я же вам говорил. Да, суперап сейчас это как раз то, о чем Николай говорит, что это по факту собрано вручную один раз. А как бы это liquid interface, жидкий интерфейс, в котором практически у меня собирается под ситуацию то, что мне нужно, и по факту, почему это гибридные интерфейсы. Потому что я, когда мне понятно, я генерю кнопки и картинки, ну как на самом деле здесь вот показано на картинке, а где надо, я голосовым образом, чатом и все такое принимаю. В этом смысл этих сценариев, но в них суть именно семантическая, потому что здесь за счет модулей памяти создается гиперперсонализированный опыт. Потому что здесь в этом плане это тоже такая категория технологий, которая у вас в коробке не появится нигде. Почему я это называю электродвигателем? Потому что здесь работает, представьте, модуль памяти. А как я могу для человека собрать данные? А я могу, потому что когда я начинаю с этой штукой общаться, у меня по нему накапливается опыт, и я могу его складывать в модуль памяти так называемый. Когда я в следующий раз говорю, а можно мне то, что я вчера заказывал, то же самое, только что-нибудь бренд поменять. И вот раньше мне это не было доступно, мы не могли такой сервис дать человеку. А сейчас это легко делается. Я поднимаю, что я там заказывал позавчера, меня ему, показываю заново. То есть практически все это работает. То есть, если чуть пофантазировать, мне вот видится дальнейшее развитие E-кома в широком смысле. Это некоторые AI-пригодные площадки, по сути, некоторые MCP, которые должны быть friendly для AI-агентов. Да, здесь два типа. Да, здесь будет как раз то, что я показывал. На самом деле у вас будет два типа. Это тот, кто будет представителем, агентом человека. То есть кто будет в сторону человека взаимодействие выстраивать. А дальше на самом деле это будет, собственно, agent to agent connect. То есть то, о чем вы говорите. То есть это скорее банк, мы просто на примере банка это разбирали. Банку надо не пытаться атаковать, как бы становиться агентом человека, потому что на самом деле человек банку не доверяет. А вот как бы создавать агентный интерфейс, который может быть подключен к агентной сети и по факту быть одним из агентов, которые включены, это вот ровно оно и есть. Причем самым лучшим для того, чтобы персональный агент, он мог выбирать из многообразия каждого декома. И вот мы в Казахстане, мы сейчас просто запускаем один из банков, ну банк исламский с партнерами. И мы там сделали консультанта по исламским финансам. Вот, ну прям такого, ну который в широкую. Да, нет, он работает и он как раз, то есть ты разбираешься, как у меня, допустим, как я могу взять займ процентный, чтобы он соответствовал шариату, а можно это или нельзя. То есть он в широком смысле. И вот получается он как раз рекомендует тебе продукты финансовые, в том числе делая апселл нашего банка, ну и рекомендует продукты других банков тоже. И это прикольно. Мы тоже там, собственно, мы получили там и в этом проекте стоимость привлечения в 5 раз ниже, просто потому что человек начинает советоваться. Стоимость привлечения рекламы на этот сервис с учетом конверсии оказалась дешевле в 5 раз, чем просто лить трафик напрямую в банк. А вот этот персональный агент, это скорее то, что стоит уже нативно на мобильных приложениях? Ну где-то, да. Но это будут типа Алиса, Гигачат. Это скорее поверхности. То есть имеется в виду, кого человек будет воспринимать как мастер-агента какого-то. Их может быть несколько в итоге? Можно вопрос? Какие инструменты вы используете? Условно, вы работаете, какие-то инструменты разрабатываете для себя, чтобы ускорить? Вы вначале говорили про разработчиков, то, что отлавливаются ошибки и автоматически исправляются. А что-то еще для себя разработали, чтобы ускорить свою работу? У нас сейчас, кстати, я как раз и открыл пример SGR. Это один из примеров. Почитайте, погуглите, чтобы я вам там сильно не рассказывал. Это как раз один из фреймворков. Это прям технология разработана мультиагентная. То есть сейчас мы это начинали разрабатывать, собственно, как свою технологию. Сейчас она стала топ-2 в мире open-source. То есть это именно мастер-агент, ты к нему можешь собрать разные тулзы, как вы говорите, по MCP, но по факту ты или сам дописываешь других агентиков, которые делают уже специфичные дела, или можешь также по библиотеке воткнуть чужих агентов. И вот он, как технология, практически может достаточно гибко, как это называется, general agent. То есть он, в принципе, понимая любой тип задачи, он может ее как раз оркестрировать, пойти дать задачу другому агенту сделать. То есть вот такого типа технологии. Это наша технология, мы ее сделали. И у нас таких там прям сейчас целый большой зоопарк. Это что-то похожее на фабрику агентов? Или в ту сторону? Но фабрика это, наверное, не фабрика, здесь просто будут разные, вот это пример класс агентов, это как раз какой-то core движок, который является мастер-агентом, который потом на самом деле придумывает, а как мне поставленную задачу решить. И у него, если есть подключенный набор разных типов агентов, которые делают уже специализированные задачи, то он сам между ними как бы оркестрирует. Просто оркестратор. Да, но вот он, это почему движок, потому что это оркестратор слишком упрощенно. То есть такой мастер-агент. А чем отличается от MCP? То есть MCP, что же стандарт взаимодействия агентов может быть? Вы же сами ответили. MCP это всего лишь стандарт. А схема guided reasoning, там написано, framework же написано? Framework это стандарт? Там есть SGR, агентный framework. Это уже ПО написанное. Это генеральный агент. Вот, к примеру, что находится в сердце у Мануса. или в сердце у резинок модели GPT-5. Это то же самое. То есть просто ты можешь это взять, скачать, развернуть у себя и на нем настроить, чтобы оно работало. То есть вы внутри просто автоматизируете фреймворк SGR, когда ты подскладываешь туда, собственно, некоторую схему, JSON-чик, потому что проверим мне, пожалуйста, что по таким шагам прошла… Ну там это сложнее. Ну я очень сильно упрощаю. Это мастер-агент. То есть это мастер-агент, который… из зоны непонимания. Первое, что важно, куча слов, там MCP, стандарт, это не движок, это просто стандарт, это просто написанное правило, по которым один агент подключается к другому. Розетка, да. Это как раз аналог электродвигателя, то есть это я называю. С другой стороны, просто не надо воспринимать эти системы как детерминированные. То, что вы сейчас сказали, оно очень близко к детерминированными, это уже как будто я сам себе что-то написал. Дальше как раз хотел уточнить, то есть вы дошли до того, что внутрь вот этого СГР-агента генерятся инструкции в зависимости от самим агентом, ну каким-то другим. Ну там, да, там на самом деле как раз есть система, которая принимает решения, то есть первое, в нее можно воткнуть библиотеки навыков или других агентов, подключить, да, и это как бы, и она будет, зная их, оперировать ими для решения задачи. Второе, она сама принимает решение, использовать ли агента или использовать свой генеральный резиндинг движок. Но это звучит как OpenAI Responses API. То есть API для использования Agents API или Uclod Agents. То есть звучит как то же самое. Это вы то же самое сделали? Нет, я просто технически понятен. Нет, это не критика, это просто вопрос. Это то же самое вы сделали просто сами или это что-то другое? То, что описываете, там все те же фичи. Просто вы у себя не сможете их на сервер развернуть. В этом примере. То есть вы же API получаете. Я вот это и понимаю. То есть вместо того, чтобы по API забирать, вы сделали, чтобы можно было развернуться. Понятно. Спасибо. А как происходит обучение этого агента, чтобы он понимал, в какой момент какую модель? Никак. Не надо его обучать. Почитайте, откройте, там реально это в гитхабе, там все описано, как это работает. Я СГР, я знаю, что такое, я вот конкретно вот это. Ну вот СГР, если знаете, значит у вас вопросов не должно возникать. Это суть этой работы. Ну потому что там смысл в том, что как это, это схемно-генеративный резонинг. То есть получается у тебя с одной стороны есть написанные в JSON схемы, ну какие-то есть, и есть по факту дальше модель, которая принимает решение использовать эту схему, или использовать внутренние механизмы модели для резиннинга. Все. То есть вот это я очень упрощенно говорю. Просто другой вопрос, как бы как ты этот уже движок разворачиваешься. Когда мы говорим, что есть JAR, это вот наш компонент, мы его сделали. То есть это нами разработанное. А есть что-то еще, что вы какие-то инструменты внедрили, разработали? Да, я просто не хотел рекламировать, поэтому потом можем поделиться, рассказать. Много. У нас целый ландшафт. Главное, чтобы у нас для ускорения все оставались в одном информационном поле, скажем так. Это вы сейчас перенесли на язык, поэтому мы сделаем следующее. Давайте мы сделаем перерыв. Да, да, все. Он же запланирован. До 17.30. И в 17.30 продолжим вторую часть. Спасибо большое. Спасибо за... Хотел бы вы можете узнать по поводу рекомендаций и...