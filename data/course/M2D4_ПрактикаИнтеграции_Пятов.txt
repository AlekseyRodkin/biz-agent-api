Продолжаем тему Соответственно, которое связано с инфраструктурным слоем Необходимым для того, чтобы все вот эти машинки, про которые мы говорили, работали Соответственно, построение систем хранения, обработки, анализ данных В контексте и трансформации это то, про что мы поговорим здесь сейчас с Алексеем Алексеем Пятовым Мы, как сказать Давно Разговариваем и в этом смысле Мы говорили про это И в классическом виде И вот сейчас будет интересно Как твоя гипотеза, что меняется В этом слое для того, чтобы Можно было развернуть искусственный телек Здесь инфраструктурные прям вещи Которые всем нужно знать И Во всяком случае про них думать Потому что потратиться придется куда-то сюда если мы системно все будем разворачивать, правильно? Все так. Нужно будет сюда понести, это будет основная статья затрат, которая будет в строчке вписана, когда мы будем к этому системному переходить, то будет, там строчка будет называться «Построение систем хранения, обработки и анализа данных». И напротив этой строчки будет написана цифра. Про цифру тоже поговорим сегодня. Да, значит, соответственно, поэтому, как они строятся, как разворачиваются от маленького к большому, если у тебя это сохранилось, мы хорошо про это поговорим. Вот очень прикладной анализ, потому что без этого работать вся остальная система будет плохо или не будет вообще. На системном уровне не будет так. Поэтому в эту сторону мы с Алексеем поговорим. У тебя опыт в разных компаниях есть, поэтому есть с чем сравнивать. Давай начнем. Алексей Пятов. Давайте поприветствуем докладчика, чтобы, так сказать, За то, что в воскресенье нам с Вадово суприти. Добрый день, коллеги. Доброе утро. Тут немножко про меня... Меня слышно, да? Кажется, да. Немножко про меня написано на экране. Я сейчас отвечаю в компании Курос Консалтинг. Есть такая замечательная фирма-интегратор-консалтер на рынке в департаменте аналитических решений за развитие бизнеса, связанного с этим направлением. Ранее до этого я выступал в роли заказчика и даже в роли аналитика. В таких системах обработки данных был и в роли вендора, когда в американской компании SAS еще до того, как стала ИИ, в принципе, модной аббревиатурой. Мы создавали эти системы в банках, страховых, ритейле, с точки зрения контроля медиапространства и так далее. Посмотрел на эту историю с разных сторон и кажется, что есть некоторая насмутанность, которой хотелось бы с вами поделиться. Собственно, почему хотелось бы вам чуть немножко ниже опуститься туда, в такой инженерный слой, то есть фундаментальный, на котором стоят все те модные современные вещи, о которых вы говорили на последние дни, я посмотрел на вашу программу. Наверное, я такую аналогию попробую вам сформулировать. Вот кто из нас водит машину? Что мы делаем, когда хотим куда-то поехать? Мы садимся, мы нажимаем кнопочку, ну или там поворачиваем ключ, беремся за руль, переключаем передачу, нажимаем педаль. То есть мы используем некоторые интерфейсы для того, чтобы взаимодействовать вот с этим болидом, который должен поехать туда, куда мы хотим, и, собственно, помочь нам достигнуть нашей цели. Представьте, что вы пришли в гараж или на парковку, и у вас вон там несколько колес валяется, там руль, тут уже бензина разлита, там он вау. И теперь как бы как с этим куда-то поехать? Ну нужно что, как бы сгрести все это в кучу, ладошками бензин набросать, и оно дальше куда-то поскачет? Нет, да? То есть вам нужно, чтобы вот этот автомобиль, он был, и у него были какие-то ручки, за которые можно его дергать. Чтобы вот эта вот прокладка между рулем и сидением, она могла эти ручки крутить. Вот собственный искусственный интеллект, который у нас на хайпе сейчас находится, и в том числе его маленькое проявление, эти большие языковые модели, которые нам сейчас много чего упрощают, Это тот самый элемент прокладки, то есть элемент водителя, но ему, этому водителю, нужна еще и система, которая может туда ехать. Некоторая такая вот инженерная сущность. Вот про это хотелось бы с вами сегодня пообщаться и в том числе посмотреть на то, как вот этот текущий вызов, связанный с искусственным интеллектом, на самом деле построение таких систем сейчас еще больше актуализирует. Как верно заметил Николай, мы уже последние несколько лет рассуждаем на эти темы, в том числе в контексте цифровой трансформации предприятия. И кажется, что сейчас тема с внедрением ИИ просто даже ускоряет необходимость, то есть ускоряет внедрение нижележащих систем, потому что искусственный интеллект по-другому не работает. Если в рамках цифровой трансформации мы по-прежнему могли оставить какие-то процессы неизмеренными, какие-то данные куда-то не внесенными, надеясь, что Вася, Петя, Маша, у них все в голове есть, они все сделают, и это как-то все будет работать, то сейчас уже, когда мы пытаемся применить куда-то искусственный интеллект, это так не работает, потому что он не может взять и достать из головы человека нужный ему контекст. Контекст – важное слово, которое вы наверняка с Николаем и с предыдущими спикерами здесь не раз вспоминали и использовали. И, собственно, контекст – это то, что и нужно для достижения вашей задачи. а он формируется на основании того, что происходит на предприятии и то, что на нем фиксируется. Собственно говоря, зачем вообще в эту историю думать, наверное, сейчас объяснять не надо. Мы как бы с вами живем настолько хорошо, насколько хорошо обрабатываем данные. И, собственно, искусственный интеллект на текущий момент это некая такая вишенка на тортике, которая позволяет нам добиться того, чего мы не могли добиться ранее, как общество. И мы это видим в том числе и в эволюции развития компаний, которые переходят от управления на основе людей и человеческих только умений к каким-то процессным моделям, когда мы избавляемся от зависимости от конкретного исполнителя, выстраивая, документируя процесс, разбивая его, декомпозируя на какие-то отдельные небольшие этапы. И потом, соответственно, можем спокойно даже менять исполнителей, ну или они, допустим, уволились или заболели, это не страшно, процесс не страдает, наше производство идет дальше. Потом в дальнейшем компании приходят к тому, что они начинают эти процессы измерять, собирая данные о протекании этих процессов куда-то, и, соответственно, могут уже теперь не просто ходить где-то рядом, как это раньше было при Федерике Тейворе с секундомером, а заглядывать в какие-то таблички и на основании этого эти процессы корректировать. Ну а теперь мы постепенно приходим вот туда, в ту плоскость управления на основе моделей, искусственного интеллекта, систем искусственного интеллекта, где уже даже не требуется ходить за кем-то или куда-то заглядывать, потому что у вас есть некоторая система или модель, которая сама этот процесс может контролировать, выявлять аномалии и в том числе подсказывать вам, какие необходимые именно изменения провести. Вот я вижу, что у вас в программе в понедельник был Юрий Ковачков, про самоулушающий процесс он вам рассказывал. Вы наверняка помните эту историю. Это как раз в том числе часть вот того AI-driven блока, куда мы все приходим. Приходим почему? Потому что это та область, в которой, кажется, можно больше заработать денег. То есть это не какая-то выдуманная история, что мы просто хотим двигаться туда, потому что хотим двигаться туда. Нет. Просто мы понимаем, что построив процесс, мы можем масштабироваться быстрее, Обеспечив этот процесс данными, собирая, мы можем улучшать эти процессы, сокращать потери, увеличивать свою выручку. Ну а когда мы это все можем теперь завести вместо людей на AI, на искусственный интеллект, мы можем делать это быстрее, лучше, точнее, в том числе схватывать те вещи или те закономерности, которые мы, как белковые человечки, пропускали до этого. А можно вопрос к этому слайду? Где тут model-driven? Или он заменен сразу на AI? Я сразу заменен на AI-driven, потому что я об этом тоже поговорю. Я иногда понимаю искусственный интеллект чуть, возможно, в другом значении, чем коллеги, и тоже поделюсь с вами своим видением на этот счет. Я это все объединил в один блок, потому что модели, если мы говорим про модель машинного обучения, скоринга чего-нибудь, предсказания, прогнозирование классификации, это часть системы искусственного интеллекта. Потому что искусственный интеллект – это технология принятия решений на основе моделей на базе обучения. Таким образом, для меня Model Driven вот там, в AI-дривен. Я здесь привел оптимистичное высказывание Германа Грефа из еще 2023 года, когда он говорил про то, какие можно обеспечить возврат инвестиций при вкладывании денег в систему искусственного интеллекта. Я последние его высказывания, такие более пессимистичные для многих, не стал на слайд выводить, но вы про них слышали, про то, что теперь можно сократить какое-то количество людей, потому что искусственный интеллект их признал неэффективным. Но вы знаете, когда Герман Оскаревич говорит про искусственный интеллект, он не обязательно говорит, что вот гигачат, который они создали, привел сразу к тому, что и всех людей мы можем увольнять. На самом деле это не так. На самом деле надо понимать, что когда Герман Оскаревич говорит про искусственный интеллект, он говорит про свою компанию, которая является одной из крупнейших и сложнейших IT-компаний теперь в России, насквозь пронизанной метриками, которые измеряют процессы, устроенных у него внутри. У него довольно много систем, вообще, в принципе, расчетов, алгоритмов, визуализации. И где-то там есть еще искусственный интеллект, который в виде последних языковых моделей, который помогает что-то делать или что-то формулировать. Но не он сам по себе является той самой точкой, которая позволяет принимать такие решения. Кого увольнять, кого не увольнять. Вся система, которую он выстроил нижележащей, является тем, что он называет искусственный интеллект. То есть это некоторый такой целый айсберг, который есть у него в управлении, и благодаря чему он может какие-то участки совершенно спокойно для себя ликвидировать, не опасаясь того, что это приведет к сокращению прибыли. Потому что, по сути, у него есть цифровой двойник его предприятия. Это термин, который был модный некоторое количество лет назад. Модный он становится еще более сейчас, потому что, если мы хотим применить какую-то штуку, которая думает за нас и говорит, что делать, надо этой штуке предоставить ту самую цифровую копию или слепок, который, собственно говоря, он и сможет управлять. Я бы хотел с вами поговорить как раз сегодня о том самом айсберге, сейчас мы с вами разберем его, который и является присоутый искусственный интеллект. Поэтому если вы полагаете, что можно, как некоторые американские компании, они об этом бодро отчитались, увольнять людей, потому что сейчас ЧАД-GPT, он за вас все сделает работу, боюсь, это не так. Можно, конечно, но те компании, кто увольнялся, перенанимают обратно, Потому что выяснилось, что код они, конечно, эти модели большие языковые пишут, но с ошибками, да, в продакшн такое вывалить нельзя. Нету понимания и архитектуры устройства того бизнеса, который был в этих компаниях, у этих языковых моделей, потому что они были обучены на большом количестве, в некотором смысле, усредненной информации. Поэтому они делают нечто усредненно хорошее, а вот сделать так, чтобы это было четко соответствовать потребностям бизнеса, нет, не получилось. В том числе потому, что до этого этим занимались люди, которые десятками лет собирали в себя контекст деятельности всего предприятия. И бизнес необходимость, и логическую структуру, и какие-то технические вещи. Наверное, мы однажды до этого дойдем, но сейчас пока еще это время не настало. И нам с вами нужно создать как раз-таки ту самую систему, которая позволит вот это все потихоньку из голов людей перемещать куда-то во что-то, в то, что можно потом будет прислонить искусственный интеллект, и это будет работать хорошо. Смотрите, когда мы говорим про то, что искусственный интеллект в виде самолета куда-то полетел, и он делает какие-то классные штуки, которые мы не делали ранее. Помните ту схему с движением от People Driven до AI Driven? Если вы запомнили, то там что People Driven, что Process Driven, что Data Driven, это были такие истории колесных транспортных средств. Они по-прежнему двигались по дорогам с использованием колес и просто чуть быстрее, чем ранее. И только самолет, вот этот AI, это штука, которая кардинально меняет принципы управления и принципы деятельности, и которая значительно ускоряет эту скорость. Но она, в отличие от всех прочих остальных, требует совершенно другой объем инфраструктуры под ней. не просто дорога, которая проложена куда-то, мы можем на телеге, на автомобиль доехать даже по грунтовой дороге. Самолет не взлетит по грунтовой полосе, уж особенно какой-нибудь современный истребитель или бомбардировщик. И для того, чтобы он полетел, надо, чтобы вообще, в принципе, его где-то собрали, где-то его потом обслуживали, контролировали, что у него все в порядке с системами, что нет там обледенения на крыльях, что у него все хорошо с заправкой, выпускали куда-то на полосу, А потом, когда он взлетел, нужно, чтобы кто-то мониторил, контролировал, разводил различные борты, и они не пересеклись где-то в воздухе. И это отдельная большая деятельность, которую мы иногда не видим или не ощущаем. Ну, когда едем в какой-то город, мы, конечно, через аэропорт проезжаем и можем это наблюдать. Но, как правило, просто не обращаем внимания. Мы сели в самолет, он нас куда-то доставил. И вот, чтобы этот самолет полетел, надо понимать, что эта вся история должна случиться. Либо она случится у вас на предприятии, либо она случится у кого-то, и вам нужно будет пользоваться его результатами. Так, как, например, вы используете сберовский гигачат или Яндекс.Гпт или чат.Гпт. То есть кто-то в данном случае это Сбер или Яндекс, или, если мы говорим про американцев, OpenAI. Все вот эту необходимую инфраструктуру у себя построили и выдал вам какой-то кусочек возможности, которой вы пользуетесь. И он построил и физическую инфраструктуру, он построил и логическую инфраструктуру. поверх этого какие-то собрал данные, ну и наверху уже есть вот такой маленький кусочек LLM, или большие языковые модели, или модели генеративные, которые позволяют делать видео или аудио, и дальше вы, собственно говоря, пользуетесь их результатами, благодаря тому, что есть что-то снизу, которое это все питает. И здесь я хотел бы сформулировать некоторое такое определение, или взгляд на искусственный интеллект. И тут, наверное, Николай, он может меня активно потыкать вилами. Я хочу сразу сказать, Николай, он глубоко мыслит и рассуждает на эту тему. Я смотрю на искусственный интеллект в таком утилитарном смысле, как его, собственно, прислонить к делу где-то в конкретных бизнес-процессах. И глядя утилитарно на него, я, наверное, разбил бы его на некоторые этапы, как он работает. Собственно, для меня так работает любой интеллект, не только искусственный, естественный тоже наш с вами, когда мы разговариваем. Сначала мы с вами что делаем? Мы собираем сырые данные, сигналы. Мы смотрим друг на друга, мы видим отраженный свет, он падает куда-то там на сетчатку, на колбочки. Это воспринимается, этот сигнал передается по нерву в мозг, там он интерпретируется и так далее, и так далее. То есть в этот момент мы собрали этот сигнал, который упал к нам на сетчатку. Дальше он прошел какое-то преобразование в определенных разделах нашего мозга. и он упал в какую-то модель, которая дальше уже, например, распознает, что это лицо человека, а это вот там бутылочка воды, а это еще что-то. И на основании того, что модель распознала или обучилась, если это происходит впервые, например, уже происходит применение каких-то алгоритмов или правил. То есть если я вижу стакан, ну я, например, хочу пить, я беру и пью его. То есть в этот момент случилось применение правила принятия решения, и я, собственно, сделал это. Ну а если вдруг я понимаю, что там что-то было невкусное, то у меня возникают сомнения, а правильно ли я распознал то, что я там увидел, и происходит некоторое переобучение этой модели, за счет чего эти данные вкусовые и визуальные попадают снова в виде сырого набора данных мне в мозг, там происходит тюнинг модели, и теперь у меня новая, более совершенная модель, которая мне говорит, вот так делай, так не делай. Это наш естественный интеллект. Если мы поговорим про искусственный интеллект, например, мы говорим про предсказания оттока абонентов, либо клиентов. Мы точно так же собираем сырые данные сначала, сигналы, и за счет их активности, какой-то коммуникационной активности, либо если это торговые предприятия, покупок, привязанных к их профилю. Потом внутри системы предприятия происходит некоторая обработка, объединение, агрегация, преобразование этих данных в тот формат, который дальше можно уже отправить в модель, которая была ранее сформирована, модель машинного обучения. И она выдаст некоторое предсказание относительно вероятности оттока конкретного клиента или того, что он купит либо не купит что-то. И дальше это попадает в некоторую систему принятия решения, это может быть какой-нибудь real-time decision manager, который на основании вот этого скорбала возьмет и отправит какое-нибудь коммуникационное сообщение, там смс-ку, например, или пуш-сообщение конкретному клиенту. И в этот момент, по сути, будет принято решение. А в том случае, если, например, мы видим, что оно не привело к нужному нам результату на каком-то периоде, то в этот момент, благодаря имеющейся системе мониторинга работы моделей, качества моделей, мы понимаем, что теперь эту модель надо отправить на обучение с использованием новых исторических данных. И она снова отправляется туда. И это то, что происходит в банках, телекоммуникационных предприятиях, в предприятиях ритейла, таких как у Тиграна, например, если он выступал, да, Саркисов Тигран? Нет? Ну вот, есть такое замечательное CTO в X5. И у них тоже такие штуки мощные работают. И вот это, по сути, то, что у нас происходит в головах, происходит и на предприятиях. И для того, чтобы вот такая вот схема, как мне кажется, система могла быть выстроена, нам нужно реализовать каждый из этих этапов. Когда мы говорим про большую языковую модель, которая что-то может за нас написать или сгенерировать, это по большому счету только вот эта вот вещь. когда мы с вами ее встроили в некоторую агентную систему, это вот эта вот вещь. То есть теперь мы уже можем реализовать на базе этой модели еще некоторое решение. Но это еще не полноценный искусственный интеллект. Я поэтому здесь на некоторых слайдах пишу по-русски ИИ. Это то, что я воспринимаю, как вот такую систему, которая может действительно делать какие-то управленческие вещи и полноценно наблюдать за вверенным ее участком. И AI в модном понимании, это генеративные модели. И если мы с вами сейчас разложим вот этот порядок операции, который нам нужно сделать, чтобы получился настоящий искусственный интеллект, или он вообще мог в принципе чем-то заниматься вменяемым, на некоторые такие технологические блоки, то мы увидим следующее, что для того, чтобы собрать данные, собственно говоря, о том, что происходит, нам нужны базы данных. Транзакционные базы данных, я уточню этот термин чуть позже, когда мы можем записывать какие-то данные о фактах, о том, что случилось. Например, мы хотим теперь, чтобы мы управляли нашими продавцами, например, или как-то могли совершенствовать продажи, что-то прогнозировать или им подсказывать. Нам сначала нужна CRM-система, куда будут они вносить все свои данные о коммуникациях с клиентами, то есть некоторые транзакционные процессы. Если ее нет, то, собственно говоря, мы ничего не сможем никак искусственный интеллект к этой истории приложить. То же самое с покупками или с какими-то другими вещами. Дальше, для того, чтобы мы могли потом на основании всех этих сырых данных реализовать и прислонить туда искусственный интеллект, нам нужно реализовать некоторый ETL или EOT процесс, который обеспечит сборку данных из транзакционных систем, складывание их в отдельное место, агрегация, необходимое объединение, обогащение внешними данными. И дальше потом уже это подсовывание под модель машинного обучения. Ну и дальше уже, собственно говоря, у нас вступают в роль те самые AI-агенты N8N. Вы рассматривали, Николай? Да, то есть как вот этот оркестратор. Есть кестера, есть еще набор таких систем. Те штуки, которые позволяют вам выстроить некоторую последовательность действий, использующих и классические алгоритмы, и правиловые, и, собственно говоря, новомодные большие языковые или другие генеративные модели. Или там те самые еще движки, которые работали до этого и еще будут работать, потому что они работают быстрее и четче для принятия решений в реальном времени. Ну и обязательно некоторое выстраивание инфраструктуры ML-Obs, так называемого, которое позволяет формировать те самые сомнения в том, что это все работает хорошо. Потому что эти модели со временем склонны протухать. В общем-то, как же и вот эти. Это связано с тем, что наша реальность непрерывно развивается. То есть мы все время что-то происходит, и мы с вами даже просто часто не замечаем изменения в нашей голове, они постоянно происходят, мы переобучаемся. И если модели не переобучаются на новых данных, на том, что происходит сейчас, у нас сейчас вообще очень такое турбулентное время, то они скоро начинают предсказывать, что это все неправильно. И для этого нам обязательно нужно реализовать вот этот цикл, который позволяет все это переобучить. Но я сегодня хочу с вами поговорить, наверное, вот про эту часть, и про то, как она должна быть устроена так, чтобы потом вот эта часть работала лучше. Вот то слово снова у нас возникло на экране, контекст. Вы все за последние дни наверняка много с моделями работали, большими языковыми, правильно, Николай? Вы в их контекстные окна, знакомый термин, засовывали какую-то информацию. Представь, ты там тот-то, тот-то, тот-то, ты работаешь так, ты должен выдать мне результат в такой-то форме, а еще ты должен знать, что. И когда делают агентные системы, например, даже у нас в компании есть определенные процессы, которые мы тоже решили ускорить с двух недель до пары часов, и это удалось сделать, работы аналитиков, которые берут определенные документы, отправляют большую языковую модель, собирают с нее определенные результаты, дальше потом к ним пристегивают еще что-то, формируют контекст и отправляют дальше в следующий шаг. Там снова работает модель и выдают какие-то определенные нужные нам оценки, либо корректировки. И вот все то, что мы в нее засунули, это вот контекст. Когда мы говорим про предприятие, про компанию, банк, это может быть производственное предприятие, какая-то площадка, либо логистическая, неважно, то все, что происходит в компании, все те данные ее деятельности, ее бизнес-деятельности, являются тем самым контекстом, который можно и нужно собрать и дальше потом с помощью определенных средств сбора, наверняка обсуждали про MCP, сервера, такие определенные технологии, которые позволяют подключаться к источникам. Дальше этот контекст передать на вход AI-модели. То есть теперь, когда мы хотим применить все те замечательные вещи, о которых вы говорили последние дни, и вам показывали коллеги, как их строить, мы должны понимать, что нам вот здесь нужно, чтобы в средства сбора поступали вот эти вещи. Если у нас нет таблиц, непосредственно в которых есть какие-то поля или файлы по определенной структуре, которые мы можем подсунуть в контекстное окно какой-то языковой модели, она не сможет ничего сформулировать нам в принципе, потому что у нее не будет целья и фактуры. Если у нас нет какой-то логической модели, которую мы могли бы передать этой модели, рассказав ей, что вот в этой таблице содержится то-то, а здесь такой-то там порядок подход данным, и ты мне должна это сформулировать в виде таких вот терминов, то тогда у нас тоже ничего не получится. Также в конечном итоге, если мы не построим внутри компании некоторый бизнес глоссарий, которая будет четко говорить, какой показатель, что для нас означает, и самое главное, на основании чего он рассчитывается, точно так же никакая генеративная модель не сможет вам ничего сформулировать, потому что ей просто будет непонятно, с чем работать. Но она попробует что-нибудь сгаллюцинировать, она наверняка в своей истории обучения видела какой-то набор текстов с похожими данными, но это может иметь никакого отношения именно к деятельности вашей компании и приведет просто к принятию неправильного решения, возможно, с высокой ценой ошибки. Поэтому вот эти все вещи, которые вы видите на экране, мы их делали глобально в среднем крупном и сверхкрупном интерпрайзе всегда. Всегда строили какую-то физическую модель данных, логическую модель, концептуальную, которую где-то описывали в Excel или даже в бизнес-глоссарии. Но раньше мы действительно могли делать это не то, чтобы спустя рукава, но как минимум постепенно. И не ожидая, что нам нужно это сделать в ближайший год. Но сейчас мы понимаем, что когда мы занимаемся этими процессами управления данными, построения системы обработки данных, пользователями их будут не только люди, на которых мы иногда можем полагаться и надеясь, что они закроют за нас эти слабости. Теперь пользователем становится система искусственного интеллекта, языковые модели, которым мы должны на вход подавать четкие структурированные вещи. Мы, в принципе, должны описывать то, что мы делаем. Мы должны это где-то документировать и вытаскивать из человеческих голов, потому что иначе это все не сработает. Тут хотелось сделать маленькое отступление и поговорить о том, что вообще даже в принципе без применения больших языковых моделей либо других генеративных вещей само по себе акцентирование внимания на системах сбора, хранения, обработки анализа данных дает определенные выгоды и эффекты. И по опыту, если посмотреть на те проекты, которые нам приходилось делать в разных доменах, они всегда так или иначе приводят к улучшению какого-то бизнес-процесса с точки зрения денег. Например, в продажах увеличивается прибыль за счет того, что тиражируется опыт лучших продавцов, это то, что мы делали в одной из FMCG-компаний, собрав процессы их работы и понимая, какие из них работают лучше. В маркетинге это совершенно давно известная история с персонализацией коммуникаций на основе правильного сегментирования и предсказания того, какая именно коммуникация позволит с этим добиться отклика и добиться продажи. С точки зрения цепочки поставок, системы хранения и обработки анализа данных, не лежащие еще даже до искусственного интеллекта, они еще давно позволяли, и сейчас эти проекты ведутся повысить оборачиваемость и, собственно говоря, снизить затовариваемость кодов. Ну а с точки зрения производства тоже наверняка вы слышали не раз примеры и из металлургии, и из других отраслей, где станки, управляемые моделем машинного обучения, никакой генеративки, просто за счет правильного сбора того, что происходит на этих участках, обвешивания датчиками, сбора это в КХД и дальше применение ML-моделей, повышали выпуск продукции и обеспечили тем самым повышенную выручку предприятия. С точки зрения даже тех функций, которые иногда воспринимаются как сервисные, это IT или юридические службы или HR, ну так просто вот я встречаю такое отношение, эти направления, они тоже являются теми, которые позволяют увеличивать прибыль за счет сокращения оптимизации издержек. Как с применением классических моделей машинного обучения, так и теперь уже с применением генеративных моделей, которые используют весь тот накопленный полознаний и выставленную инфраструктуру. Здесь мы можете видеть эти примеры на экране, я не буду их подробно расписывать, можем про это, если хотите, поговорить отдельно. С точки зрения, например, маркетинговых вещей, о которых я упоминал, это та самая сегментация и формирование персонализированного сообщения, когда вы за счет того, что собираете всю историю покупок клиента, плюс данные программы лояльности и еще какие-то, возможно, обогащаете внешними данными, вы в состоянии теперь обеспечивать такую коммуникацию с клиентом, которая бьет ровно в то самое чувствительное место, за которое его можно брать. Например, кто-то реагирует на скидки, кто-то реагирует на баллы кэшбэка, кто-то еще на что-то. И, собственно говоря, в той истории, где мы это реализовывали в ритейле, удалось добиться довольно существенного прироста отклика и дополнительной выручки. Как раз-таки за счет того, что обеспечив нежележащую инфраструктуру сбора данных и потом ее направление, еще даже модель машинного обучения, это до появления генеративных моделей, мы добились существенных экономических результатов. В компании Burger King, тоже, я думаю, вы знаете ее, существует такая замечательная компания на рынке, было построено хранилище данных, в данном случае на облачных сервисах для снижения совокупной стоимости владения. и люди не были готовы инвестировать в развитие своей собственной инфраструктуры, вообще это дорогое удовольствие. Ребята здесь за счет того, что они оцифровали свои процессы и построили вот эту модель данных предприятия, и в дальнейшем ее на нырях накрутили модель машинного обучения, обеспечили себе рост эффективности в части ресторанов, процессов. И здесь тоже получили элементы дополнительной выручки. На самом деле мы можем говорить о том, что постоянный систем хранения и обработки анализа данных в некотором таком правильном и основательном формате, оно позволяет не только получить выручку, если мы говорим про те самые сервисные функции, как IT, непосредственно связанные с увеличением выхода продукции, либо поиском новых денег. Это еще и оптимизация издержек, связанная с тем, что создание инфраструктуры, которая готова в будущем и для применения ИИ, обеспечивает вам возможность оптимизации фонда оплаты труда, который тратится на эту инфраструктуру сбора данных. Собственно, это как раз то, что мы делали в компании Комус, тоже на облачных сервисах. в сервисах, переписав и создав ее в такой форме, что теперь, в общем-то, можно применять, уйдя от монолитных систем, закрытых в современный, так называемый, дата-стэк, теперь можно применять системы искусственного интеллекта и, в частности, большие языковые модели. Здесь, здесь, да, то есть в тех вещах, которые опираются на возможность построения кода. большие языковые модели, они генерируют текст, соответственно, мы ушли в ту сторону, где этот текст можно открыто доставать, открыто модифицировать, ну и использовать в том числе для оценки отчетности. То есть, в конечном счете, хотел бы резюмировать, что основная задача систем хранения и обработки анализа данных, в том числе искусственного интеллекта, это не только оседовать волну хайпа, это, прежде всего, это увеличение прибыли и сокращение сдержек. Как достигается выполнение основных задач? За счет архитектуры, о которой мы сегодня поговорим немножко, и за счет, собственно, обеспечения достоверности и репрезентативности данных. Почему важны здесь все слова, которые написаны? Потому что архитектура – это то, как мы собираем, храним, обрабатываем без привязки к конкретным программным продуктам. Потому что программные продукты могут меняться, учитывая наше турбулентное современное время, они точно будут меняться, и нам нужно к этому быть готовыми. Поэтому прежде всего надо рассуждать при построении таких систем об архитектуре, о том, как эти компоненты связаны между собой, из чего это все состоит и как оно должно действовать. а уже непосредственно технические решения либо программные продукты выбирать, что называется, ситуативно, исходя из бюджета и из того, что отвечает вашему видению правильного. Когда мы говорим про достоверность и репрезентативность данных, здесь эти два слова суперкритично важны, потому что это то самое топливо, которым питаются системы аналитики и питаются системы искусственного интеллекта. Если мы попробуем залить просто воду в бензобак, машина никуда не уедет, самолет не улетит. Самолет нужен чистейший керосин, будьте здоровы, автомобилю хороший и качественный бензин. То же самое здесь. Когда мы подаем на вход какой-нибудь модели, которая теперь у нас вместо человека управляет участком и говорит, как правильно, некорректные данные, то же самое, что у человека, понимается некорректное решение и вообще происходит какая-то галлюцинация. А чего галлюцинирует модель? Ну, помимо того, что им трудно сказать «нет», тогда, когда от них ждут ответ. Это также связано с тем, что в их обучающую выборку изначально попадали какие-то вещи, не соответствующие действительности, и так тоже случается. И поэтому, если мы оцифровали процессы деятельности нашего предприятия, внутрь у нас теперь падают недостоверные данные или их отсутствующие вообще, то в этом случае у нас и на выходе всегда тоже получится какое-то некачественное решение. Если мы говорим про репрезентативность, это важный термин, возможно, вы помните его из статистики. Он говорит о том, что у вас то количество данных, которое есть, оно достаточно для того, чтобы, собственно говоря, отражать некоторую закономерность, которую вы пытаетесь уловить. Если у вас там всего 10, 20, 30 записей, вы вряд ли сможете построить поверх этого какую-то вменяемую модель машинного обучения, которая будет что-то качественно для вас предсказывать или классифицировать. Вам, как правило, нужно большое количество наблюдений, это тысячи, десятки тысяч и миллионы записей, и поэтому следует озаботиться тем, чтобы система хранения и обработки анализа данных могла в себя такие данные разместить. Они где-то у вас накапливались, и дальше вы их уже могли, собственно, подсовывать модели машинного обучения, прогнозирования чего-нибудь, да, или оптимизации. Или, собственно говоря, дальше передавать на откуп это каким-то агентным системам. Давайте теперь, собственно говоря, заглянем туда немножко внутрь всего этого волшебства. Здесь вот я хочу два термина таких озвучить, ввести, что просто они у нас с вами были в голове, мы говорили на одном языке. Есть транзакционные системы и аналитические системы. И здесь мы говорим о ролях, не о конкретных продуктах, потому что вполне бывает сейчас, да и ранее, что некоторое программное средство, оно в себе объединяет и ту, и другую роль, и можно и так, и так его использовать. В общем, поэтому мы говорим о выполняемой функции. Транзакционная система – это то, куда вносится запись о каком-то факте, который случился. Например, это база данных под кассой какой-нибудь. Прошел человек, пробил бутылочку воды, тем датаматекс кодом. Собственно, по кассе прошла покупка, эта запись внеслась в базу данных. Вот она строчка за строчкой туда складывается. Дальше, когда вы хотите в целом проанализировать, например, покупки в разделе товарных категорий, либо там город каких-то, если вы это объединяете с программами лояльности, то вам дальше нужно теперь сагрегировать данные, то есть объединить эти записи между собой и как-то по этим группам сделать уже расчет минимальный, средний, максимальный суммы и так далее. Транзакционные – это то, куда мы все пишем, а аналитические – это то, где мы дальше считаем какие-то необходимые нам показатели для принятия управленческих решений. И мы можем таким образом путь от данных, когда они только появились, те самые записи о фактах, случившиеся, до человека, который принимает решения, изобразить вот так упрощенно, такими простыми визуальными блоками. Что мы с вами видим здесь? Мы видим, что здесь есть некоторый блок малых данных и так называемый Big Data, больших данных. Это опять же просто ярлыки, надо понимать, что за ними может быть совершенно индивидуальное содержание, потому что про Big Data вообще это уже 10 лет про него говорят и до сих пор до конца не определились, есть много различных вариаций на этот счет. Но мы говорим про большие, разнородные, быстро растущие данные, как структурированные, так и не структурированные. Ну а маленькие данные это что-то там, таблички какие-то, ваша собственная Excel или записи, 100 или 1000 записей, которые можно также в Excel легко покрутить. И если мы говорим про некоторый такой маленький набор данных, который вполне себе умещается в один лист Excel, то это то, что можно спокойно подсунуть в систему визуализации или отдать какой-то агентной системе, чтобы она за вас обдумала, что в ней находится, и дальше подсказала, что кажется, что это так, а здесь у нас вот такой-то сегмент является наиболее превалирующим, а вот здесь, если мы применим наш новый подход, то мы можем получить вот такую-то дополнительную выручку на основании каких-то тех алгоритмов, которые вы в контекстное окно ей поместите. И дальше все равно по-прежнему до сих пор у нас принимает решение человек, несмотря на появление агентных систем. Кто-то вот тоже из власть-выдержащих недавно высказался, что у любого решения должна быть фамилия, и никакой агент за вас не сядет. Поэтому здесь должен быть пока что человек, который несет административное и уголовное ответственность за свои решения, а агент по-прежнему является всего лишь некоторым помощником, который эти решения туда подносит. И в том числе... Да, да, мы, наверное, это какое-то светлое будущее. Все бы сразу внедрили. Да, но пока что это так. Пока что мы всего лишь здесь хотим с помощью этих агентных систем снизить ту самую вероятность, попасть туда, куда мы не хотим. И в том числе есть блок больших данных. Это все то, что у нас есть в структурированном и не структурированном виде. Тексты, логи, какие-то там данные о событиях, очень большие таблицы на миллионы и миллиарды записей, которые нам очень тяжело своей головой объять, чтобы принять решение. мы вынуждены их каким-то образом либо передавать на вход агентным системам, если это все пролезет туда в контекстное окно, либо применять какие-то алгоритмы расчетные, упрощающие, агрегирующие для нас эти вещи, и плюс модель машинного обучения, которая в состоянии весь этот поток в себя засосать, и дальше для нас сформулировать какой-то небольшой блок данных, тоже в виде таблицы, и мы отправляем это все в некоторое средство визуализации, это какая-то BI-система из тех, что существует на рынке, или используем эту табличку, подсовывая в какую-то языковую модель и просим ее интерпретировать то, что она увидит внутри. Ну, собственно, либо мы просим человека, ну и получаем какие-то из этого инсайты и дальше принимаем решение. Это такая вот упрощенная схема. Мы эту схему можем на самом деле с вами расшить и сделать ее побольше и помассивнее. Это, в общем-то, тот же самый путь от данных до решений состоит, только он уже из большего набора функциональных блоков, где слева вы видите, собственно говоря, те самые транзакционные системы, куда вписываются данные деятельности вашего предприятия. Это база данных под какими-то приложениями, под сайтом, личными кабинетами, это логи деятельности, так называемые цифровые следы сотрудников в каких-то системах, в АБС, в СРМ, еще где-то. Это какие-то текстовые файлы, которые вы обмениваетесь в переписке, данные по закупкам, собственно говоря, данные электронного документа оборота, ну и в том числе данные о деятельности оборудования. Дальше все вот эти вот факты, которые зафиксированы на предприятии, чтобы ими вот здесь могли воспользоваться люди, которые хотят сделать что-то хорошее для компании и получить новые деньги, старые деньги, либо оптимизировать затраты. Для этого нужно, чтобы эти данные протекли вот туда, через ту самую систему хранения, обработки и анализа данных. И у нее в этой системе есть несколько блоков. Во-первых, это, собственно говоря, блок интеграции, который обеспечивает передачу данных отсюда в некоторое место, где данные будут храниться в корпоративной модели данных, объединяющей, как правило, данные многих транзакционных систем. в таком формате, чтобы можно было очень быстро и четко получать какие-то аналитические выкладки. Потому что я чуть позже объясню, почему не очень классно считать здесь. Собственно говоря, этот блок может состоять из различного набора продуктов. Вы пока не обращайте внимания вообще на эти логотипы. Они приведены здесь просто для примера, если для кого-то есть какие-то знакомые. Здесь у нас раньше, конечно, были другие имена, но теперь мы живем в импортозамещенной реальности. И пока что GreenPlan это один из в России тех продуктов, на которые реально компании мигрируют. Биржи, банки и все остальные. И где, собственно, выстраиваются данные в рамках всего предприятия, централизованно. И когда мы переместили в пакетном либо потоковом режиме данные вот сюда, обеспечивали какие-то определенные расчеты, обеспечили витрины для того, чтобы из них можно было нужные нам показатели расчетные быстро достать, У нас, собственно говоря, теперь они перемещаются в блок визуализации, блок построения отчетности, в котором уже находятся BI-системы, так называемые бизнес интеллиженс, куда уже некоторый ограниченный набор данных из витрин может быть забран. Это могут быть открытые бесплатные системы, это могут быть вендорские российские системы, ну или если у кого-то еще есть доступ к Power BI, там клику или другим продуктам. Да, у них, наверное, все хорошо, табло, пожалуйста, это все как раз у TAN-блок. И вот там, собственно говоря, уже те самые возникают дешборды, куда мы смотрим и принимаем какие-то решения. Ну а теперь там еще у нас возникают и агентные системы, даже все вот эти вот ребята, которые делают систему визуализации, они внедряют своих AI-помощников на основе больших языковых моделей внутрь своих BI-систем для того, чтобы можно было просто написать, А что у меня происходит там? Некоторые даже создают системы отчетности и визуализации уже в принципе в формате чат-бота. Есть у нас на российском рынке Sapiens Solutions. Они сделали из реперта, так называемый продукт. Там просто в WhatsApp ты пишешь, и он тебе отвечает обратно, скидывает табличку или какую-то визуализацию. И для того, чтобы мы могли строить сценарные модули, которые будут принимать решения на основании того, что у нас происходит в компании, нам надо еще и построить некоторый блок с аналитиками, так называемыми дата-сиентистами, которые будут все это хорошее делать. Вот такая большая труба, состоящая из разных функциональных блоков и набора разрозненных продуктов, это вот и есть та самая система хранения и обработки анализа данных, которая, как вы видите, лежит в основе AI, применяемого уже на некоторой такой последней миле. Ее мы можем с вами для простоты схлопнуть, просто чтобы осталось в голове. Вы просто, может быть, не обратили внимания. В трех местах же у тебя AI нарисован. Ты просто сейчас, кажется, это проброс прокомментировал. Мне кажется, что здесь важно обратить на это внимание, поскольку у тебя он один раз как автоматическое решение, обращающееся к данным, и это один тип интерфейса, которым он работает. Один сценарий. Это грубо вот здесь агенты, решающие практические задачи внутри вашей системы. И передающие управляющие сигналы куда-то. И передающие управляющие сигналы куда-то, потому что видишь, чем мне понравилось. У тебя здесь он наряду с логистами, он тоже тип потребителя. Да, все верно. Потому что он может быть… Давай так, я сейчас по-другому скажу, вот, что я хотел спросить. Можно ли примерно так рассуждать, что у тебя вот этот агент, вот здесь, может быть у логистов, у закупок, у розницы, у маркетинговых финансов? Это хорошо, что точнее, да, это действительно так. То есть этот AI-агент, он не сам же по себе живет, он какую-то бизнес-функцию реализует. Как называется? Давай так. Его можно вывести как отдельное решение автономное, которое работает. Так и можно нарисовать агентов под каждой из функций, которая решает их задачу. Или в этом плане логист, снабженный AI-агентом, имеет доступ к этим данным и работает дальше, соответственно, напрямую. Там где-то есть его системы, в которых он ходит, из которых он забирает данные. И это такой вот будет протяжка. Эти ребята, они пользуются вот этим некоторым AI-агентом, соответственно, для реализации какой-то своей задачи. Вот у тебя просто здесь написано отчетность, это я думал, что я могу сходить сюда в отчетность. Нет, подожди, подожди, это разные вещи. Я просто хочу, чтобы мы архитектуру поняли. Смотрите, это я увидел, но я их хочу как разное сделать. У тебя есть, например, маркетинг, который ходит за отчетностью в какой-то бот и работает с ним. Это человек из маркетинга работает по отчетности с этим агентом. Это ассистент. А это хреновенно приставлено к маркетингу, который работает в автоматическом режиме, решая какие-то задачи, напрямую минуя эту историю и выдавая какой-то результат, обзванивая, не строя аналитику. Это, грубо говоря, полностью автономный модуль, который работает в маркетинге, решая задачи маркетинга не в ассистивном режиме, а в агентском режиме. Да, например, так. Вот поэтому я хотел вот это агентский режим, а вот это агентско-ассистентский. То есть здесь как бы требуется... Это реактивный режим, то есть в ответ на взаимодействие. Это даже может быть проактивный режим. Самостоятельно двигаешься куда-то. Я это хотел уточнить. И отдельная вещь, которую ты вверху написал, ее можно не заметить, но она важная. Потому что она у тебя лежит в блоке управления данными. И там лежит AI, который, соответственно, проверяет каталог, нормализует данные, отвечает за качество и так далее. Почему он там лежит? Потому что блок управления данными критичный для всей системы. Все верно. А работать с ним все время лень и не хватает рук. И с ним один раз отработали, а надо работать на протяжении всего. Поэтому мы туда внедряем AI, который совершенствует систему управления данными, которая совершенствует ответы, отзывы и так далее. У тебя они, как это называется, не случайно здесь расположены в таком области? Нет, совершенно не случайно, да. Они размещены здесь, во-первых, в том месте, где они либо заменяют человеческую функцию, в этом году здесь, да, либо они в месте, где люди, потребители взаимодействуют с системой, потому что, ну, вот эти вот ребята куда-то вот сюда вот не ходят. Они там в сообщениях, которые по кавке проваливаются, никто не заглядывает, им это и не надо. И в табличке сырого слоя они тоже не ходят. И поэтому AI-агент, конечно, на самом деле можно и тут прислонять, и тут прислонять, но здесь скорее просто разработчики будут какие-то свои задачи частные оптимизировать. Если мы говорим с точки зрения управленцев, то, конечно, это либо вот эта часть, либо эта часть, да. А там, как верно заметил Николай, тоже светится, потому что это блок работы человека, который, собственно, определяет ту самую архитектуру и концептуальную модель предприятия, и в том числе соответствие показателей каким-то определенным уже физическим вещам. Скажи, СТГ и ОДС, это что такое у тебя? СТГ и ОДС, вот эти колонки? Это стейдж, это просто слои. Сырой слой предварительный и уже, собственно говоря, ядрой витрины. На это можно не обращать внимания. Это слои хранилища, короче говоря. Да, слои хранилища. То есть это какой-то набор таблиц определенный, по определенной логике построенный. Вот. И действительно до управления данными часто не доходят руки. И в том числе потому, что это всегда, вот все, что вы видите, оно представляет собой огромный набор сущностей, которые тяжело человеческой голове все вместе сложить. Вообще, конечно, у нас 7 сущностей всего одновременно в памяти помещается. Просто понимаешь, как бы, смотри, почему я говорю, что не без... Почему я выперся-то, собственно, комментировать? Потому что я говорю, что мы же эту структуру с тобой много раз обсуждали, там не было этих самых... Раньше не было. ...AI, да. Но когда... Что дает добавление? Она же не механическая. Как бы мы добавляем AI, например, в слой управления данными. У нас повышается качество данных. что дает материал для AI, который ассистирует, и повышает производительность маркетинга, аналитики, финансов и так далее. То есть выходит на другие показатели в этих слоях. А когда мы в агентской, ну совсем в автоматической AI, он как бы усиливает всю систему, беря на себя автопилот решения каких-то задач. И вот так устроенная система, для меня это важно, она дает другую производительность всему, всей архитектуре и всему бизнесу, который у тебя вот здесь справа нарисован. А, соответственно, пища для него лежит в системах источники, и в этом смысле, если кто-то бы, мне важно, чтобы брали как инструмент люди эту штуку, если вот кто-то у себя это положит на доску и скажет, так, а у меня где чего, где у меня источники, что у меня есть из этих самых источников. источник, это же точка входа, одиннадцатка какая-то есть, значит, ее там же надо рисовать, одиннадцатку, правильно, в этом перечне где-то? Да, она здесь. Ну, я думаю, ГНРП, например. Правильно, дальше я сейчас спрашиваю, а из управления данными у меня что-нибудь есть? Ничего нет. А что же нужно мне тогда построить из управления данными? Дальше смотрю, а хранилище хоть в каком-то виде есть, а оно, кажется, внутри нее. А нужно ли вынести ее или там объединить две системы каким-то одним хранилищем? Тоже вопрос, который делаю. И там, соответственно, кого я... А дальше с другой стороны можно уйти, Вообще-то я хочу усилить свой маркетинг, значит, я должен сделать ассистента, а куда он там должен втыкаться у меня, через какие данные проходить, или если я хочу там логистику сделать, а могу ли я где-то какие-то функции принести. То есть я сейчас показываю, что по этой схеме можно рассуждать про себя, здесь присутствующим. Ты-то как бы про себя на ней рассуждаешь, а мы присутствующие могли бы тоже с ней работать, думая про себя, и она вполне себе здравосмысленная. Просто эти кубики, они в том или ином виде у вас должны присутствовать для того, чтобы у вас работали вот эти решения и давали вам эту производительность, которую мы все ищем здесь, внедряя. Может, его не ради развлечения внедряем. Причем кубики в любом случае присутствовать будут. Конечно, я про это и говорю, что они в любом случае, но там они чем-то замещены. Ну, то есть в каком-то виде они могут быть. Да. Саша. Есть небольшой вопрос. Вот смотрите, все вот эти подходы, хранилища, шины данных, вся остальная штука, вот каждый раз, когда это делаешь, это все очень дорого, долго и прям вот миллионы лет. Есть ли сейчас в текущих решениях такие подходы, которые бы сокращали путь доставки данных для АИ-агентов, для АИ-решений, минуя все вот эти классические подходы с очисткой данных, с каталогами данных, со всем остальным делом? Или нет? Мне бы хотелось вам дать волшебную таблетку, но ее не существует. Сейчас есть иллюзия, что мы можем просто проскочить все эти этапы, и давайте все, что у нас есть, все сырье вывалим, а он там дальше сам разберется. Но, увы и ах, нет. Я про что? Есть вот эта концепция Data Virtualization, которая говорит про то, что в большей степени для АИ требуются не сами, ну, сами данные, понятно, тоже, но их не обязательно так тщательно чистить, находить там дубли, аномалии, а больше важна слой мета-описания этих данных. То есть что это такое с бизнесовой, условно говоря, точки зрения? И в таком смысле потоки данных, которые и контроль этих данных, которые работают над тем, чтобы было качество, а они довольно сложные, дорогостоящие, они, может, не так нужны уже? Или как? Я не вижу возможности на самом деле сэкономить на качестве данных, как вы говорите, можно не обращать внимания на дубли и так далее. Потому что это то самое сырье. Воспитать человека тоже очень дорого. И, собственно говоря, это происходит вообще на протяжении десятков лет. Системы нам получается строить быстрее, а стоимость их, наверное, тоже меньше, чем стоимость воспитания человека. Мы не можем пропустить этапы, в школе не учиться, хоп, и сразу в университет прыгнуть. Такая же, к сожалению, вещь и с точки зрения построения систем Просто надо, знаете, на что смотреть? Что когда я говорю про функциональные блоки, я вовсе не утверждаю, что вам нужно взять сейчас и замахнуться Вот это все начать строить у себя для того, чтобы какой-то эффект получить Это именно функциональные блоки И мы дальше с вами посмотрим про разные этапы их построительства И будет понятно, что это можно Вы даже когда вытаскиваете данные отсюда в виде таблички складываете куда-то, а потом ее смотрите в Excel, это тоже на самом деле прохождение по этой трубе. Это, наверное, когда, как будто эта картина, она характерна больше для уже какого-то очень крупного предприятия, от уровня того же X5, SBIR, WTB или еще кого-то, где все абсолютно функциональные блоки расшиты. И тогда, ну, как бы, бери да применяй. И они как бы исторически, с учетом масштабов их деятельности, не могут себе позволить относиться к данным проще и что-то игнорировать. Да, у них исторически сложилась уже такая. Я имею в виду, представим компанию, которая плюс-минус с нуля начинает, и то ли им надо классические всякие DataGavens внедрять или из коробки их пытаться реализовывать. А, вот сейчас посмотрим. Сейчас посмотрим. У меня там дальше есть одна картинка, даже несколько. Она, возможно, ответит на ваш вопрос, но если нет, мы попробуем еще раз. Смотрите, я хотел бы просто вот эту вот большую модель схлопнуть до вот такой простой, я назвал ее там нежно обожаемым всеми нами, и Владимиру Владимировичу, в частности, соло СССР. Хороший соло. Все мы были, да, жили и дружили. Только я расшифровал чуть иначе, это собираем, сохраняем, считаем и раздаем. И вот этот тот путь, который нам надо неизбежно пройти при построении системы сбора анализа данных вне зависимости от масштаба, это то, что происходит вообще всегда. И здесь как раз, Николай, возможно, ответ на твое уточнение. Как ты видишь, здесь пользователи хотят то, что справа. И это тот путь, который на самом деле, наверное, надо проходить. То есть отталкиваться не от того, что мы сейчас идем и соберем все на свете, а потом как-нибудь что-нибудь с этим сделаем. Надо всегда идти от какой-то конкретной потребности здесь, ну, например, усилить управление запасами или оптимизировать работу своих торговых представителей в их прямых продажах. И дальше смотреть на то, а что для этого нам нужно. Ага, конечно, нам нужны там собрать данные об их перемещениях. Или нам нужно, если мы говорим про аналитику мерчендайзинга, создать систему, где будут собираться эти снимки, а потом мы построим модели? А вот можно уточнить справа, где дашборд отчеты и агенты? Там не нужно добавить API или датапродукты, которые автоматизированными системами используются? Потому что дашборд отчет вроде для людей, агенты для IT, но Software 3.0, а Software 1.0 как будто тоже там просится. Кстати, хорошее уточнение. тогда просто агентов можно вообще вот сюда вынести в отдельный блок за раздачей, потому что они будут пользоваться, собственно говоря, вот этими результатами, в том числе датапродуктами, которые имеют некоторые IP, прокинутые наружу. Вы про это, да, имеете в виду? Да, ну и про то, что сами вот системы, из которых мы что-то инжестим, там, CRM-ки и прочее, они тоже ведь ходят за информацией, которая после компьютера возникла. То есть такое может быть, что какая-то информация возникает в компьютере, вот в этом слое, и дальше переиспользуется CRM-кой, там, не знаю. Вполне, ну да, окей. Я вот про такие интерфейсы, которые в серф, по идее, должны быть для этого. Хорошее уточнение, спасибо, да. Я внесу на будущее. Действительно, это так. Дальше результатами обсчетов каких-то можно их использовать, обратно возвращать в транзакционные системы или, собственно говоря, в систему аналитики, где мы будем смотреть на какие-то агрегированные показатели. В общем, история основная в том, что мы сначала идем от задачи, потом формулируем требования, а уже на основании того, чтобы вот это все появилось, мы должны реализовать сначала вот этот некоторый контур, где мы соберем эти данные из транзакционных систем, в каком-то режиме все это посчитаем, разложим на какие-то определенные свои, в зависимости от того, как часто нам это требуется. Горячие – это нужно постоянно в течение нескольких минут. Теплые – это то, что в течение дня, например, а условно холодные – это то, что, например, может быть достанно в течение рабочего дня или даже позже какие-то определенные такие менее востребованные данные. Ну и дальше, собственно говоря, мы производим некоторые расчеты на основании где-то размещенных у нас объединенных транзакционных данных и получаем агрегированные вещи, да, либо мы, собственно говоря, даже да, я, пожалуй, с вами соглашусь, надо и агенты, и системы потребителей выносить еще правее. В общем, мы предоставляем некоторые результаты эти расчетные туда, наружу, тем, кто будет ими пользоваться. Как будто возникает квадратик принятия решений, и там может стоять человек, может стоять агент, а может еще кто-то. Да, ну как бы здесь цель этой схемы просто упаковать вот эти все разнородные наборы функциональных блоков до всего лишь четырех, которые говорят о том, что для того, чтобы мы что-то хотели добиться хорошего с использованием ИИ в том числе, мы должны сначала что-то где-то собрать, потом где-то это все разместить, потом поверх этого произвести необходимые расчеты, объединения, обогащения, агрегации, а потом это упаковать в формат, доступный для использования хоть человеком, хоть и агентом, хоть какой-то целевой системой. И здесь на выходе действительно нужны какие-то определенные интерфейсы. Таблица это интерфейс взаимодействия, да, или API тоже интерфейс взаимодействия. Скажите насчет теплых и горячих данных. Вот у нас сейчас данные T-1 в КХД мы заливаем ночью. Реально эти данные сейчас делать день в день? И это тогда теплые данные? Да. А на чем, подскажите? На чем что? На каких системах? Ну, раньше Terodata, сейчас недоступно. Вы простите, вас плохо слышно. Ладно, я потом... Да, давайте мы с вами потом поговорим про эту историю, потому что тут есть разные подходы. Здесь вот тоже возможно в качестве ответа, то, что мы с Николаем не раз обсуждали, что не надо замахиваться, пытаясь построить у себя в компании вот ту самую вот эту здоровенную схему со всеми функциональными блоками, всеми наборами продуктов, потому что это хороший способ все потратить деньги зря. Тем более сейчас время такое, когда мы не можем себе позволить большие инвестиции, и скорее задача там падать медленнее, чем конкуренты, чем активно и агрессивно расти. Еще из того, что я наблюдал, проблема построения каких-то здоровенных систем, которые могут делать все и сразу, и еще внедрить туда сразу дата-гавернанс сверху, и как бы дата-стюардов расставить по компаниям, когда компания к этому еще не готова, это приводит к тому, что люди начинают активно сопротивляться. Если, например, еще данных нет, а мы хотим внедрить какую-то систему прогнозирования, либо оптимизации, либо еще чего-то, мы еще ничего не собрали. Получится, что мы эту инфраструктуру аналитическую создадим, а туда подсунуть будет нечего. Нечего будет нашему AI-агенту на самом деле что-то брать себе на вход, потому что мы не сформировали ту базу знаний, которую можно было бы засунуть ему в контекстное окно. Кроме того, часто бывает, что бизнес-функции, о которых мы говорили, финансы, маркетинг, производство, еще чего-то, они говорят, что нам и так хорошо, нам вот это все не нужно, мы лучше знаем, нам никакие эти агентные системы или даже просто на основе машинного обучения не нужны, чтобы мы принимали решения лучше. Никто лучше нас этого не знает. И только постепенный подход и некоторая все-таки низкая определенная скорость изменений и приучения людей к тому, что это не является каким-то системой врагом, которая будет у вас забирать работу или будет теперь говорить, что вы работаете плохо, и вас всех надо уволить, а скорее помощник, способ аугментации вас в вашей деятельности. Только вот такие вот все-таки работа с людьми, и я не зря здесь написал это как в оперативно-розыскной деятельности, вербовка агентов изменений внутри подразделений, она позволит перейти к какому-то нормальному, адекватному, продуктивному использованию в средней и долгосрочной перспективе. Краткосрочные эффекты часто, попытки в краткосрочном периоде получить эффекты с использованием любых новых вещей приводят часто к саботированию. Просто потому, что вы наверняка знаете модель изменений от CAR, она в себя несколько этапов внедряет. Первый из них это awareness, desire, желание вообще это как-то применить. Ну и потом, собственно говоря, знание, возможность и регулярное использование этих вещей. И это всегда требует времени. То есть взять и сразу потратить сотни миллионов или миллиард на систему хранения, обработки и анализа данных, обвешанную всеми вот этими мешурой, это как бы путь в никуда, потому что, скорее всего, закончится ничем. Вообще даже Гартнер в свое время сформулировал очень правильную лесенку того, как нам следует идти в его случае в предиктивные модели. Но мы теперь можем говорить уже и про прескриптивные модели с применением AI-агентов, которые бы нам подсказывали или даже вместо нас говорили, что нужно делать. Это всегда все-таки неизбежный поход от того, что мы сначала в принципе собираем, каким-то образом нормально фиксируем сырые данные, очищаем их, строим для себя отчеты, понимаем, какую мы можем из этого пользу получить для своих управленческих решений. Потом мы теперь строим эти отчеты или получаем ответ на запросы достаточно быстро, а не только раз в квартал или раз в месяц. Дальше мы в состоянии уже теперь это дело моделировать с использованием современных технологий Data Science. Ну и, собственно говоря, когда мы выстроили весь этот уже pipeline, дальше нам очень просто поверх этого повесить прескриптивные системы, которые будут нам теперь сами ходить за данными и вместо нас утром писать нам куда-нибудь в WhatsApp или в Telegram, что нужно сделать сегодня или что подправить, или что какие-то там звоночки нехорошие появились. Этот технологический стэк, то есть надо понимать, применение искусственного интеллекта, которое вон там, наверху, он базируется на всем том же, что строилось у нас здесь десятками лет, и нам эти этапы нужно в рамках своей компании проходить и строить некоторую платформу данных, которая бы вот это все схлопывала и дальше подавала наверх на вход туда, на вершинку пирамидки. И эти платформы данных на самом деле не обязаны быть всегда развесистой клюквой. Вот сейчас мы как раз, отвечая на вопросы, обсуждая с молодым человеком, можем про это поговорить. На самом деле на этапе ноль, когда еще нет ничего, но есть какие-то транзакционные системы, то же самое Динеско, СРМ, еще что-то. Мы, или там система фиксации товаропотоков, какие там конкретные артикулы в контейнерах лежат и так далее, в каких-то логистических, например, предприятиях. Мы на самом деле на этом этапе ноль, желая получить какой-то эффект от аналитики, начинаем работать непосредственно с самими системами-источниками и отправляем запросы прямо туда, если у нас есть прямой и сырой доступ. Хорошо ли это? Это на самом деле вопрос большой. Почему? Когда скорость принятия решений у нас не очень высока, это не в течение дня, а вполне себе неделя, например, да, такой подход годится. В чем проблема? Когда вы отправляете аналитические запросы туда, в базу данных, которые находятся под некоторым транзакционным приложением, то, во-первых, там сама вся модель, как устроены таблицы и запись, она оптимизирована под быструю запись, а вовсе не по то, чтобы объединить несколько таблиц между собой и быстро дать вам результат. А во-вторых, ваш аналитик вполне может быть сформулирует какой-то некорректный запрос, такой бывает, и база просто повесится. А в этот момент у вас перестанут работать касса, нельзя ничего будет провести в СРМ-ке, либо еще в какой-то закупочной системе. это не классно, потому что это парализует работу компании. И если раньше эти запросы писали аналитики, и это все-таки заставляло их потратить какое-то время, и это происходило не так часто, то если мы вдруг к такому подходу попробуем применить агентные системы, которые могут нам сформулировать этот запрос некорректно и быстро его туда отправить, мы просто рискуем вообще убить всю работу. И поэтому такой подход, конечно, на этапе пока ничего нет возможен, Но на самом деле, если мы целимся вот сюда, нам надо от него переходить на следующий этап. И этот этап, он хотя бы позволяет нам минимизировать нагрузку на транзакционные системы. Это способ вынести оттуда что-то куда-то и, например, в какую-то даже простую базу данных вроде Postgres бесплатного. Просто самая основная задача вынести все из транзакционных систем туда, где можно будет безопасно применять аналитические алгоритмы или модели машинного обучения, или, собственно, ЛОМ, которая будет писать запрос и отправлять его сюда. И это позволит операционную деятельность предприятия ей не рисковать, а всю нагрузку ввести здесь. Эти блоки можно при необходимости дублировать или расширять, и эта уже конструкция будет работать. Как видите, все эти функциональные блоки, трубы сохранены, но это для масштаба мало предприятий, вполне нормальная история, где у нас есть некоторая оркестрация потоков о том, как мы отсюда перемещаем данные в некоторое хранилище, построенное на базе простой СУБД. И дальше уже здесь еще даже может биосистемы не быть. Вполне можно из Excel подключаться к Postgres и доставать данные туда запросами, ну, либо использовать большие языковые модели, которые будут писать запросики за нас, и мы будем туда их отправлять. И здесь надо понимать, что нам уже стоит готовиться к применению больших языковых моделей в будущем, да и даже на этом этапе. И нужно уже по-хорошему бы вот здесь писать комментарии в коде, которые в дальнейшем потом можно будет просить оптимизировать большие языковые модели, которые смотрят на все как на набор каких-то текстовых инструкций. И нам нужно в таблицах уже корректно ввести метаданные, то есть что это поле, что оно означает. Раньше мы совершенно спокойно могли, наверное, обходиться тем, что какой-то там админ ДБА держит все это в своей голове, он работает у нас 10 лет, ну и слава богу, все будет хорошо, то надо понимать, что уже агентной системе большой языковой потребуется, опять же, что-то написанное языком, и мы должны там внутри этой СУБД сами для себя обеспечить дисциплину заполнения метаданных правильно и корректно. Ну и, собственно говоря, здесь уже на самом деле, если мы хотим получить эффект от применения больших языковых моделей, которые будут за нас анализировать таблицы, Нам нужно переходить в сторону формализации этих Excel-отчетов. Смотрите, а есть ли опыт, когда мы не описываем, например, для АИшки, структуру данных, какие-то метаданные, а делаем наоборот как reverse engineering, потому что наверняка дофига больше хранится неописанной информации, чем описанной. Соответственно, можно ли, может есть такой опыт, загрузить сами данные, и дальше по сути этих данных, связи между ними, АИшка сама выстраивает собственно семантику этих данных. Она высказывает некоторые гипотезы на основании всего того, что когда-либо там попадалось на вход при обучении. Дальше нужно это валидировать. То есть это один из способов получения новых, в том числе этих метаданных, это загрузить весь этот набор данных и попросить, опиши, пожалуйста, его. Он скажет, на основании того, что я здесь вижу, вероятно, это то-то. Ну и дальше, собственно говоря, просто нужно это в любом случае проверить. Есть какие-то решения для этого? Можно чуть-чуть дополнить сейчас. Я сейчас тебе дополню просто. Еще как вариант не только сами данные загрузить, но еще и кодовую базу, которая их преобразованием занимается. Дать возможности IHK по ним искать. И тогда еще будет более обоснованная гипотеза. Ну это как чат GPT или в Perplexity. В Perplexity есть Space, это пространство, куда вы можете залить массу всего, это все попадает в некоторую RAC-систему, которая там строится под капотом, и потом вы пишете к ней запрос, обстукиваете об нее какие-то вещи. Просите, например, вывести там CSV-шку с описанием поля, его description и еще чего-то. Дальше, ну, то есть в необходимом вам формате. Ну, а потом вы, например, заносите это обратно. Каких-то усиленных LLM-ками инструментов качества данных, ну, типа OpenMetadata, я там у вас видел, может еще какие-то есть, которые бы позволяли, собственно, вот это делать? Нет, я пока таких не знаю. То есть мы можем OpenMetadata заменить на LLM, что ли, в каком-то виде? Нет, не получится. Но OpenMetadata это как каталог, где есть определенный набор интерфейсов. Вы можете поднимать там карточки, вы можете создавать коннекторы к данным и все прочее. LLM это может быть просто часть OpenMetadata, если когда-то они туда добавят, или взаимодействие с ней, которая бы, например, обращалась бы, перекидывая какой-то набор известных, то же самое описание таблицы, а потом обратно бы на основании того, что получено из LLM, куда-то в карточку вписывала бы сама. Такой формат можно было бы реализовать. Но LLM не замена OpenMetadate, это разный класс систем. А вот примеры какие-нибудь есть описания метаданных? буквально там, не знаю, таблица, а что описывает, насколько детально, насколько проваливается здесь, если что? Слева. А я не вижу такого вопроса. Здесь слева. Здесь я про то, что любая таблица, это не только, например, field 106, это еще и description, собственно говоря, описание того, что в этом поле находится, что это дата рождения или что это сумма за такой-то период. Мы, когда спрашиваем LLM, мы же не просим ее, посчитай нам field 106 умноженное на sum/avg/month. Мы ее просим: а посчитай нам продажи за месяц. Как понять для нее, что продажи за месяц лежат у вас в таком-то Если этого нет в метаданных, то есть это внутри SUBD описание самой таблицы, то тогда ей без этого, она этого не поймет. Вам нужно будет просто сюда в OLM, чтобы получить такой ответ на вопрос, подгрузить описание таблицы и, собственно говоря, сами эти данные. - PostGree - это просто как пример? Если бы Oracle и Debitoo... Просто пример. Это может быть не Postgres, это, ну, если у вас есть Oracle замечательно, да, превосходно. Пока еще есть. Это может быть MS SQL, MS SQL база. Это может быть любая другая реализационная. В принципе, на этом этапе, наверное, да, ClickHouse еще не нужен, но тоже как вариант реализации возможен. Это просто для примера. То есть прям человеческим языком описывать все, буквально, да? Ну там поле А, там это именно конкретное отрождение. Да, да, то есть раньше просто мы это все держали в головах людей. Я вот сам помню еще, когда мы начинали, мы с 49-ки там, ну это я лично, есть там люди, то есть с 8-кой и ранее работали. Были истории, когда где-то это хранилось у кого-то в родовском файлике описание полей, где-то это вообще не было описано, метад данных, но просто все было в голове, потому что этим там 5 лет работаешь, и тебе ничего не нужно. Ты взял сам, селект написал, потому что ты все как бы сам это знаешь. Но если за тебя писали эти select-агенты, то для них нужно на вход подавать это описание. И поэтому нужно уже привыкать его формализовать. Уже эти справочники, которые можно будет, допустим, в Perplexity Space подсунуть, у себя описывать, или, что намного проще, ввести учет прямо в самой СУБД, там просто у любой таблицы есть ее description, описание полей. Потому что потом его очень легко выгрузить и подсунуть. То есть это просто, надо понимать, что мы сейчас с вами живем в таком мире, что ИИ это вот, ну, либо уже, либо вот там ближайший год, два, три, пять, мы все туда пойдем, это у нас как бы ИИ-центричный мир, и мы теперь должны неизбежно привыкать формализовывать то, что мы делаем. И наши Excel-отчеты, они тоже все-таки, да, сейчас буквально секунду, я добавлю и послушаю ваш вопрос, они тоже должны вместо вот этих вот, знаете, я встречал совершенно разные объединенные ячейки по таблице, которые, понятно, считываются человеком, все-таки разбивать на некоторые такие структурные вещи, которые точно языковая модель съест, где у вас есть одна колонка, один сголовок, и вы как-то эту сущность таким образом выстроили, структурировали. Вот это поймет языковая модель. А если это у вас такой мерч из всего подряд здесь и где-то внизу цифры, она просто даже может не понять, что эта цифра относится к этому заголовку. Надо базу знаний организации предварительно нарезать в чанки и хранить. Это реально, нереально для того, чтобы скорость с моделями взаимодействия улучшалась? Ну, смотрите, если базу знаний нарезать на чанки, это в том случае, если вы строите свою рак-систему. Или несколько рак-систем. Ну, или несколько, да. Тогда вы для себя, естественно, режете на чанки, потом делаете имбеддинги от этого чанка, складываете это в векторную базу данных, ну или в тот же самый POSGRES, используя PG-вектор. И потом у вас на вход я и модели будут подаваться в зависимости от запроса на один наиболее близкий участок. И она будет все это упаковывать в ответ. Это одна история. Если вы планируете использовать какие-то, как вот есть у меня знакомые, публичные языковые модели и сервисы, в которых есть уже подготовленные так называемые спейсы или пространства, то тогда нет, вы просто берете эту базу знаний прям страницами и загружаете туда. Это зависит от того, вы хотите сами у себя построить так, чтобы никто не мог к ней получить доступ, или вы готовы делиться с американцами, китайцами? Это понятно. Вопрос стоит в том, что есть ли инструменты, которые будут позволять это делать, если ты предодобренных не создашь баз данных. Потому что если конвертатор может это делать быстро, то для онлайн-сервисов это хорошо. А если нет, то ты даже 2-3 минуты ждать не будешь, пока клиент хочет онлайн-сервис. У вас вопрос, есть ли система, которая быстро может нарезать вашу конкретную базу знаний на те или иные кусочки, чтобы потом дальше из нее сформировать эту рак-систему. Я честно скажу, что лично не знаю про такие оптимальные истории, еще и потому, что каждый раз, по моему опыту, в корпоративных рак-системах процесс делают индивидуально, потому что где-то размер чанка должен быть такой, где-то можно сделать его больше, но это сильно очень зависит от того, что именно там написано. Поэтому я лично не знаю, но как домашнее задание, в том числе для слушателей там будущих периодов, я себе это унесу. Мне тоже как бы любопытно в обувь в эту сторону копнуть. Можно вопрос? Да. Я вот был в зуме, там не было возможности задать вопрос, пришел сюда задать. Вот вы говорили то, что, например, есть столбец, имя клиента и нужно подписать то, что это имя клиента, но в принципе это то же самое описание, которое раньше по-хорошему нужно было делать, чтобы когда придет другой человек или сотрудник начнет смотреть базу данных чтобы он понял это в принципе те же самые требования которые были раньше абсолютно или там базу данных когда мы собираем они плюс-минус по схеме смотрю смотрел этот плюс минус та же самая база данных а что как по-другому вот например у человека есть возможность он пришел посмотрел а это имя это почитал название столбцов он понял но Но если что-то он не понял, он идет и доузнает контекст. А вот у IHK нету такой возможности доузнать контекст. Вот были ли кейсы у вас, когда нужно было прям подробно описывать, чтобы IHK больше контекста понимала, нежели что это стал без имя. Например, это имя было собрано на таком-то этапе, в такой-то таблице, при таких-то процессах, как-то дополнительно, может быть, надо описывать. И как вы это делали, если вдруг делали? Вы очень верное замечание сделали, что то, о чем я говорю про корректное заполнение метаданных, это ничего нового, это все тот же самый процесс, который опирается на уходы в 80-е, когда корреляционные СУБД появились. Просто раньше мы где-то иногда делали это спустя рукава, а теперь, если мы хотим это засунуть в контекстное окно ИИ, уже нельзя этого делать, потому что у нас нет возможности пойти у кого-то доуточнить, ну точнее у ИИшки нет возможности доуточнить. Только то, что она получит на вход, тема будет пользоваться. Поэтому мой здесь тезис в том, что теперь это у нас становится просто как обязательная процедура, если мы хотим применять продуктивно у себя ИИ. Это вопрос актуализации, приоритизации этих вещей. Раньше можно было не обращать внимания, опираясь на людей, а теперь нет. А второе, про доуточнение. Здесь можно помимо самой структуры таблицы и ее описания подсовывать в контекстное окно, еще же можно на вход подавать либо примеры уже реализованных запросов, которые показывают, как связаны таблицы между собой, либо, собственно говоря, это совестное описание. И плюс выгрузку, например, из того же бизнес-глоссария, либо возможность по ручке туда нырнуть, в котором тоже в текстовом виде описана связь вот конкретно этого показателя, который мы считаем, с сущностями, с таблицами, из которого собираются эти, может быть, комплексным. И, собственно говоря, из каких физических таблиц потом это все образуется. Для того, чтобы какой-нибудь chat GPT, например, пятый, мог бы это все дело собрать в корректный валидный запрос. А из вашего опыта этого достаточно сейчас? Вполне. Вполне. Надо понимать, что при обучении эти большие языковые модели видели много разного, совершенно, и поэтому четко сформулированная инструкция с описанием связи между собой элементов при удаче позволяет получить валидный запрос. Иногда бывает разное. То есть мы помним, что языковые модели не идеальны и могут где-то что-то придумать не то. И в программном коде, и в выборке. Но как правило, в 90% случаев передовые модели, там, код или чат GPT 5, они довольно хорошо пишут запросы, если им дать весь максимально полный контекст. С точки зрения метаданных и связи данных с рассчитываемыми показателями. Ну и дальше мы, собственно говоря, переходим в историю построения этой развития инфраструктуры уже в каких-то более крупных системах. Здесь уже может быть Oracle, Greenplum, какие-то еще существенные вещи. Ну там до сих пор есть Тиродата и превосходная, замечательная или Вертика. Здесь я просто говорю про некий такой импортозамещенный стэк. И вот здесь уже на этом этапе построения среднего такого хранилища данных у нас возникает вопрос то, что раньше просто было модным, сейчас, наверное, в свете применения и уже и больших языковых моделей в работе, и агентных систем, возникает потребность уже где-то на этом этапе посмотреть куда-то в сторону так называемых датаконтрактов и вообще, в принципе, формализации всех этих процедур, переливки данных, которые происходят. Что такое датаконтракт? Это некоторая такая вот сущность, которая с одной стороны в человекочитаемой форме, А с другой стороны, в машиночитаемой форме есть несколько языков разметок, яму, томол, которые позволяют это делать, описывает наши требования к данным. Например, это некоторые таблицы, соответственно, в ней находятся такие-то поля, они должны быть в таком-то формате заполнены, у них должно быть уникальный, либо не уникальный, еще какие-то там дополнительные внутри с точки зрения сроков поставки, актуальности данных, там еще требования прописаны. И дальше, как бы, в чем прелесть? С одной стороны, их можно использовать для быстрого знакомства дата инженеров с тем, что они получают на вход в виде продукта, который они используют где-то в другой системе. А с другой стороны, прелесть в том, что можно их с использованием даже не только агентных систем, но и в том числе классических обычных алгоритмов, встраивать в pipeline перемещение данных и проверять, что у нас на вход сюда попала табличка, которая с этим требованием соответствует. Раньше это было, опять же, такое nice to have, которое нам ускоряло инженерам работу, но поскольку мы двигаемся в сторону применения ИИ, которому нужен контекст, то есть метаданные, даже здесь уже сейчас дат-контракты становятся такой актуальной штукой, потому что мы можем с их помощью, с помощью медагентных систем в автоматизированном виде сравнивать соответствие набора данных, либо мета данных и дата контракта, и в том числе в том блоке, который акцентировал внимание Николай, куда всегда у нас раньше не добегали руки людей правоуправлением данными, использовать AI ровно для этого. Обеспечивать применение написанных требований, по сути, к структурным элементам системы хранения и обработки анализа данных в автоматическом режиме. Ну и дальше, собственно говоря, мы двигаемся в сторону построения этого самого полного фарша, и там у нас появляются дополнительные сложные блоки. В конечном итоге сейчас мы избавляемся вообще от какого-нибудь там GreenPlan, Oracle, либо еще чего-то, переходим на архитектуру WhiteHouse, где мы можем эффективно масштабироваться либо системы хранения отдельно, либо системы для расчетов отдельно и при этом еще и экономить денежные средства на содержание всей нашей аналитической инфраструктуры. А можно вопрос? Кто-то сделал что? Wayhouse? Да, ну вот Тигран из X5 одним из первых он опробировал в России и в этом году они пошли в продуктивное использование. Но GreenPlan они еще используют. Что? Пустите, не слышу вас. Суверенная это? Суверенная штука? Ну да, они построили на ванильных компонентах, то есть это был некоторый S3, подозревая, что это меню, ну, поверх этого, собственно говоря, опенсорсные версии Trina, Spark и Iceberg как каталога метаданных. Ну, в этом смысле оно суверенное, что оно собрано и работает внутри России, это не вендорский продукт, а понятно, что это некоторые заимствования из, так сказать, мирового опыта. Есть ребята, ну тоже самое GoByte, вы знаете, наверное, их у них есть, DataSapiens, точнее, Vendor, у них есть Nova, замечательный WayHouse продукт, тоже суверенный в этом смысле. Есть VK с его дата-платформой, есть еще игроки, которые тоже в эту сторону двигаются, тоже обеспечивают суверенные решения. Есть внедрение в банки, я не знаю, оно, кстати, под NDA или нет, но в одном таком красном банке, тоже применение WayHouse платформы. Есть в Войхаус платформа в Т-банке, кстати, они про это хвастывались и рассказывали. На Войхаус применяют Positive Technologies, есть такие ребята в области InfoBez. Ну, как бы достаточно. Единственное, что они еще не избавились совершенно полностью от релекционного хранилища, потому что у него есть свои определенные преимущества. Полно людей, кто с ним умеют работать, зафиксированы процессы, четко выверены процедуры, механизм безопасности. То самое, до чего вейхаусу еще необходимо дорасти. И куда все включают все время дату, сейчас смотрят про обеспечение инфобеза. Алексей, можно вопрос, пока не ушли? У меня порядка 2000 дата-контрактов сейчас между системами зафиксировано. И вопрос такой, где здесь ЛЛМ может быть полезен? Потому что я понимаю, что процентов 20 там дубли. Половина дата-контрактов может быть нормально не заполнена, не зарегистрирована в ИТАМе. например, не от темы, больная прям. Она полезна как раз-таки с точки зрения выверения этих дат-контрактов, особенно если у вас есть требования и некоторый шаблон, его структуры. Вы можете засунуть эти контракты в ВЛМ-ку и, собственно, требования к нему, для того, чтобы он вам подсказал, какие из них не соответствуют этим требованиям. То, что мы раньше делали либо людьми, либо мы это делали каким-то, не знаю, надо было загонять контракт куда-то, из-за того, собственно говоря, в скрипте делать дикт. когда дикс сравнивать с шаблоном, то есть это можно засунуть спокойно в ОЛМ, она с этим в состоянии справиться. Структуры она нормально схватывает и контролирует. То есть все, что связано с работой с текстом, а Datkontakt это всего лишь текст и структура этого текста ОЛМ, работают прекрасно. Структурирование рекомендаций по, например, каким-то исправлениям, устранениям неоднозначности, с этим тоже ОЛМ в состоянии помочь. самогрин по дат-контракт. И в том числе попробовать метаданные соотнести с дат-контрактом, понять, что что-то расходится с ним. Здесь я хотел вам привести вот такую вот схемку, которая говорит о том, что можно делать. Николай, сколько у меня еще времени? Пока надо заканчивать. Хорошо. Что нужно делать в зависимости от того, какой в компании, собственно, есть объем данных накоплен или используется. И здесь ответ, он сильно как раз от этого объема пляшет. Если данных вообще нет, ну не только о компании, а о каком-то бизнес-процессе, который мы хотим использовать, например, как раз вот тот самый, просто из последнего, чем мы начали заниматься, это как раз процесс контроля работы за торговыми представителями. Здесь иногда нужно просто в принципе создать какой-то процесс фиксации данных и их куда-то начать складывать, чтобы потом иметь возможность, накопив данные за сезон, или вот эту историю, то, что мы начали делать с одним производителем промышленной продукции, который хотел создать кнопку для автоматического выставления этой климатического оборудования в режим в зависимости от потребностей и истории использования. Там, в принципе, нужно было изначально создать процесс, снабдить это оборудование датчиками, которые бы передавали бы на регулярной основе и складывали куда-то в базу данных эти сигналы. Температура, влажность, все остальное, что было в помещении. И только когда мы смогли бы накопить достаточный объем этих данных, потом, собрав, уже можно было бы построить первые модели, которые бы просто как минимум проверили гипотезу, что потребности разные, они отличаются в зависимости от географического расположения, от розоветров и еще от чего-то. Ну и дальше, собственно говоря, когда здесь их стало бы много, ну и станет однажды много, вот там уже можно делать какие-то более крупные истории и внедрять, собственно говоря, первые серьезные модели в продуктивное использование. В общем, здесь все всегда начинается. Если это какая-то работа, выполняемая людьми, это, как правило, форма ввода. Здесь на этот счет полно разных продуктов и фреймворков для того, чтобы люди просто фиксировали свои результаты. У меня здесь как раз на столе лежит книга, я взял ее с собой, потому что на самом деле все, что я вам сейчас рассказываю, это все придумано было, наверное, еще в 1939 году. Это вот Эдвард Деминг, замечательный человек, вы наверняка слышали про него, когда на всех бизнес-школах, вообще в принципе в вузах рассказывают про цикл Деминга Шухарда «Plan, do, check, act» – такой кружок, у него четыре четверти. Собственно говоря, Деминг про него рассказал японцам про цикл Шухарда в 50-х годах и стал автором японского экономического чуда. Потому что самое главное, о чем он говорил в рамках этого цикла, это фиксация того, что происходит, для того, чтобы дальше обеспечить стабилизацию процесса и, имея статистику, что с ним происходит, иметь возможность что-то конкретно подкручивать. И вот в этой книжке как раз-таки приводится интересный пример про определённое производство и контрольные карты, где нужно было вносить вообще вручную в эти карточки люди количество дефектов из того, что они вязали спицами, прописывали. И вот это и есть по сути создание этих самых контрольных карточек, но только теперь на современных ужащах, с современными программными продуктами. И здесь у нас появляются с вами первые таблицы, первые цифровые следы, которые мы дальше уже будем накапливать для того, чтобы строить модели и все остальное. Если здесь ничего нет, то пытаться сюда каким-то образом все те большие шапки аналитической инфраструктуры наложить, будет просто бесполезно, потому что нечего будет обсчитывать, и агенту на вход нечего будет подать. Но здесь почему-то стоит под вопросом. На самом деле уже даже здесь можно вполне с AI-агентом, например, большой языковой моделью, точнее, советоваться о выборе наилучших форматов, каких-то наилучших практик. А как мне структурировать таблицу, если я хочу в ней зафиксировать какие-то показатели? А если я хочу... Ну и можно на каком-нибудь манусе первые варианты отчетности какой-то делать, и даже аналитику какую-то такую для личного пользования вполне себе начинать создавать. Уже сейчас доехало туда. Ну вот манус я как раз имею в виду, как такого рода решение, мне кажется. Да, то есть здесь это как раз-таки оптимизация... Это для личной эффективности на этом этапе, для личной эффективности. Меня как руководителя или самих сотрудников уже можно использовать. И плюс здесь можно использовать какие-то готовые сервисы, например, компьютерного зрения у Яндекса есть, у ВК есть. Если вы, например, хотите реализовать контрольно-пропускную систему, которую бы шокбаум поднимал в зависимости от номера автомобиля. Есть сервисы, которые, в частности, у ВК, они с оплатой каких-то копеек за одно изображение принимают на вход. Небольшое количество кода, использование готового сервиса компьютерного зрения, и вот у вас уже система пропуска на склад. Давай мы так сделаем, просто у тебя здесь не очевидно, как это называется, заодно докрутим твою презентацию. Значит, мы скажем так, здесь мы можем сказать, открытые системы, готовые решения, вот там AI где у тебя написано, там просто писать, открытые системы, готовые решения для работы с таблицами и для личной эффективности. Облачные сервисы. И облачные сервисы, о которых ты сказал, вот можно прямо их туда разместить. Просто потому, что здесь еще рано свои какие-то создавать. Я правильно и говорю. Открытые системы, облачные сервисы, которые вы берете и работаете со своими данными. Здесь, вот сейчас ты расскажешь, я думаю, что здесь что-нибудь для локальной, микрорешения для локальной оптимизации, какие-нибудь первые ассистенты какие-то, вот типа того, что мы вчера создавали, ну, с Яндексом или с кем-то другим. Ну и дальше, чтобы у нас такая прям получилась, что его можно из первого этапа, но меняется стэк, ты начинаешь у себя что-то онбордить. На самом деле, то есть те ОЛМ, которые вы сегодня тоже утром на рефлексе разбирали, они применяют абсолютно на любом этапе, просто для разных нужд. Если здесь уже у вас, когда появилась некоторая модель предприятий, объединяющая разные бизнес-процессы, все, которые мы рассматривали, вы можете уже строить прогнозные какие-то модели и агентные системы создавать, которые их будут использовать для совершенствования процесса, ну и уж тем более вот здесь уже это в полный рост, когда у вас вся организация как в Сберии работает, и любой может накликать тот какой-то набор данных, который он хочет, поверх этого построить какую-то аналитику или отчетность, или построить модельку, потом ее отпилотировать и внедрить в прот, то здесь еще на предыдущем этапе вы, собственно говоря, только строите какую-то сквозную аналитику по предприятию и внедряете первые модели. Но даже на этом этапе и на этом этапе те ООМ, о которых вы рассуждали последние дни, они могут какие-то вещи, которые вы делаете как люди, автоматизировать или оптимизировать. Все то, что связано с генерацией текста, с проверкой текста, с структурированием текста. Ну вот ответ тоже был на вопрос про дата-контракты, структура отчетов, форматы отчетов, код какой-то аналитический, запросов, который позволит получить какие-то нужные вам данные. Все эти вещи, они применимы на любом этапе, в том числе на этапе нет и мало, потому что они уже позволяют вам быстрее добраться до истории с много, и, собственно говоря, каким-то образом построить эту систему. Так же, как просто даже можно проконсультироваться с ОМКой по тому стеку, например, продуктов, которые можно использовать для той или иной задачи. По выбору модели машинного обучения, либо нейросети, которые используются в конкретной этой или другой задаче, чтобы, например, иметь возможность поставить задачу уже своим инженерам, либо дата-сиентистом, ну и непосредственно для реализации. Можно вопрос? Да. Мы очень много говорим про принятие решений, но очень мало говорим про execution, реализацию. Даже в вашей таблице пропущено execution, насколько в execution есть успехи? Что вы подозреваете под execution? Вот, например, мы приняли какое-то решение что-то сделать и пошли это сделали. Например, приняли решение, ну пусть будет маркетинг, где-то бюджет понизить, чтобы система пошла и понизила. Приняли решение трансформировать какие-то этапы на странице, система пошла, трансформировала, уже в связке насквозь. Я пока работаю с крупными компаниями, я вижу, что они не готовы передавать вот такой вот экзекьюшн свой полностью на агентные системы, в том числе потому, что мы говорили про ответственность, которая лежит на людях по-прежнему. И какие-то персонализированные коммуникации, такие вещи, там где все-таки цена ошибки поменьше, там да, это было сделано уже давно и по большому счету там те же самые ОЛМки современные, Они используются просто для того, чтобы эту коммуникацию улучшать, делать более персональной и вести какой-то диалог. Вы, наверное, знаете, полно этих разных мемов про рекрутеров, которые по запросу от кандидата пишут алгоритм обхода дерева. Пока это в этом этапе находится. Именно разрешение коммуникационных проблем и сокращение фонда оплаты труда на операторов. Вот там. Если мы говорим про управление, например, промышленным оборудованием, то еще никто агентной системы с использованием модели машинного обучения, не внедрял туда для того, чтобы, например, отдавать указания людям. Например, я знаю, в одном из металлургических заводов, расположенном за Уралом, ребята сделали с использованием ОЛМки, Яндексовского GPT и Яндексовского спичкита, Систему для озвучивания результатов работы предыдущей смены на сменовстречных собраниях в 8 утра и в 8 вечера. Там, соответственно, подается на вход табличка с производственными показателями, она уходит в Яндекс.Гпт, который ее описывает текстом. Потом этот текст передается в SpeechKit для того, чтобы сформировать, ну, из тексту Speech решить задачу, собственно говоря, озвучить некоторый результат работы смены. И потом он озвучивается через громкоговоритель, собственно, во время этого собрания. Вместо того, что сам бригадир шел это все читал и проговаривал. Вот такое, да. Это с чем связано? С пока еще то, что люди не доверяют или системы не могут? Скорее, люди не доверяют. Вот, например, да, Северстальдит, что они это сделали еще много лет назад, еще не было ВЛМ-ок, модель, которая автоматически регулирует работу широкопрокатного стана. Так вот, им потребовалось, наверное, год, где-то год, чтобы тот человек, который отвечал, собственно говоря, за этот участок, привык доверять этой модели и понял, что она даже работает лучше, чем он с его 10-летним, 20-летним опытом. Это все время, почему я говорил, что не надо торопиться и пытаться ломать процессы, можно просто получить какой-то неолудизм на ровном месте. Пока это так, то есть должно пройти время, чтобы мы привыкли к тому, что эта агентная система нам в 95% случаев хотя бы, ну чаще, чем люди, выдает правильное решение и никто не пострадал. Особенно производство это важно, потому что какое-то указание о том, пойти туда или сделать это, может быть сопряжено с физическим ущербом. И пока никто не готов из людей это все полностью перевести на агентов, потому что часто это жизнь, здоровье граждан. Я хотел сказать бы, что есть некоторая там, если не методология, то набор шагов, которые надо по-хорошему сделать правильно, начать с разработки дата-стратегии, которая привязана к бизнес-задачам, и дальше уже реализовывать архитектуру, собственно говоря, заниматься непосредственно исполнением и дальше обеспечить сопровождение и развитие. Но надо понимать, что в жизни у нас, как правило, опять же по циклу Деминга-Шухарда проходит. То есть мы делаем как-то, например, вот как мы смотрели с вами, с этапа 0 до этапа следующий шаг. Потом мы понимаем, что сделано плохо, переделываем. Ну и в целом, рано или поздно мы придем к тому, что получив развитую дата инфраструктуру, мы понимаем, что теперь нам надо сделать хорошо, и вот мы основательно по всем этим этапам проходим. Здесь, собственно говоря, те же самые ОЛМ-ки могут нам подсказать на каждом из этапов, с ними посоветоваться, что необходимо реализовать, или какие шаги, например, у нас пропущены. В том числе взять, например, если попробовать сгрузить в нее свою оценку по какому-нибудь ДКаму, который оценивает цифровую зрелость организации. Николай, я должен завершаться, наверное? Две минуты, да. Потому что у меня здесь есть еще блок, я оставлю эту презентацию, и он останется у вас. Вы сможете самостоятельно в свободное время ознакомиться. Это про роли, которые возникают в построении этих систем. И то, что по-хорошему для того, чтобы нам построить какую-то систему, которая будет обеспечить реализацию нашей задачи, нам было бы неплохо провести аудит того, что у нас здесь происходит, с использованием людей, ну или с использованием больших языковых моделей, если мы можем, собственно, на вход подать все наши требования, попросить ее уточнить эти требования, превратить в четкое техническое задание. Потому что от технического задания, собственно, очень сильно зависит оценка той компании интегратора, либо, может быть, внутреннее подразделение самой большой организации, оценка стоимости этих работ и доработок. Потому что нужно закладывать риски для того, чтобы интегратор не ушел в убытки. И, собственно говоря, здесь влияние ОМКИ на формулирование правильного и адекватного ТЗ, оно в этом смысле неоценимо, потому что далеко не всегда сам бизнес-заказчик, чего-то хочет, он может это сформулировать достаточно как бы правильно и быстро. Ну а на этапе эксплуатации здесь у вас уже как бы возникают чуть другие роли, которые важны, но вы по этому сможете почитать самостоятельно. Еще на завершение я тоже коротко коснусь того момента, который обещал Николаю, это про стоимость. Если мы говорим про здоровенный крупный КХД в каком-нибудь холдинги нефтегазовым, понятно, что это истории в построении в сотни миллионов рублей, да еще и там ПО и ПЛЮС железо, которое может тоже стоить, и спокойно проекты выходят в миллиарды. Но если мы говорим про уровни среднего плана организации, то это уже более такие доступные цифры в десятки миллионов рублей. ПО и железо здесь можно не морозить деньги в оборудование, а использовать, например, облачный стек, и тогда это будет обходиться в десятки раз дешевле, как минимум, в среднесрочном периоде. А дальше вы уже поймете, если вам это нужно, вы сможете уже купить конкретный набор оборудования, который будет обкатан на облачном сервисе. А дальше, когда у вас уже есть реализован какое-то там КХД централизованное, для вас там датамеш структуры, в частности, дальше уже конкретные проекты реализуются в какие-то единицы, миллионов рублей, и тоже в понятные быстрые сроки. просто потому что у вас теперь уже есть на что нашлепнуть этого. Вот AI-помощник, тоже из свежих примеров. Есть куда нашлепнуть, вы можете на вход ему подать необходимую базу данных товаров, плюс рекомендационные пометки о том, какой товар может быть замещен каким товаром, в зависимости в том числе от того, что использовал конкретный покупатель. И это уже какая-то такая более вменяемая, быстрая история. А дальше у нас с вами происходит процесс учета этих данных, процесс контроля качества этих данных. По сути, тот самый PDCA цикл, но только уже в применении непосредственно к тому самому цирью, тем самым цифровым следам, которые вы собрали в деятельности вашего предприятия. Мне хотелось бы просто, чтобы в завершении у вас осталась такая картинка перед глазами, что данные – это то, что делает вас независимыми, в том числе от поставщиков. Когда вы не просто, например, внедрили, как раньше, САП, в нем инкапсулировалось все на свете, включая и модели, и алгоритмы, и все. Как без САПа пережить, очень сложно всем туда, в эту историю переместиться. Но когда вы выносите сами данные, то, как они у вас описаны, хранятся и рассчитываются в некоторый мир идеальных платоновских вещей, а дальше эти инструменты подбираете под него самостоятельно, вы становитесь независимой от них, у вас теперь бизнес чего-то хочет и довольно быстро получает, потому что данные где-то нормально размещены, хранятся, с тобой представляют актуальные и сопровождаемые продукты. Ну а IT помогает, собственно говоря, выстраивать эту инфраструктуру, о которой мы с вами говорили, и сверху этого нашлепывать любые другие кусочки, как это, я забыл, как называется. Ну вот это. Пазлы. Пазлы. Да, кусочки пазла, которые уже реализуют конкретные AI-агенты в тех или иных системах и процессах. Ну и здесь вам тоже AOM-ки в помощь, потому что внутри передовых языковых моделей собрано большой довольно корпус знаний, и они, кстати, достаточно вменяемы, с ними можно тоже советоваться по тому, как вот этот домен данных внутри себя в компании выстроить. Ну и, в общем-то, удачи и успехов вам во всех ваших проектах с использованием искусственного интеллекта. Спасибо большое. Поблагодарим докладчика. До 13.00 у нас перерыв. В 13.00 мы продолжаем. У нас, к сожалению, позже мы не можем начать. У нас по зуму будет коллега выступать. Спасибо тебе большое.