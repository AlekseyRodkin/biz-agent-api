Так, ну давайте у нас небольшой завершающий кусочек именно лекционной части. И дальше будем переходить на практику. Можно просто слайды показать? Спасибо. Да, мы остановились на мультиагенных системах. Немного о них поговорили. Вот. Финальная тема. Вчера вставал вопрос. Хотелось бы ее немножко сегодня раскрыть. Это сравнение OnPremia versus Cloud. Я сразу скажу, не привязываясь к конкретному провайдеру или поставщику. То есть общие подходы. Тут, наверное, нету чего-то неожиданного, но пункты хотелось посвятить, какие играют роль при выборе того или иного подхода. Первое, что интересно, когда мы говорим о затратах. Понятно, что по затратам в облаке эта история сильно дешевле. Как правило, провайдеры предоставляют модели по токенам, слой вокруг моделей либо не тарифицируется, либо тарифицируется минимально. Основная стоимость потребления в облаке идет за токены моделей. Если смотреть конкретно на наш пример, на пилотных агентах, на агентах в проде, речь идет о десятках, в очень больших случаях, сотнях тысяч в месяц. Как правило, пилотирование вообще тысячи рублей и меньше. То есть это совсем небольшие деньги. Если мы говорим про OnPrem, то это, понятно, закупка серверов, это GPU, сетевое оборудование. И обычно это либо подписочные, либо бессрочные контракты. Но здесь речь идет уже о десятках миллионов и даже сотнях миллионов. То есть сразу большой капекс, который закладывается еще до того, как мы подтвердили гипотезы, что эти агенты вообще работают. Масштабирование. Тоже понятная история. Облако быстрее и гибче. Инфраструктура внутренняя ограничена физической инфраструктурой. Закупка ГПУ может быть очень небыстрый процесс, особенно в России. При этом тут нужно тоже учитывать следующий нюанс. Когда мы говорим про облачных провайдеров, это, как правило, модели, которые предоставляются большому количеству пользователей. И все облачные провайдеры, они не могут всегда 100% гарантировать одинаковое время ответа. Это нужно понимать, это нужно закладывать при разработке решений. То есть может случиться такая ситуация, что приходит пользователь и кидает в модель 100 тысяч запросов, огромных таблиц, которые нужно проанализировать. Это загружает модель, модель для других пользователей может начать отвечать дольше. То есть с учетом масштабирования всего это можно сгладить, но гарантировать всегда четкое время ответа достаточно сложно. В физической инфраструктуре здесь больше гибкости, здесь можно разграничить прямо на уровне кластера, Но это требует дополнительных ресурсов, дополнительного DevOps и так далее. Обслуживание и обновление. Понятно, что в облаке отвечает за это облако. И какой здесь важный нюанс, который стоит помнить про обслуживание. Опять же, это очень сильно зависит от типа карт и так далее. Но даже если мы смотрим чисто на уровень железа, то NVIDIA карты, самые популярные, они могут выпадать, ломаться практически каждый месяц. То есть каждый месяц, возможно, ситуация, когда карта сломалась, модель перестает печать, и нужно ее переводить на другой хост. Это очень частая ситуация. Это нужно учитывать, закладывать, в зависимости от железа, понятно, где-то лучше, где-то хуже, но это нормальная ситуация. И это только про уровень железа. Все, что выше, это все требует поддержки, самостоятельного обслуживания и так далее. Производительность. Это вот как раз то, что я говорил. В облаке, возможно, волатильность. Может случиться ситуация, что модель перегружена конкретно, и она начинает отвечать дольше. Опять же, это не у конкретного провайдера, это все провайдеры. Есть даже отдельные публикации и замеры, где как модели по скорости в среднем отвечают. Дальше. Частый самый аргумент, мы уже про него говорили, это безопасность. То есть в OnPremium у нас максимальный контроль над данными, трафиком, соответствия комплайнсу и так далее. В облаке на самом деле это тоже очень интересный момент, потому что облако делает максимально, вообще все облака очень сильно вкладываются в безопасность, потому что в облаке живет много клиентов и любая утечка это очень большие риски и пиарные, и денежные и так далее. Поэтому в плане безопасности технической облака делают очень много. Но, конечно, есть законодательство. То есть есть, например, история в России конкретно с банковской тайной. Банковская тайна — это облака не сертифицированы, или, скажем так, это серая зона для хранения банковской тайны. При этом, например, в FZ-152 персидальные данные у облака и у iStudio сертификаты есть. То есть многие считают, что MLM-ки обучаются и так далее. Опять же, этого не происходит, потому что иначе мы бы не могли получить КЗ-152 и так далее. Вот, гибкость настройки. Здесь такая вещь, что облако, как правило, дает управляемые сервисы, и они ограничены набором компонентов ручек, которые позволяют решать ряд широких сценариев, но при этом не все. То есть они все равно предоставляют какое-то ограничение. В OnPremium понятно, максимальная гибкость, можно разворачивать, делать все, что угодно на своем железе, но это, в свою очередь, ведет к нагрузке на поддержку, на DevOps, на обновления и на все остальные вещи. Стоимость владения. Стоимость владения будет очень сильно зависеть от того, каких агентов мы по итогу используем. Если мы говорим, что это пилоты, это небольшие агенты, у нас нет постоянной нагрузки, то платить по токенам сильно дешевле, потому что провайдер утилизирует железо, вы платите только за те токены, которые нужны. Если это какие-то постоянные нагрузки, условно, 24 на 7, мы загружаем железо, у нас есть столько агентов, столько кейсов, то, как правило, при расчетах OnPrem здесь получается сильно выгоднее, чем пользоваться облачным провайдером. Ну и, конечно, скорость развертывания. По нашему опыту облако это день в день пришли и начали использовать, можно тестировать, пилотировать. В OnPrem это могут быть месяцы с учетом всех проверок безопасности, развертывание, подбора команды, обучение и так далее. Это очень долгая история. По надежности в облаке, понятно, SLA обеспечивает провайдер, в он премии очень сильно зависит от требований инфраструктуры. Ну и по интеграции с экосистемой инструментов, как правило, облачные провайдеры стараются делать их максимально совместимыми с open source, с другими компонентами, чтобы… Ну, там есть много говорили про стандарты, про MCP, про A2A, про OpenAI API и так далее. В OnePrem это все требует самостоятельного выбора. Понятно, что здесь мы рассматриваем такие условно крайние варианты. То есть готовый сервис в облаке, либо полностью собирать все с нуля в OnePrem. Есть промежуточные варианты, то есть, например, разворачивание готовой облачной платформы в контуре, которая решает часть этих задач, но глобально все равно многие из вещей здесь остаются применимыми и актуальными. Вот. Поэтому, как бы, если бы глобально давать какую-то общую рекомендацию, все-таки надо стараться начинать с пилотов в облаке, проверить гипотезы, возможность сделать маскирование данных, выбрать нечувствительные данные, проверить, что оно, в принципе, заводится, работает, приносит эффект, и уже дальше смотреть, либо договариваться с командой безопасности что-то выносить в облако, что-то ставить в контур. Я скорее верю, что мы в какой-то момент придем к гибридным инсталляциям, где какие-то чувствительные данные, чувствительные задачи будут лежать в контуре и обрабатываться на локальных моделях, но часть нагрузки будет уходить в облака, просто потому что, давайте возьмем квен 235 миллиардов. Просто, чтобы развернуть эту модель, нужно 8 H сотых для нормальной производительности. Это чтобы ее развернуть. Как я сказал, GPU выпадают каждый месяц. То есть нам нужен бэкап. Бэкап это еще 8 H сотых. Уже 16,00 просто, чтобы развернуть квент 1065B в более-менее отказоустойчивой конфигурации. Если у нас растет нагрузка, это еще больше. И это я не говорю про модели типа DeepSeek. DeepSeek, если так вот задаться, посчитать, это может быть до 100,00, чтобы это была надежная отказоустойчивая конфигурация. Ну и для моделек уровня DeepSeek. Это нужно учитывать, поэтому под локальные задачи маленькие и средние модельки, под сложные большие задачи, под большие модели, скорее всего, без облаков будет сложно. Да, вопрос. Я не очень понимаю про токены. Например, возьмем задачу какой-нибудь рекомендовательный сервис. У тебя есть миллион транзакций в день. И ты можешь, например, взять и за один вечером в 12, прочитай из кавки все вот эти транзакции и сделай результат. Это будет один токен или миллион токенов потратишь? То есть ты можешь онлайн вычитывать их, либо просто ты запускаешь по расписанию один раз в день, в 12 ночи и все. И ты тогда съешь один токен. Или как это будет? Нет, вообще токен это единица, с которыми работают модели, а токены переводятся в символы. В зависимости от русского, английского языка модели. Ну, условно, там Яндекс.ГпТ, да, обучена под русский язык, у нее один токен, четыре символа. А на английском два символа, ну, условно. И в зависимости от того, сколько данных лежат в топиках Kafka, эти символы переводятся в токены, и стоимость будет за вот эти токены. Плюс инструкции, плюс еще что-то. Дальше провайдеры, в зависимости от провайдера, есть разные подходы. Например, реалтайм режим, когда мы сразу возвращаем ответ синхронный, он стоит одних денег. Но многие предлагают отложенную обработку бачевую, что просто ставим в очередь, как освобождаются карты, они обрабатываются отдельно, она, как правило, сильно дешевле, чем вот такая моментальная обработка. Поэтому тут надо смотреть уже от провайдера. Вот стоимость за токен, она будет зависеть от модели, от скорости обработки, от в целом нагрузки. Да, какую инфраструктуру закладывать? Ну, это такие очень-очень приблизительные цифры. Понятно, что мы говорили сегодня, что агент может быть что угодно, что они могут быть разного уровня сложности. Это приблизительная прикидка. MVP, как правило, можно начинать с 2-3 GPU-карт. Сейчас более-менее стандарты 600, но можно и с меньших карт начинать. Предположим, это 30 одновременных пользователей чата. Дальше обычно у нас появляются уже подтвержденные гипотезы. Начинаются агенты, которых мы хотим выводить в прот. Это уже сильно больше пользователей, ну и условно растет количество агентов. Тысяча одновременных чатов пользователей. Я такого пока не видел. по крайней мере в России. Если случится, будет хорошо. Но это идеальная ситуация, которую рисовали сегодня утром. На самом деле с лекционной частью у нас на сегодня все. Спасибо большое. Были вопросы в перерывах про AI-студию. Добавили ссылку на комьюнити в Телеграме. Там все мы находимся. Там мы пишем про все обновления в продуктах, про обучающие мероприятия и так далее. Сейчас у нас, например, идет целая серия мероприятий, где мы обучаем, скорее, технических пользователей, как работать с iStudio. Если хочется более персонально пообщаться, вот все наши контакты тоже можете писать. Будем рады помочь рассказать. Вот, наверное, я здесь сделаю паузу. И, может быть, какие-то остались вопросы перед тем, как мы перейдем в практике. Сейчас самый хороший момент их задать. Наверное, тогда задам я вопрос. Мне слышно? Что самое непонятное для вас, как аудитории в агентах? На что еще стоит обратить внимание? Что стоит подраскрыть? Можно вопрос по поводу обработки технической документации, связанной, допустим, с проектированием зданий, Что-нибудь в эту сторону есть? Да, это скорее, в широком смысле сейчас нерешенная задача, связанная она с тем, глобальный подход какой? Мы документацию загружаем в рак, и агент использует поиск по этой документации и отвечает по ней. Сложность в том, что надо как-то научиться вот эти схемы. Как правило, в этой документации очень много схем, диаграмм, графиках. Их нужно научиться правильно интерпретировать, складывать, и чтобы поиск мог учитывать информацию, которая есть в этих схемах. Какие-то простые схемы, диаграммки, текущие возможности распознавать могут, но сложные диаграммы, они пока в общем смысле остаются сложной задачей, которая либо требует очень узкого кастомного пайплайна, то есть надо специально строить, продумывать, как мы будем выделять эту информацию, обрабатывать. Это требует ненулевой разработки и ненулевого использования компонентов. Глобально, если вы сейчас в iStudio придете, загрузите документацию, как у вас, она, скорее всего, часть информации просто не найдет, она ее не поймет. Поэтому пока это требует кастомизации, посидеть над конкретными форматами файлов, научиться их правильно парсить, чтобы складывать в базу для поиска. Это самая сложная задача здесь. Хорошо, тогда спасибо большое. Передаю слово Саше Пелевскому. Спасибо. И он уже дальше расскажет про то, что мы будем делать на практической части. Спасибо. Спасибо. А, можно руку поднять? Да, вам помогут. Ссылки вам понадобятся чуть-чуть позже. Во, все работает. Кликер работает. Кликер тоже работает. Всем добрый день. Меня зовут Александр Пелевский. Спасибо коллегам за вводную теоретическую часть. Про себя не буду долго рассказывать. Я в компании Яндекс.Облак работаю больше 4 лет и отвечаю за часть сервисов AI-студио. До этого отвечал за некоторые другие сервисы Яндекс.Облак. Их у нас достаточно много, больше 70 штук. За какую-то часть из них я отвечал в части их развития, в части взаимодействия с клиентами, объяснял им, зачем они нужны, как ими пользоваться, и разными другими способами их развивал, так скажем. А сегодня мы попробуем собрать AI-ассистента или агента, или и то, и другое. Для Telegram, в общем-то, без использования какого-то кода, постараемся это сделать достаточно быстро. Я надеюсь, что у многих из вас получится. Если у вас у кого-то будут возникать в процессе проблемы, я буду прямо с вами это делать. Но если у кого-то будут проблемы, вы можете поднять руку. Мои коллеги Дмитрий и Настя помогут вам о каких-то мелочах, если вы где-то будете спотыкаться, у вас будут проблемы со входом и так далее. Для начала расскажу, какую задачу мы будем решать. Немножко придется погрузить вас в сервисы Яндекс.Облако. А кто, кстати, знаком с сервисом Яндекс.Облако, вообще представляет себе консоль. Работал там не очень много, там несколько человек, поэтому придется подробнее рассказать. Немножко очень обзорно. Мы постарались максимально упростить ваш путь для того, чтобы решить эту задачу. Ну и в общем будем ее вместе решать. В конце немножко поговорим. А решать мы будем ровно ту же задачу, которую показывали коллеги сегодня вам. Это и ассистент или бот, который поможет вам отвечать на вопросы, а можно ли работать с той-то компанией, насколько она благонадежна, какие есть риски взаимодействия с ней, и вообще сможет вам рассказывать о том, как у нее дела с точки зрения финансов, а может быть и какие-то другие вопросы. Отвечать в зависимости от того, как вы сформулируете задачу для этого агента. Вообще, если у вас вдруг под рукой есть какие-то документы о вашей компании, и вы вместо тех документов, которые мы будем использовать в процессе, готовы их использовать, то пожалуйста, мы не настаиваем на том, чтобы брать именно те файлы, которые мы нашли, публично доступные, вы можете взять какие-то свои и сделать более приближенный для вас пример и реализацию такого ассистента. Ну и нужно понимать, что Telegram это скорее просто поверхность и такой способ взаимодействия с этим агентом, который, я надеюсь, есть у всех у вас. Просто это достаточно быстро и легко можно сделать, как интерфейс взаимодействия с агентом. А Telegram у всех есть? Правда ведь? У кого-то нету? Есть кто-то, у кого нету? Нету. А кто делал вообще Telegram-ботов раньше? О, много делали. Мы тут срежем углы. Отлично. Немножко о сервисах, с которыми мы будем работать. Я уже говорил, что у нас довольно много сервисов в облаке, а часть, касающаяся AI-сервисов, объединена под такой группой сервисов AI-студио. В ней есть очень много всего. Есть генеративные модели, и open-source, и наши собственные модели. Мы ими точно будем сегодня пользоваться. Мы также будем пользоваться инструментами, которые есть поверх этих моделей. Это и инструменты создания агентов, это и плейграунд сверху, хотя он не выделен, но мы им будем пользоваться. Это и MCP серверы, все это мы сегодня на практике поиспользуем для того, чтобы решить нашу задачу получить работающего агента. Начну с маленького квадратика, который последний среди синих инструментов. Это Workflows. Это инструмент, тут на самом деле в коридорах я несколько раз уже слышал слова про N8N, другие популярные инструменты. Можно упрощенно сказать, что это такой же инструмент для автоматизации процессов, создания и приложений. Но что важно, он достаточно плотно интегрирован с нашими собственными сервисами, позволяет вам не изобретать какие-то вещи, которые мы уже за вас продумали и решили. И автоматизировать разные цепочки процессов, которые тоже можно назвать своего рода агентами, если они используют модели MCP и так далее, фактически создавать такие мини-приложения. Что там есть? Там есть палитра инструментов. В правой части вы это все увидите. Есть разные операторы логические, которые позволяют создавать циклы, создавать условия. И набор операций или интеграции для взаимодействия с какими-то конечными системами. Мы практически ничем из этого пользоваться не будем. Но точно будем использовать и взаимодействие с моделями, и с агентами AI-студию. Это выделено то, что сделано в части интеграции с ИИ-платформой и помогает строить такие ИИ-приложения поверх ИИ-студию или внутри ИИ-студию. Выглядеть это будет примерно так. Что-то похожее мы соберем, даже проще. Здесь есть какое-то ветвление. У нас его может не быть, ну и не будет. Если кому-то интересно сделать более сложное, потом можем пообщаться. Использовать мы будем фактически только один шаг, тип шагов, агент AI-студию, которого предварительно создадим. Ну и Telegram-бота. Может быть еще Switch, но это опционально. Для тех, кто никогда не взаимодействовал с нашим интерфейсом, такое обилие сервисов порождает некоторую сложность. И хочется вам дать некоторую вводную, чтобы вы не пугались, когда вы зайдете по ссылкам, которые вам прислали, чтобы вы не пугались, что вы будете видеть и как все устроено. В облаке в Яндекс.Клауде мы все присутствующие являемся фактически пользователями в рамках организации, организации Яндекс.Клауд Тренинг Хаб. И каждый из вас обладает своим собственным облаком. Это вот в блоке ресурс менеджер первая часть, и iShift 1, и iShift 2 и так далее. Это название облаков. а внутри них есть дефолтный каталог или фолдер, или папка, как угодно, в котором происходит обычно вся работа, создаются все ресурсы. У вас может быть несколько фолдеров, у вас может быть несколько облаков, но в вашем случае у вас есть свое облако, свой фолдер. Есть очень много других вещей, которыми обычно в проде клиенты занимаются. Это права доступа, биллинг. Мы их касаться не будем, это все для вас уже создано. и происходит незаметно. Вы админы в своем облаке, и никаких препятствий для работы у вас не должно быть. Маленький нюанс. Когда вы будете работать с... Когда вы будете работать с сервисами, вы будете работать как пользователь с теми правами, которые у вас есть, то есть с админом. Когда у вас что-то в облаке работает в каком-то автоматическом режиме, вызывается телеграммом, интернетом, как угодно, обычно используется тоже некая учетная запись, это сервисная учетная запись, тоже со своими правами, ролями. И необходимо там, где вы видите, практически везде указывать эту сервисную учетную запись, чтобы когда ваши процессы работают автоматически, они имели тоже какие-то права, иначе они не будут иметь доступа к чему-то, что им требуется. В общем, если вы видите необходимость указывать сервисную учетную запись, указывайте ее, она для вас уже тоже создана. Есть ряд сервисов за контуром и iStudio, которые могут вам понадобиться. Lockbox – это скорее опциональная вещь. Она предназначена для хранения разных токенов, секретов, паролей, чего угодно, что может в процессе потребоваться. Вы можете им не пользоваться, использоваться просто текстом, вбивать там, где нужно будет вбить какие-то токены. Но если вы хотите все сделать правильно, можете использовать Logbox. API Gateway нам понадобится для того, чтобы дать доступ к Telegram к нашему боту, и он вызывал наши процессы. Ну и сам Telegram, конечно. Я предлагаю попробовать залогиниться по тем двум ссылкам, которые у вас есть. с тем логином паролем, который вам должен был быть отправлен. Логины там вида AI-SHIFT 0, 1, 2, 3, 4 и так далее. И после того, как вы это сделаете, может быть в двух соседних вкладках, вы попадете в консоль Яндекс.Облако и на Вики-страничку, на которой будут некоторые дополнительные, Давайте подождем несколько минут, чтобы у всех это получилось. Получается? И у кого-то есть вопросы? Может быть, кому-то помочь? Что, не получилось? У кого-то... Так, коллеги, давайте зарегистрируемся. Или, если кто-то не сумел, скажите, почему. Если не сумел, все, дисквалификация. Смогли ли зайти по... Диплом с красного становится бурым. Присыланные ссылки, присыланные логины и пароли. У кого не получилось? Настя, можешь помочь коллегам? Подличный. Там внизу слева есть переключатель. Вы можете переключиться на другую учетную запись другой организации. У кого получилось? Другой вопрос. У всех почти, я понял. Хорошо. У нас еще будет несколько слайдов, поэтому у тех, кто не получилось, будет время это сделать. Что мы видим? Давайте еще пару минут подождем. Настя, а? А какой вы открываете? Это Вики, да, это первая ссылка, там еще есть вторая, вот это видимо соседняя. А, это ваша. А, это ваша консоль. Вы сможете под этой же учетной записью зайти в консоль. То есть у вас внизу есть переключатель пользователя, вы можете из своей учетной записи выйти и зайти с той, которая у вас есть. Ну, они обе понадобятся, на самом деле. Вот, консоли вики. Ну, почти у всех получилось. Можно попробовать в инкогнито режиме. Взаимопомощь пошла. Давайте я дальше продолжу. У нас там буквально пару человек не справилось. Мы им сейчас поможем. Мы видим консоль Яндекс.Облака. В левой части мы видим навигацию, дерево навигации, где есть как раз информация о нашей организации в самом верху, где есть со значком облака наше облако, в котором мы работаем, и фолдер. Мы находимся фактически в фолдере, где будут представлены сервисы, которые мы будем создавать или использовать. И здесь уже есть несколько сервисов, которые по умолчанию создаются. И есть как раз сервисный аккаунт, который мы предсоздали для вас. В сервисы AI Studio, с которыми мы работаем, можно попасть прямо отсюда. Вот здесь есть короткие ссылки сразу на эти сервисы. А можно еще зайти в меню все сервисы и поискать их там. Там такой же блок AI Studio, это то же самое, если что. И работать мы будем, начнем по крайней мере работу с сервисов AI Studio, куда я вам предлагаю переключиться. А я сейчас открою на своем ноутбуке консоль, и мы вместе будем дальше двигаться. Итак, мы переходим в интерфейс AI Studio, где мы видим описание всех возможностей, которые есть в платформе. Возможности создания AI-агентов, подключения или создания MCP-серверов. Все нашли AI Studio? Можно сверху выбрать все сервисы и вот здесь полистать чуть ниже. Это все не нужно. Вот здесь есть E-Studio. Даже можно вот так сделать. У кого не получилось? У всех получилось. Мы хотели создавать E-агента. И прямо такой раздел мы здесь видим, создать E-агента. Прямо можем туда провалиться. и нажать кнопку «Создать агента», где нам будет предложено достаточно небольшое количество настроек. Создать агента, да. Если мы в AI-студию находимся, вот здесь. В AI-студию, для того чтобы перейти в AI-студию, вы можете лучше всего вот здесь, во всех сервисах, найти EI Studio и щелкнуть на нее. Там мы видим практически самую первую кнопку, которая есть. Это создать EI агента. Это именно то, что мы хотим сделать. Нажимаем кнопку создать агента, придумываем какое-то имя ему, Это не важно. Здесь же мы можем выбрать модели, которые мы хотим использовать. Я рекомендую использовать либо Яндекс.Гпт 5.1.Про, либо Квен. Давайте Квен. И здесь есть… А какая мощнее? В разных случаях по-разному. Дима должен был создать агента. Дима вам наверняка рассказывал про разные настройки, про температуры. Дим, давай про температуру комментарий нужен. Я могу сам, но я что-нибудь навру. Про векторы, да. Вектор немножко в сторону. Температура. Дима вчера много говорил, что по сути, что такое генерация языковой моделью, это подставление следующего слова. То есть с какой-то вероятностью она выбирает следующее слово. И вот эта вероятность, я могу брать всегда слово, у которого наибольшая вероятность, что оно будет следовать за предыдущим сообщением. А могу взять, например, не самое вероятностное, а второе, чуть менее вероятностное, или третье вероятностное. И вот чтобы вот этот подход обобщить, ввели такой параметр, как температура. Грубо говоря, она отвечает за креативность ответов. То есть если у меня температура супер низкая, то я всегда выбираю самое вероятное слово, и модель такая достаточно строгие ответы дает. Если у меня температура высокая, то она может сильно креативить, придумывать какие-то более специфические словесные конструкции. И глобально, как ее выбрать? Если мы говорим, что у нас агенты, которые должны четко отвечать по документам, лучше температуру ставить ниже. 0.3, 0.2, 0.1, это близко к нулю. Если мы хотим какие-то общие задачки на креатив, придумать что-то, какие-то необычные формулировки, то температуру можно ставить близкую к одному. Для примеров всех вокруг агента рекомендуем использовать не больше двух. Ну, там 0.3, 0.2, как бы примерно так. Отвечая на вопрос про Квен, Яндекс.ГпТ.Про, скажем так, больше сама по себе модель Квен. Она очень большая, она дольше отвечает. Как выбрать модель? Квен чуть лучше справляется с вызовом большого количества туллов, чем Яндекс.ГпТ. Поэтому мы делаем пример на ней. Яндекс.ГпТ хороша для сценария агента. То есть если вы выбираете инструмент поиска по документам, только его, то я бы рекомендовал работать с Яндекс.Гпт. Она быстрее, она хорошо не придумывает ничего. Если много тулов, то я бы начинал с квена. Если много тулов, в них надо ориентироваться. у этих тулов каждого свое какое-то описание, нужно в нем ориентироваться и более креативно подходить к решению задачи, то, наверное, да, я предлагаю начать с квена. Но, в принципе, вы можете просто попробовать в процессе и одну, и другую, сравнить результат и с этим, в общем, поиграться. И это практически все настройки, которые вам нужны. важно задать правильную инструкцию для агента, системный промп, так называемый, и объяснить вообще, какую задачу будет этот агент решать, для того, чтобы при поступлении в него каких-то вопросов он понимал, кто он и за что отвечает. Поскольку мы делаем агента, который анализирует для нас финансовое состояние компаний, с которыми мы, например, собираемся работать или хотим получить о них информацию, мы ровно это и напишем, что ты консультант, или аналитик, я сейчас буду писать, но общий смысл такой, вы можете от себя это написать, вы должны написать здесь следующее, что ты агент, который отвечает за анализ финансового состояния компании, ты даешь рекомендации по тому, работать или не работать с этой компанией, оцениваешь риски и потенциальные проблемы, которые могут быть при работе с этой компанией. Вот примерно такой простой промп, я предлагаю с него начать и, собственно, это сюда и вписать. Поскольку мы дальше будем использовать инструменты, можно также дать сразу инструкцию агенту о том, что обязательно используя в своей работе инструменты. Потому что модель, в принципе, может в какой-то причине решить, что это ей не нужно. Или у нее, например, есть информация уже, которую мы запрашиваем, и она посчитает, что это лишнее. Поэтому можно ей явно тоже дать на эту тему инструкцию. Я сейчас это напишу. Мы хотим создать агента, ассистента, который нам будет подсказывать, давать информацию о контрагентах наших. То есть вы можете или не можете работать с компанией Яндекс.Облако, например. Я хочу узнать. Или любой другой компании, про которую вам нужно получить информацию. Поэтому такой агент, его инструкция для него будет выглядеть примерно как я написал. Я сейчас ее сюда тоже впишу, чтобы дальше двигаться. Другой запрос делаешь, да? Не, такой же, в принципе, как он сказал, своими словами. Типа по оценке благонадежности. Веб-класс. Вот какой-то такой промпут я написал. Точность его не очень будет иметь значение. На самом деле важно подобрать правильный промпт, потому что результаты могут отличаться немного или много в зависимости от того, как вы поставили задачу. В качестве инструментов у нас есть несколько возможностей. Я бы для начала показал, как у нас работает инструмент WebSearch. Фактически это инструмент, который будет искать в интернете по публичным страницам в том или ином регионе, в данном случае в России, мне более интересно. будет искать эту информацию просто по публичным данным в интернете. Начнем с этого инструмента. Я тут явно указал модели, чтобы эти инструменты использовались. Ничего ли я не забыл? Ничего не забыл. Я нажимаю кнопочку создать. Нет, мы инструмент веб-серч используем для начала. Мы их на самом деле все попробуем. но попозже. И на этом мы могли бы разойтись, потому что мы уже создали агента. Вы можете здесь в правой части его потестировать, позадавать ему вопросов каких-то и проверить, что он действительно работает, получает информацию из интернета. Я сейчас это сделаю и прокомментирую, что я вижу. Дим, ты еще раз хотел? Пока Саш тестирует, просто хотел показать очень полезную вещь, неочевидная, но очень многим помогает, особенно если собирать первые прототипы. Когда вы настраиваете инструмент поиска, у него есть такая настройка, как домены. По сути, это возможность ограничить поиск в интернете каким-то одним конкретным сайтом, ну их может быть до пяти штук. То есть, например, если вы хотите построить агента, который отвечает на вопросы только вот по конкретно вашему сайту и в принципе ничего больше в интернете не смотрит, то здесь можно вот прям в UI указать его домен, там, yandex.cloud. И тогда это будет работать следующим образом. Модель понимает, что ей нужно сделать вызов инструмента. Дальше поиск проходит только, то есть он технически ограничен только конкретными сайтами, которые вы указали, то есть это прям отдельный индекс поисковый. Там находится нужная информация, придется модель, и дальше уже модель по ней отвечает. То есть это очень часто первый хороший прототип, чтобы сделать, например, чат-бот по сайту. Нет, нет. Это работает достаточно быстро. Здесь вот у меня отвечает достаточно долго, только потому, что как раз, по-моему, я квин использовал. Если кто-то выбирал Яндекс.Гпт, то ответ этот сильно быстрее приходит. Да, тут что? Если вы хотите... А, вы можете сказать, отвечай мне на русском. Прямо в инструкции. Скорее всего, он мог в интернете найти текст на английском, когда обратился, передал модель, и модель по ней отвечает. Почему вот так вот выглядит ответ? То есть это то, что мы тоже уже обсуждали. Модель как Venn достаточно большая. Она может долго отвечать, и часто это обходится тем, что мы используем режим стриминга. То есть модель начинает печатать. Мы еще не успели его добавить именно в UI. Через API оно будет работать через стриминг. Но глобально что сейчас происходит? Модель получает этот запрос, понимает, что ей нужно сделать вызов инструмента WebSearch, идет в поиск, берет весь огромный контекст поиска и отвечает по нему на вопрос. Достаточно быстро. Можно попробовать. Пока еще подожду 30 секунд. Попробуем. У кого-то получилось ответ модели увидеть? Нет, не отвечает почему-то. Ничего не происходит. У меня она показывает, что пользователь. Вряд ли мы смогли. Яндекс.Джип.Ти, да. Давайте попробуем другую модель выбрать. Вам ответил. Квен. Про. 5.1. Давай прокомментируем. Вызов инструмента, он на самом деле может быть очень объемным, и может случиться при полнении контекстного окна, как случилось у одного из ваших коллег. Что в этом случае делать? Ну, пока в UI это не очень фиксится, можно попробовать переформулировать запрос и корректировать вебтул до определенных доменов? Можно ограничить набор доменов, можно сделать какой-то более точный вопрос. Но я уже вижу, что с помощью инструмента вебсерч, то есть поиском по интернету, агент ответил на мой вопрос и рассказал мне в соответствии со своей инструкцией о рисках, о состоянии компании и дал какое-то заключение о том, что с компанией возможно и перспективно работать. Давайте еще пару минут подождем, чтобы у всех появился какой-то первый результат. Говорит слишком, вывалился сам за свой предел размера текста. Вот, это как раз то, о чем мы говорили с Анастасией, что можно ограничить, либо ограничить домены, по которым мы ищем, или немножко более точно сформулировать вопрос, или сказать ему, дай мне ответ в один абзац. То есть, вот как пытаться ограничить работу модели для того, чтобы она не… А это вывалилась сама модель или результат поиска слишком большой? Ну, это скорее особенность реализации в UI. Вот так. В смысле, ничего не понял. Кому подойти помочь? Наша цель, чтобы мы получили какой-то первый ответ от агента, фактически получили первого работающего агента. Это достаточно большой промпт и сложный. И если на это все еще накладывать результаты в Эпсерча, то многовато. Это скорее… По ним происходит поиск. То есть не то, что они все грузятся, по ним поиск делается уже. То есть в модель попадает результат поиска. Ну и каким-то ранжированием. Топ-мен ответ. Давайте немножко прокомментирую. У всех сейчас появляется ошибка с размером контекста. Что происходит? Происходит следующая проблема. модель обращается в поиск и берет весь контекст страниц. Сейчас там по дефолту стоит параметр 5 страниц. То есть, представьте, она берет текст с 5 страниц в поиске, передает в модель, и модель пишет, что квен просто долго работает, потому что очень большой контекст. Яндекс.GPT пишет, что это все не помещается в ее контекст. Попробуйте, пожалуйста, переключиться на модель GPT OSS 120B. У нее и большой контекст, и она быстрее отрабатывает квена. И, по идее, все должно работать. Это первый пример, где начинается отладка и где могут возникнуть проблемы. По сути, сейчас мы подбираем модель с учетом размера контекста, скорости ответа. И задачи. И задачи, да. И инструментов, которые мы используем. Я OSS выбрал. Первый был QN, потом ответил Яндекс.Гпт. Кстати, достаточно быстро я получил тоже результат, даже гораздо более подробный. Да, смотрите, вот этот вот значок значит, что произошел вызов инструмента WebSearch. И для тех, кто сильно хочет погрузиться в детали, вот, Саш, чуть-чуть выше, там есть вот значок, да, Если ты его нажмешь, тут технически идет расшифровка, какой инструмент был выбран, как он был вызван, с какими параметрами и так далее. Кстати, про запрос «Почему на английском?» моделька сформировала запрос на английском, типа финансовая стабильность Яндекса. GPT-OSS решила, что на этот вопрос лучше сформировать поисковый запрос на английском. Можно в промте и прописать, что делай запросы на русском. Но в целом агент сделал заключение, описал минусы, плюсы, возможность или невозможность работать с этой организацией. Ну и, собственно, вы можете на любой организации потренироваться. Агент не только, понятно, про Яндекс.Облако отвечает, про любую организацию, по которой мы хотим найти информацию публичную. Более-менее у всех получилось ли кого-то еще подождать? Или мы подойдем, поможем? Вот коллеги там, да. Давайте дальше посмотрим, что еще мы можем с этим сделать. публичная информация, ну фактически мы сэкономили себе немножко времени на том, чтобы там листать поиск в Яндексе и все странички, которые мы можем найти. Это само по себе полезно, но нам хочется получить больше. Например, использовать поисковые индексы, про которые говорил Дима сегодня, и загружать информацию в агента, которая может быть специфична именно для нашей компании, или для наших контрагентов, или в общем какие-то данные. Если мы хотим, чтобы их использовал агент в своей работе, они могут быть не публично, не доступны интернете, но мы хотим их использовать для работы агента. Для этого у нас есть другой инструмент. Это инструмент поиска по файлам, по поисковым индексам. Здесь он называется Retrieval. Мы его добавляем и нам предлагается создать поисковый индекс. Для того, чтобы создать поисковый индекс, мы нажимаем кнопку создать поисковый индекс. Я взял публичные файлы, публичные отчеты. У вас есть ссылки на них в вашем LMS-системе, в которой вы работаете. Я видел скриншот, они точно там есть. Вам ссылку присылали. Можете взять какие-то свои файлы. Если вы хотите посмотреть, как на ваших данных это будет работать. Здесь, опять же, есть некоторые настройки по тому, как обрабатывать эти файлы и загружать в поиск. А подскажите еще раз, где этот индекс находится? Вы когда нажмете «Добавить инструмент», сейчас я покажу. Вот здесь есть кнопка в фоне на заднем плане «Добавить инструмент». Называется инструмент Retrieval. И когда вы его выберете, вам будет предложено создать как раз поисковый индекс, добавить в него файлы любые. В данном случае у меня есть какое-то количество финансовой отчетности публичной по некоторым компаниям. Но в идеале инструмент предназначен для того, чтобы вы все-таки туда загружали какую-то свою специфичную информацию, которые нет в интернете, какие-то инструкции, описание ваших продуктов, часто задаваемые вопросы, что угодно, на что в интернете найти ответ нельзя. Вот там вопрос, да, я вижу. Ну да, распаковать. Правильно ли я понимаю, если я задаю домен, например, ограничить какими-то сайтами, то если на сайтах выложена информация, например, в формате доков, экселев и так далее, он ее не возьмет, а ее надо грузить как ретриевал. Да, если у вас информация в виде PDF, в виде каких-то Excel таблиц, в виде PowerPoint презентаций, документов DOC, то вы все это можете загрузить в инструмент векторного поиска, создать поисковый индекс для того, чтобы агент использовал его в своей работе и предоставлял информацию с учетом этих файлов. А можно будет загрузить, например, ссылку на корпоративный базу знаний Confluence? Это чуть позже я отвечу на ваш вопрос. Здесь именно какие-то отдельные документы. Это файлы, которые мы под капотом разберем. А много можно? Много. По-моему, 150 мегабайт на один файл, а файлов может быть тысячи или сколько-то прилично. Ну да, на всех ограничениях 10 тысяч, но это ограничение тоже повышается, может быть до миллиона и больше. А количество чанков что такое? Чуть-чуть назад, Дима. Да, смотрите, вопрос, что такое чанки. Когда мы с Настей рассказывали про рак, мы говорили про то, что когда мы складываем наш документ в базу знаний, он разделяется на фрагменты текста. То есть что происходит? Берется весь документ, бьется на фрагменты и складывается такими фрагментами в базу. Этот фрагмент это и есть чанк. То есть зачем это делается? Чтобы в модель не весь документ передавать, а передавать только нужный по информации кусочек. Поэтому там есть параметр количество чанков, его можно стандартное количество 5, 3. Оно не тратит очень много токенов, но достаточно, чтобы найти нужную информацию. Что значит количество чанков 5? Мы делаем запрос в RAC, мы делаем поиск, он находит 5 фрагментов текста, передает их в модель, и модель отвечает только по этим 5 кусочкам, по этим 5 фрагментам текста. Вот эти все настройки расширенные, их оставляйте как есть, они подобраны хорошо, довольно оптимально. Вот, тип индекса гибридный. Фрагменты, они большого размера? Фрагменты, они по деполту 1000 токенов, 1000 токенов, например, 4000 символов, один фрагмент. А можете подсказать, вот этот вот справа чат, где тестирование, можно ли его как-то очистить? Описания можно не делать, да. Они все равно будут в индексе, они больше для вас нужны, эти описания. После того, как вы создали поисковый индекс, для того, чтобы немножко упростить модели жизни, получить более гарантированный результат, Я бы удалил тот инструмент, который мы создавали. В принципе, вы можете его оставить. Это поле для экспериментов, посмотреть, будет ли он использовать либо одно, либо другое, или то, и другое, возможно. То есть там разные модели будут по-разному себя вести. Кто-то возьмет в оба инструмента, сходит, кто-то получит информацию из первого, поймет, что вроде бы все уже понятно и забьет. То есть здесь не совсем может быть гарантированным поведение. Я для того, чтобы просто показать, что это действительно используется, уберу сейчас инструмент WebSearch и все. И пересохраню своего агента и задам ему вопрос по какому-нибудь из документов. Я знаю, что у меня там есть отчетность по N-компании, и буду по ним что-нибудь спрашивать. Хочу убедиться, что действительно по ним будет получен результат. Файлы, которые у нас лежат, их можно тоже посмотреть. На поисковый индекс можно посмотреть. И я вижу, что вопрос в поисковый индекс действительно случился. И на основе тех файлов, которые я загрузил, была получена информация. Была получена и сформулирована ответ агентом, исходя из его промта. То есть я оцениваю возможность и невозможность работы с компанией, анализирую и хочу рекомендации, потому что можно с ней работать или нет. Что, собственно, он не ответил с учетом той базы знаний, которая у агента есть. Они есть у вас в LMS, у вас три ссылки было прислано вам. Одна на консоль, одна на вики и еще одна на вашу LMS, где есть эти файлы. Вот, вот это файл. Вот, вот это вот. Я добавил все эти файлы. А вот загрузить кнопочка. Я их скачал сначала, потом загрузил. Да. Ну, он может пару минут повисеть. Они там, по-моему, достаточно большие файлы. Ну, то есть один файл добавится достаточно быстрее. В принципе, если оно еще так повисит, 2-3 минуты, можно попробовать повторить. Векторной базы нет. Она под капотом. Я уже пробовал, не хватает каких-то. А вот сейчас как действует? Может быть, на последнее время? Ну, здесь есть, здесь, да. Ну, вы можете свои чанки принести и записать их прям чанками. Дима, расскажи про то, как принести свои чанки. Там есть вопрос. Да, давайте. А я попросил рассказать компанию МТС. Я отдельно отображаю контент основной информации, также подкружаю в метадату какую-то историю. Конкретно, допустим, по одной какой-то записи, если необходимо. У нас разные модели. У нас разные модели, разный промпт чуть-чуть. Возможно, у меня более детальный, я его явно прошу описать, финансовое состояние, что-то еще. Поэтому мой ответ более полный. В общем, в этом и есть суть. Поэкспериментировать и с моделью, и с инструкцией для модели для получения более точного ответа в соответствии с задачей этого агента. У всех получилось? У кого не получилось? А, еще думает? Давайте еще пару минут. Вы можете позадавать ему вопросики. Я спросил, какой максимально... Да, но вы можете спросить, можно ли работать с компанией ВТБ. А у вас не загрузился, еще индекс поисковый не создался. Все понятно. Давайте подождем. Там вот у Анны, у некоторых еще не создается индекс. Долго файликов накидали. Много. Вы находитесь в режиме редактирования. У вас почему-то вроде редактирования, а вроде нет. Давайте мы сейчас делаем вот так. На всякий случай вот так. И вот теперь попробуем Да, это же он, да? Вот теперь попробуем еще раз Это что-то подвисится Да Да У кого еще висит создание поискового индекса? Анна? Заново? Он у вас, может быть, создался уже, проверьте, может, он уже там есть. Вы можете вот сюда зайти, убедиться, что и файл загруженный, и поисковый индекс создался. Почему их у меня два? Интересно. Почему-то два. отвечает на вопросы или индексы сдает? У кого не получилось спросить, агенты получить ответ по базе загруженной? Настя, давай еще поможем. Не знает ничего про SZD? Попробуйте Квен как модель, попробуйте Яндекс.ГпТ. Вот здесь надо… У СС у вас получилось, да? У всех моделей могут быть нюансы. Может быть, надо в инструкции сказать, что тебе будут приходить вопросы. Это тоже может помочь. А у кого логин 55? У вас? Мы с вами в одном фолдере работаем. Мне сказали, что будет до 50 человек. Если хочешь таблицы, ты в ману. на самом деле приходим к тому пайпу, что будет все хорошо. Может быть, ребята уже выкатили. На самом деле у нас сейчас уже парсер локальный раскатан хороший, может быть, мы скоро выкатим. Значит, на самом деле хорош парсером. Я пользуюсь парсером, который работаем. Я ему практически не знаю, что это работает. Это подробно. Таблица. название можно сказать что я делаю Причем они для этого не имеют. У всех ли получилось создать поисковый индекс и попросить агента ответить по данным этого поискового индекса и получить результат? Или так, у кого не получилось? Видимо, у всех получилось. Отлично. Мой агент уже умеет искать информацию в интернете, умеет использовать базы знаний и файлы, которых, возможно, в интернете нет, но специфичны для моей организации. И Дмитрий рассказывал про MCP и возможности агентов взаимодействовать с внешними системами. И я бы хотел, чтобы для анализа контрагента агент еще и воспользовался какими-то внешними инструментами, а не только файлами или публично доступной информацией. Я тут снова, наверное, удалю в качестве инструмента индекс поисковый, чтобы просто не усложнять. И попробую добавить MCP-сервер как инструмент для моего агента. У меня пока нет ни одного MCP-сервера. Я его создам. И есть разные способы того, как можно создать MCP-сервер. Я могу перечислить какие-то API моей внутренней системы для получения информации. Здесь были вопросы про то, как создавать MCP-сервера. Но у нас есть и ряд шаблонов, готовых от наших сервисов или сервисов-партнеров. Если бы, например, у меня была AMA-CRM, возможно, я бы мог туда сходить. Но у нас есть шаблон Contour Focus, а это как раз сервис, который занимается предоставлением информации о реквизитах, о разной финансовой информации о компаниях, делать скоринг рисков работы с ними по нескольким параметрам. И я буду использовать MCP сервер контур фокуса в работе своего агента. Для того, чтобы это сделать, я выберу шаблон контур фокуса и попробую добавить инструменты и параметры. То есть настрою этот MCP сервер, создам свой на самом деле, для того, чтобы с ним работать. Контур фокус – это сервис не общедоступный, он платный. И для доступа к нему нужны ключи. У нас для этого мероприятия такие ключи заготовлены. Они есть во второй ссылке, которая у вас есть в Вики. Сейчас есть она у меня тут. Вики Яндекс.Ру, да, Slash Federation. Наверное, я там уже был. На этой странице в ее правой части есть ключи, которыми вы можете воспользоваться. На них на каждом есть некоторые ограничения, поэтому лучше возьмите свой для вашей учетной записи и используйте его в настройках создаваемого MCP сервера. Вот здесь есть кей, такой параметр. Нужно взять ключ, сюда его вставить и нажать. Мы выбираем шаблон контур фокус на заднем плане вот здесь при создании МСП сервера. Дим, можешь сюда еще подойти? Пока остановиться или дальше идем? Вот, молодой человек. Да, мы знаем, что мы можем пойти в компанию Contour Focus и купить у нее этих ключей. Или у вас уже есть этот сервис, и вы можете их там как-то получить тоже эти ключи. Ну, вот они у нас тут уже есть готовы. Ссылка на Вики. Это одна из трех ссылок, которые вам отправили в чате. Там же, где была консоль, вики. Вот эти ключи на вики лежат на страничке. И здесь был вопрос, кстати, про базу знаний, раз уж мы тут вики используем, был вопрос про конфлюенс. Правильный способ заставить агента ходить в конфлюенс, это реализовать, а лучше не реализовывать, а скачать с докер хаба уже готовые MCP конфлюенса, Самый простой способ – развернуть его и сказать агенту через «подключить», там вот вторая кнопочка, вы сможете сходить в произвольный MCP-сервер, развернутый у вас. Это, наверное, первый простой способ. Второй простой способ – вы можете реализовать поверх API Confluence свой MCP-сервер, просто добавляя, там была возможность именно HTTP вызовы указать для поиска страниц, для создания страниц, для получения информации страниц. Вам не так много вызовов понадобится, буквально 3-4, и вы сможете свой MCP сервер просто сделать. А как он будет тогда использовать механизмы поиска, которые доступны по API Confluence? То есть он не будет засасывать к себе весь контент? Нет, это просто сильно сложнее и дороже. Вам гораздо проще сначала сделать поезд, как вы уже сделали. А в этом и проблема, что очень плохо находит. Да, после того, как мы на самом деле для получения списка инструментов, здесь мы видим список инструментов, которые предоставляет нам наш MCP сервер. Это инструменты получения экспресс-отчета, инструменты поиска информации по компании. Их здесь несколько, мы их на самом деле выберем просто все, либо нажмем здесь добавить все, либо почитаем про них и осознанно это сделаем. Но мы хотим, чтобы наш агент использовал максимум инструментов, которые есть в этом MCP, мог и искать, и получать экспресс-отчеты, и скоринги. Их вообще у контура достаточно много, но вот в MCP реализовано всего несколько. И после добавления мы увидим, что наши инструменты здесь добавлены. Точнее, да, добавлены в MCP-сервер. Какое-то можно придумать ему имя. Любое. А еще разочек. Можно понять, где ключ к MCP взять? На вики-страничке. По адресу wiki.yandex.ru. slash federation, slash длинный ID-шник. Это одна из трех ссылок, которые вам вначале отправляли. И там нужно вниз прокрутить. Там просто не очевидно, там надо вниз прокрутить. Все эти ключи внизу вики лежат. А, внизу? Да, там ты открываешь вики, и там сначала идет просто текст. Текст про GQ. Так, смотри, у меня нет. Ну, выглядит по-другому. Это широкий экран очень видимо. Вот, найдите лучше свою учетную запись здесь, чтобы просто не потратить ключ коллег. Сервисный аккаунт здесь можно не выбирать. У вас публичный, я предлагаю использовать публичный доступ. Вы можете ограничить доступ к своему MCP серверу, но это все сейчас не очень важно и нужно. Можно вот логи еще включить. И после этого мы нажимаем сохранить. У всех получилось создать свой MCP сервер? Спасибо. Да, смотрите, здесь в названии MCP-сервера используйте, пожалуйста, маленькие буквы без цифр и дефисов. Такой есть прикол. У тех, у кого не получается хранить, проблема была в этом. Для тех, кто создал свой MCP-сервер, фактически уже имеет возможность подключаться к внешнему сервису, мы возвращаемся на вкладочку редактирования агента, где он появился, и мы можем его выбрать как инструмент, доступный нашему агенту. Это, скорее всего, соседняя вкладка. И здесь же будет ряд настроек, я их сейчас прокомментирую, но мы их не будем использовать. Мы можем вот здесь в диалоге, в работе с агентом сказать, что если ему надо туда ходить, в этот инструмент, то ты у меня спрашивай, не против ли я, что агент будет использовать этот инструмент. Мне в принципе не хочется каждый раз это подтверждать. Я скажу, что не надо мне подтверждений, просто ходи в эти инструменты и дай мне эту информацию. После того, как я сохраню, я предпочитаю для того, чтобы более гарантированно сейчас результат вам показать, его отключить. Ну, потому что он может получить информацию из интернета, и я не смогу вам показать, что вы воспользовались MCP-сервером. После этого вы можете такие же вопросы начать задавать про компанию МТС, или Яндекс.Облако, или РЖД, или какую угодно другую, и посмотрим, чего будет. Да, получить взаимодействие с какой-то внешней системой. В данном случае с сервисом Contour Focus. А как приоритизировать источники, чтобы он вначале, например, брал данные из файликов приложенных? Да. Сейчас. Товарищи... Раз-два. Приоритизацию можно описать в промте. То есть, приоритет инструмента вы задаете в инструкции к модели. После того, как вы создали MCP-сервер, вы возвращаетесь обратно в агента, и у вас появляется выбор, какой MCP-сервер вы хотите использовать. Вы говорите, да, я хочу. Нашли? Так, вы его редактируете. Вот здесь хотите подредактировать. Давайте вниз, вниз, вниз. Я рекомендую брать вот search, чтобы он не ходил в интернет, а вот ходил только. Ну, вот здесь delete, нажать кнопочку. И добавляйте инструмент вот здесь. MCP. Вы его уже создали, да? Вот. Вот только его надо выбрать. Да, вы можете подключить свой mcp-сервер. Как раз вторая плиточка, на которой вы находитесь, позволит вам уже существующий… Условно я могу создать просто сервер, сгружать туда файл, информацию, его подключить и все будет работать. Если вы хотите по протоколу MCP предоставлять информацию из какой-то своей системы, то вы можете создать свой MCP-сервер, подключить его к агенту через подключение, вот эту вторую плиточку, либо вы можете не заниматься созданием своего реализации MCP-протокола, если у вас уже какой-то API есть в вашей системе, реализовать MCP-сервер нашими средствами. То есть сказать, что вот такой-то там put, get, post, запрос дает мне такой-то инструмент в MCP. То есть это все тоже здесь можно сделать. Все-таки какая-то дока есть по созданию MCP-сервера? Или это абсолютно любой сервер может быть? Нет, документация публично. Спасибо. у кого-то получилось что-то от контура получить ответ другой более но эта модель решила ну там смотрите там из интересного ответ который мы получаем из контура он вообще видит джейсон то есть на самом деле в процессе еще и джейсон этот интерпретировал вот это не нет ничего не не требует как бы посередине не никакой конвертации модель сама получив его его хорошо понимает но он хорошо описан некорректную Прямо по окей сюда. Не же следующая, а вообще не наша. Токеном. Для которой контур, руководитель, не тот адрес, не тот. Он не виден, ну, где точно не пишет. Да, вот у них у всех горит эта штука. не а а правда подобное отвечает просто не показывает не лезет источник я когда вот здесь добавлял вот эту штуку ну вот ретри подружаю файлы, все дело отвечаю, он меня по ним не ищет вот надо за репорт глобально я что-то неправильно делаю, правильно? да, нет У кого еще не получилось из контура информацию достать? Чтобы агент точнее достал информацию из контура. 響鐘 Можно вопрос? Насколько это готово для использования? Кому отвечаете? Вам задали вопрос? Да, да. Допустим, мы хотим завтра у вас развернуть какого-то агента, какую-то историю. Мы запустили функциональность создания агентов в том виде, как вы сейчас видите, и созданием CP-серверов в конце сентября. То есть этой штуке уже три месяца. Основные проблемы, которые там были на старте, на мой взгляд, решены. И сейчас тот момент, когда если что-то появляется, оно решается максимально быстро. Не буду говорить цифры, но мы на старте смотрели использование и MCP серверов, создание агентов. Там хороший был быстрый рост на старте, я потом перестал смотреть. Этим пользуются. Просто даже сейчас 40 человек сидят, как будто бы все не очень гладко работает. Вы не сможете получить гарантированный ответ от модели с первого запроса. сказать ей, создай мне агентов Telegram и получать через 5 минут готовый ответ. Это как бы какая-то работа, которую мы с вами вместе сейчас проходим. Ага, сейчас я небольшое заявление сделаю по тому, как посмотрела. В общем, когда вы используете MCP, прописывайте модели, в каких случаях нужно ходить в MCP. Уберите лишние инструкции и постарайтесь, чтобы это было согласовано. Касательно использования GPT-OSS-1020B, прямо сейчас есть бага на сервере, лучше ее не использовать с веб-поиском. там технически не объясню, но в общем лучше сейчас не пытаться потерять время, к сожалению. GPT-120 OSS лучше не использовать пока. Давайте я еще кому-нибудь помогу, пока жду ответа. У кого-то получилось достать что-нибудь из контура информацию? Вот я тут переключился на квин. У меня более-менее хороший ответ получился. Я вижу опять же, что я вижу. что модель использовала несколько инструментов MCP сервера. Причем я думаю, что не один раз на самом деле. Она использовала, поскольку что такое компания X, Яндекс.Облако в данном случае модель не знает, она сначала запустила метод поиска, спросила у контура, какие есть компании, и вот условно получила тот список, который вы видели. И дальше сделала запрос еще в несколько методов. Поскольку инструкция у меня максимально общая, я хочу и финансовую информацию, и риски, и скоринг, и все. Она все эти методы Ани есть в контуре использовала и собрала мне какой-то готовый ответ. И в конце кажется, да, есть вывод, потому что я явно просил делать выводы, можно ли нельзя работать. Здесь где-то был... Я видел раньше хорошие… Да, некоторые риски, в общем, есть. Работа с нашей компанией, как оказывается, с точки зрения Квена. Вот примерно такой ответ мы можем получать от нашего агента. У кого? Кто готов дальше двигаться? Кто не готов? Все готовы. Мы говорили о том, что мы хотим на самом деле сделать так, чтобы эта штука работала не только на ноутбуке у вас, в консоль Яндекс.Облако, а вы могли этого Telegram-бота иметь у себя в кармане и использовать в любой удобный момент времени. То есть фактически мы хотим создать некое приложение для работы с этим агентом. У нас здесь есть такая кнопочка «Открыть workflows». Я рассказывал в начале про Workflows как инструмент создания разных сложных приложений несложным образом. И по нажатию на нее у меня уже предсоздался некий процесс, в котором уже есть блок Агенты iStudio, где указан мой агент. Он здесь уже используется. И я для того, чтобы... Мне нужно этот процесс настроить на то, чтобы получать сообщения из Телеграма и отвечать на них. Как я это буду делать? Я вижу у себя в палитре, и у вас тоже это есть, палитре действия под названием TelegramBot. Я могу перетащить сюда этот. Вот здесь кнопочка «Открыть Workflows». А тут какая-то большая дефолтная схема, судя по всему. Ее удалять все? Дефолтная схема, если вы попали в дефолтную схему, скорее всего, вы открыли вот здесь Workflows. Да. А я хочу использовать этого агента. Вы сможете и там это сделать, но вот если вы нажмете кнопку вот здесь, сверху, справа, то у вас уже появится не дефолтная схема, а схема, в которую уже встроен вот этот агент, как бы, ну, преднастроен. Вы можете и вручную это сделать, просто будет проще и быстрее. Соответственно, в нашем мини-приложении нам нужно реализовать две вещи. Для тех, кто устал, я думаю, что минут через 15 уже закончим, если что. Наше мини-приложение должно получать сообщения с Телеграма и отвечать на них. Для того, чтобы отвечать, мы добавим по итогу работы вот этого блока нашего агента, запуска и отработки нашего агента, мы добавим кубик отсюда из палитры, перетащим его под названием TelegramBot. Он будет отвечать на наши сообщения. Но для того, чтобы вообще создать в Телеграме бота, тут были руки и кто-то говорил, что знает, как создавать Телеграм ботов. У меня есть пару слайдов, я их, наверное, проскочу, но просто будет быстрее, если я сразу покажу, как это делается. Вам нужно в Телеграме найти контакт под названием bot. Bot. Bot. Извините. Father. Вот так он называется. Не, надо его создать. Мы его создадим сейчас через специальную штуку в Телеграме под названием bot.father. Да. Мы будем телеграммного бота создавать, которому вы сможете писать, а он будет вам отвечать. Он будет запускать вашего агента и отвечать вам. Находим бот Fuzzer. Открываем. Здесь есть кнопочка Open. Create new bot. Можно нажать Start. Он вам предложит команду Create new bot. тоже. Можно задать ему какое-то имя. Вам нужно, это просто имя, это отображаемое имя, а еще вот есть ссылка, по которой он доступен, она должна заканчиваться на бот всегда. У кого не получается? Кому помочь? Нет, нет, нет. Это вы вот сюда зашли? Вот. Да, да, это он уже сюда добавлен. Да, но мы, наша задача сейчас в Телеграме создать бота. После того, как вы создадите бота, у вас будет токен. Этот токен вам нужен для того, чтобы… Где токен? Еще раз показать. Здесь есть кнопочка токен. Вот как так он выглядит. Это цифры, двоеточие. Куда его вставить? Его нужно вставить в вашем workflow в разделе токен. Можно просто текстом. Не очень безопасно, но мы никуда не торопим. Точнее, наоборот, сейчас не будем безопасностью заниматься. По идее, такие вещи надо сохранять в лукбоксе и более безопасно их хранить. Мы сейчас этот текстом сделаем. Это секретница. Можно создать там секрет и указывать здесь идентификатор этого секрета. но для простоты сейчас просто текстом укажем. Токен, текст и вот это значение нашего токена. Здесь же вам надо будет написать текст, который вы хотите, чтобы отправил ваш Telegram-бот. Я пока здесь какие-то заглушки буду использовать. И кое-что еще покажу. Я вам рекомендую настойчиво в названии шагов использовать более короткие имена. Например, здесь мы можем взять вот так, TG. Да, хорошая ошибка. Да, значит смотрите, здесь вам точно нужно будет выбрать сервисный аккаунт, потому что ваш workflow будет ходить в модели, а на это нужны права. Что такое идентификатор чата? Хороший вопрос. Это то, куда ваш Telegram будет отвечать. А в личку? в личное общение с вами. Вы, общаясь с этим Telegram-бота, имеете некий идентификатор этого канала коммуникации, этого чата. И вам нужно его знать. Для того, чтобы бот знал, куда отвечать. А где его взять? Внимание, вопрос. Создаем общение с Telegram-ботом. И сообщение, которое прилетит из Telegram. Сейчас я дальше про это расскажу, но на вики страничке вы можете найти подсказки на эту тему. Сейчас я жду, пока вы добавите значение токена. И вот здесь любые заглушки внесете, любой текст, чтобы просто это сохранить, указав сервисный аккаунт. Дальше я объясню, как это все завести окончательно. В самом низу. значит это не самый низ Я не знаю, видишь, что мы вообще боимся. Выберите создать агента, выберите нашего агента, открыт workflow. Вот, здесь уже у вас там был базовый процесс, а здесь уже преднастроены. А, создать все-таки аналогов? Да, сейчас у вас вопрос, да? Нет, нету сферы. сервисный аккаунт выберем. Да. И до инфлятора чата пока что-нибудь. На ИСа. Сервисный аккаунт. Да, сейчас. Пока оставьте что-нибудь. Это обязательно. Потому что уже... Да, все отлично. Ругается, что что-то мне не хватает. Здесь надо указать сервисный аккаунт, потому что мы будем ходить в модели, а на это нужны права. Одно дело, вы это делаете? Да. Да, потому что Workflow понимает, что ему нужны будут права для работы в своей студии. А какие права? Вот они есть у сервисного аккаунта. У вас уже здесь софт, вы здесь. Сейчас будет нормально. Давайте заново. Кому еще помочь создать первый workflow? Дальше вам нужно… Вот здесь есть муклопен. Это можно командами, а можно в таком более… Спасибо. Он запускает и говорит ошибку. Так, давайте пойдем чуть-чуть дальше. Будет, наверное, понятнее. Нам осталось полтора шага для того, чтобы с этим закончить. Мы пока не решили проблему того, как Telegram будет вызывать наш процесс. То есть мы можем уже, мы создали бота, мы можем ему что-то написать, но при этом ничего не происходит, потому что Telegram не знает, чего делать с этим, когда ему пришло сообщение. И нам нужно сейчас сказать Telegram, запускай мой workflow, когда тебе пишут, когда пишут твоему боту. Как это сделать? Для этого мы пойдем в корень. Я там нажал на домик, вот если мы в workflow находимся, Вот здесь на домик или в меню мы выберем сервис API Gateway, он называется, и зайдем туда. Вот там все сервисы, можно поиском найти API Gateway. Это сервис, который позволяет выставить в интернет те сервисы, которые вы создаете в Яндекс.Облаке. или ваш собственный, в общем, неважно. Он позволит нам получить ссылочку, по которой мы сможем вызывать наш workflow. API Gateway. Здесь мы выбираем, нажимаем кнопку создать API шлюз, задаем имя, И вот здесь в палитре есть интеграция с Яндекс.Воркфлос, где нужно будет внести вот такие настройки. Нет доступных рабочих процессов. Куда они делись? Он для всего процесса. У меня просто пропало, поэтому не вижу своего workflow. Давайте я на примере чего-нибудь другого workflow попробую показать. Давай сначала быстренько. Вот у меня есть агент. Я открываю workflow. Я добавляю Telegram Bot. Я выбираю токен. Здесь указываю просто текстом. Здесь я что-то пока пишу. Это не важно сейчас. Это очень важно, но чуть позже это станет важно. И указываю сервисный аккаунт, с которым наш workflow будет работать. Теперь я иду во все сервисы, выбираю API Gateway. Создаю API шлюз. А это просто второй раз уже, поэтому экспресс. И здесь есть возможность добавить workflow. Вот такой путь. При поступлении пост-запросов я буду запускать мой workflow. Дальше идем. Путь корень просто. На самом деле вы можете здесь какой-то свой путь указать, но тогда вам телеграмму надо будет его же сказать. Да, потому что у вас могут быть разные боты, например. Ну, короче, все. На самом деле создать пост. Вот так я сделаю. Там есть такой тулбар сверху. Что у нас есть? У нас есть ссылка. Вот здесь, служебный домен. На самом деле вы можете теперь взять эту ссылку, скопировать. и на вики страничке написано, как телеграмму сказать о том, что вы хотите вызывать эту штуку. Где эта страничка? Что я делаю? Я беру вот эту ссылку и составляю из нее такую конструкцию. В качестве токена я использую токен, который у меня уже есть. Вот должна вот такая ссылка получиться. Примерно. Ну, не примерно, там у вас будет другой токен и другой адрес вашего API Gateway. после api gateway так где у меня это его здесь если зайти в обзор смысле добавили добавили пост запрос сюда добавили. И вот здесь у меня есть служебный домен. Это штука, по которой уже сейчас можно, если отправить пост-запрос, запустить в Workflow. Но пока этого делать не будем, пусть это делает Telegram, когда будет получать сообщение. Вам нужна вот эта ссылка и токен Telegram. Токен Telegram у вас тот же, который вы в Workflow вписывали. Вот так выглядит ссылка. То есть вот здесь bot.token. SetWebHook.url равно HTTPS. И вот ссылка. Вот прям в браузере можете вставить вот эту штуку. Ссылка. Вот здесь в первой части токен. Bot.id. Он должен сказать webhook, set, там что-то true, да. Вот. Сейчас будем смотреть. Да, служебный домен. И по идее сейчас я нажму Enter. И я таким образом сказал Telegram, вызывай, пожалуйста, мой API Gateway, который вызывает мой workflow, В тот момент, когда я буду что-то писать. Давайте посмотрим, так ли это. Я пойду в своего бота. Все вот эти угловые скобки, их удаляйте. Это они просто как заменитель. Ссылка есть на вики. Страница. Вот она вот здесь. Вот таким образом выглядит. Значит, вы не ставили токен. Кавычки не убрали. Должно быть сообщение о том, что вебхоу босс сет. Теперь вы можете пойти в своего бота, в него перейти и что-нибудь ему написать. Вот напишите на что-нибудь. Подскажите, у меня вышло все true, но закомментированных строк нет сверху. Это нормально? Это нормально. Немножко забегу вперед. Мы почти до конца дошли. Сейчас какой должен был получиться результат. Мы пишем нашему боту и он не отвечает. Я уже три сообщения ему написал, он молчит. Это вот я ему написал, могу еще написать, аж четыре раза уже написал, молчит. Пойду посмотрю вообще, что с ним происходит. Где мой, где мой, мой, мой, сейчас MCP, gate, много всего. Вот мой рабочий процесс. У моего рабочего процесса есть история запусков. Я четыре раза написал, и на самом деле он четыре раза запускался. Но возникала ошибка. Можно, конечно, поразбираться, что там за ошибка. Но давайте я покажу вообще, что здесь происходило. Запустился AI Studio Agent. У нас процесс из двух кубиков. Из вызова AI Studio Agent и из отправки сообщения в Telegram. Мы там, если помните, вбили какой-то произвольный ID-чат, что-то еще. То есть мы не знаем, куда отправлять ответы. И в этом месте отправка Telegram Bot не состоялась. Но зато запустился агент E-Studio, из Telegram пришло сообщение, вот мой где-то текст KGH, который я там писал, все сюда приходило. И даже на выходе из этого кубика в процессе был какой-то результат, но какой-то абстрактный. чего нам здесь не хватает нам не хватает информации о том куда отвечать и чего мы вообще спрашиваем у A-агента нам нужно параметризовать этот процесс и добавить в него те переменные которых не хватает куда отвечать и на какой вопрос отвечать то есть что мы вообще сообщение какое мы отправили то есть в запусках вы можете увидеть что есть некоторая структура на входе где есть в том числе текст И нам нужно это передать каким-то образом в агента. На вики-страничке описано, как это можно сделать. Можно вот этот message-текст, который мы... Где мы это делали? Вот здесь. Message-текст. Передать в агента. И это можно сделать следующим образом. Я прямо вот это скопирую с вики-странички. И буду использовать в Workflow 9.1.1, хорошее название. Редактировать. Я его отправлю в агенты, потому что сейчас туда уходит пустота. Мы его вызываем, но ничего ему не передаем из тех сообщений, которые мы вбиваем. Да, нет, в агенты iStudio. Мы туда отправляем пустоту. Сейчас вызывается iStudio агент, туда не передаются наши сообщения, которые мы пишем. Я нажал редактирование агента, выбрал кубик iStudio агент и в сообщение, потому что нам нужно передать ему то, что мы у него спрашиваем. А еще рекомендую называть блоки покороче. Вот это делаем. Идем в workflow обратно. Да, мы должны передать то, что мы пишем, то, что к нам пришло из бота. Дальше сохраняем. Нет. Потому что мы все еще не знаем, куда отправлять ответ. Точнее мы знаем, а наш workflow не знает. Вот здесь есть идентификатор в исходном сообщении, который из Telegram приходит. Есть идентификатор чата у моего бота со мной. Это один идентификатор. Даже если вы напишите моему боту, у вас будет другой идентификатор чата. Нам нужно его взять из исходного сообщения и сказать, что мы отвечаем в этот чат. Для этого мы идем в редактирование вот сюда и в идентификатор чата. Не статичное значение вписывай. Можете статичное, там обычно минус и там большая цифра. Можете в истории запусков посмотреть. А можете сделать его более универсальным, чтобы он отвечал всем, кто ему пишет, тем ID чата, который… Вот, на Вики есть эти выражения. Кому помочь? Кстати, хороший вопрос. Это идентификатор, это текст, который был получен. А нам нужен ID-чат, чтобы отвечать. Он содержится в другом месте. Продолжение следует... Поднимайте руки. Нам осталось одно действие, чтобы все закончить. Некоторые уже пошли чуть дальше, давайте я здесь продолжу. Помимо идентификатора чата, в который мы будем отвечать, сейчас я сохраню на всякий случай, чтобы ничего не пропало, и переименую немножко. Что-то не переименовывается. Значит, теперь мне нужно писать в текст, который отправляет Telegram, ответ. Нет? Сейчас разберемся. Сейчас я сам попробую. Может, мне тоже пошли. Вот здесь есть пример того, как выглядит результат шага предыдущего, ну или первого. Только у нас шаг называется не iAssistent, а iStudio. Так, сейчас, извините, я не там пишу. Так, сейчас, секунду. input message текст мы передали в агента а вот здесь мы хотим в текст ответа результат так здесь есть какое-то название название не меняется у меня тоже поэтому в тексте который я хочу чтобы telegram не ответил telegram bot я буду использовать вот такую конструкцию это последнее действие которым нам надо сделать на этом все честно я взял название вот этого шага. Если вы его переименовывали, то у вас оно будет другое. У меня оно такое. Ну, у вас тоже, скорее всего. Я знаю, я не буду сейчас рассказывать откуда, но я знаю, что его результат работы этого шага записывается в поле Result. Это можно посмотреть в истории запусков, там это видно, посмотреть, что там между входами и выходами переходит. И после этого все должно работать. Если я ответа не вижу, я иду в запуске и проверяю, что здесь происходит на шкале времени. Ну пока я вижу, что у меня работает первый кубик, то есть обращение к моему агенту. И я пока спокоен. Но как только он отработает и вообще здесь все отработает, У меня в Телеграме должен появиться мой ответ. Подождем. У кого получилось уже? О, много у кого. Вот, смотрите-ка, я получил ответ в Телеграме. В странном формате, но... Вывод, работа с этой компанией невозможна и нерекомендуема. Очень сложно все. Янтарь Полюс почему-то, да. Нету здесь представителей компании Янтарь Полюс? Ну, это модель. Дальше надо в агенте экспериментировать. Давайте кому-нибудь поможем. ありがとうございました Давайте я покажу завершающий слайд. Я тут какое-то количество пропустил. Но вообще мы сделали достаточно много. Мы использовали штуки четыре разных сервисов Яндекс.Облака. Раз, раз. Раз, раз. Что-то задели? Раз. Мне кажется, может, что-то здесь внизу кончилось. А вот здесь горит. Раз, раз. Про цены расскажете чуть-чуть? Да, да, да. что в самом агенте какая там профессиональная. Именно когда в агенте, в iStudio, то есть, или было нормально, да?