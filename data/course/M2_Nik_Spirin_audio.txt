
Nik Spirin audio.MP3
Спикер 7:
00:00:03 — Но и такой визионерской части, куда все должно прийти и как с этим работать, тоже будет много и какие-то фреймворки полезные, которые можно прям взять в бизнес, мы тоже, Никита тоже расскажет, и мы с ним поработаем. Никита, без слова, поехали. Да.
Спикер 2:
00:00:24 — Спасибо. Спасибо за приглашение в первую очередь. Я очень рад всегда с Николаем и командой поработать. Вот с Колкова действительно мы уже выступали, наверное, совместно больше пяти раз на программах CDTO. И сейчас для программы iShift такой презентации of the record, соответственно, чтобы честно поговорить.
Спикер ?:
00:00:47 — Про важные темы, поделиться какими-то фреймворками, помочь вам правильно начать мысли про искусственный интеллект как управленцам, и надеюсь, что это поможет как бы ускорить прогресс для нас всех, как человечества,
Спикер 2:
00:01:03 — Которое стремится к хорошему будущему. Если посмотреть на мою карьеру последние 15 лет, приблизительно это вот так выглядит, то есть непонятно, чем я занимался с 2010 по 2022 год. Потом наступил чат GPT Moment в ноябре 2022, и искусственный интеллект начал расти по экспоненте. Это, конечно, шуточная форма.
00:01:30 — За это время я успел поработать с более 30 компаниями, которые здесь представлены на слайде, или с которыми я себя ассоциирую. С точки зрения бэкграунда, чтобы вам понимать, с какой позиции я делюсь этими фреймворками. Первоначально я был сам ресерчером по искусственному интеллекту, машин-леарнинг инженером, был консультантом, стратегическим консультантом, был фаундером четыре раза,
00:01:59 — делая различные EI-стартапы, топ-менеджером больших компаний и инвестором в EI-стартапы, в английские инвестиции либо сопровождение каких-то institutional rounds. Вот. И на данный момент в NVIDIA я занимаюсь тремя колючевыми платформами для создания AI. Шуточно, опять же, я себя называю Actuary Man или заводчанин, потому что мы внутри используем очень активно концепцию AI Factory.
00:02:33 — И у меня получается фабрика по созданию данных для моделей. У нас есть собственные фаундейшн-модели под названием Нематрон и Космос, и, соответственно, нужно для них готовить данные, размечать данные и использовать людей для того, чтобы делать оценку качества моделей. И скорость порождения этих данных очень большая, соответственно, это нужно формализовывать как производственный процесс, и для этого есть Data Factory.
00:03:03 — Вторая фабрика — это фабрика по оценке моделей, то есть у нас появляются новые модели постоянно, каждую неделю какой-то пресс-релиз происходит, либо это DeepSeek, WAN, Nematron, LAMO, OpenAI, Antropic и так далее. И нам нужно быстро понимать, насколько они качественные, какие новые задачи они умеют решать, насколько хорошо, как быстро они работают, сколько стоит развернуть такого модель на масштабе.
00:03:31 — И мы, соответственно, занимаемся процессом оценки моделей системно на больших скоростях. И третья фабрика, наверное, это самая главная фабрика, это связано с упаковкой этих моделей для low latency и high throughput inference, то есть оптимизированные на производительности контейнеры и различные компоненты импринт стека для Яйма и LookSky.
00:03:57 — И это тоже мы делаем на очень большом объеме. За последние полтора года выпустили больше 170 моделей. Опять же, все популярные открытые модели, как только они появляются, мы их упаковываем в контейнеры. Ну и помимо этого, я люблю делиться знаниями, выступать с лекциями в надежде, что я таким образом себя отмасштабирую.
00:04:21 — То есть я с удовольствием занимался всеми IAI-проектами в мире, которые только есть, поскольку это безумно интересно. Но здесь, таким образом, как бы отделяясь знаниями, я надеюсь, что эти фреймворки позволят ускорить процесс внедрения IAI и улучшения качества жизни всем через лекции.
00:04:43 — Еще одну оговорку я сделаю, что мой рабочий язык английский, то есть 15 лет я живу в США, И поэтому, если я буду вставлять русские и английские слова, на меня не обижайтесь, это может быть выглядит иногда очень неуклюже, но я буду стараться всеми возможными способами сделать это максимально гармонически корректно. В общем, давайте двигаться. У нас очень много материала. Первая часть мы поговорим про бизнес-вопросы, про продуктовые вопросы, про поиск возможностей внедрения искусственной интеллекта и как про это думать.
00:05:18 — А вторая часть после обеда будет посвящена больше техническим вопросам, трендам и каким-то визионерским вопросам, плюс обсуждении того, как системно компания за счет всех этих технологий будет меняться. Ну и мы сгенируем очень много токенов, чтобы быть в тренде. Шок-контент, да, то есть в 2019 году на мероприятии VentureBeat один из топ-менеджеров Gap в панельной дискуссии сказал, что 87% проектов по искусственному интеллекту не доходит до выхода в промышленную эксплуатацию.
00:05:57 — И это как-то стало достаточно популярным, цитируемым материалом в комьюнити. И, соответственно, мы постоянно пытались понизить этот коэффициент неуспеха, научиться работать на тот момент с технологией Deep Learning.
00:06:13 — Если это недостаточно, то буквально месяца два назад MIT выпустил новое исследование, в котором они сказали, что генеративный искусственный интеллект сuccess rate 5%, То есть все стало только сложнее, и, соответственно, нужно учиться правильно с этой технологией работать. Появились новые вызовы, и новая методология должна быть пересобрана. У меня на этот счет три ключевых тезиса.
00:06:45 — Первое, то что если посмотреть на успех внедрения какого-то простого IT-решения на уровне компании, то есть пусть это будет какая-нибудь CRM-система, ERP-система и так далее, то success rate приблизительно 30−50%. То есть искусственный интеллект, будучи максимально новой, неизведанной технологией, да, он как бы более рискованный, но если посмотреть на какие-то уже супер понятные продукты интеграции, то там success rate тоже не 100% или далеко от этого числа.
00:07:17 — Вторая мысль о том, почему 95% зависит от того, как мерить, то есть, что значит эксперимент, что значит успех, и если учитывать все возможные итерации, которые идут в счет перед выкаткой какого-то продукта в продакшн, то это действительно, наверное, будет такая цифра.
00:07:40 — Но если мы посмотрим и как бы объединим все эти продукты как нормальная часть итерационного процесса подготовки решения к финальной выкладке, то, наверное, эффициент будет выше. И третья мысль, да, действительно, эта цифра, она должна в какой-то момент коммунитизироваться и, по крайней мере, стать сопоставимой с интеграцией каких-то базовых IT решений там на том же уровне 30−50 процентов, тогда это будет в каком-то плане уже понятная, управляемая технология.
00:08:16 — То есть задача моей лекции отчасти поделиться советами и рецептами, которые работают, и таким образом этот коэффициент улучшить. Дальше шуточное видео, я совсем коротко покажу, тоже мне оно очень зацепило в свое время, когда мы работали с Vodafone.
00:08:35 — Они все очень любят футбол, да, и вот показали такую штуку, когда мы работали над company wide трансформацией водофона. Я буду комментировать коротко. Представьте, что это OpenAI, потом Anthropic, потом опять OpenAI, тут у нас DeepSeek, Anthropic, опять DeepSeek, и так далее.
00:09:18 — То есть ключевую концепцию вы поняли. Соответственно, существует несколько лидеров рынка, которые очень хорошо понимают эту технологию, которые ее создают, управляют. И есть очень много других компаний, которые в этом хаосе погрызают, пытаются как-то разобраться, куда все двигается, и из-за скорости появления новых технологий это сделать достаточно сложно.
00:09:43 — Соответственно, исследование McKinsey говорит о том, что это получается compounded annual growth rate для компаний-лидеров, которые уже научились внедрять искусственный интеллект. У них скорость внедрения растет, и капитализация тоже растет по сравнению с компаниями, которые в эти лидеры не попадают, и это уже не на процентных соотношениях, а в иксах проявляется.
00:10:12 — То есть в два с лишним раза где-то в зависимости от индустрии до 6x скорость роста компаний-лидеров,
Спикер ?:
00:10:22 — Которые умеют работать с технологией искусственного интеллекта относительно старых компаний,
Спикер 2:
00:10:28 — Или которые немножко опаздывают. И второй график тоже из того же исследования МакКинзи. Он говорит о том, что если посмотреть средний разрос зрелости компаний с точки зрения внедрения искусственного интеллекта в период 2016−2019 или 2022, то это, получается, дисперсия увеличилась, что это означает? То, что лидеры стали значительно сильнее отделяться от среднего по рынку, с конкретной индустрией, и разброс увеличился.
00:11:03 — То есть лидеры двигаются вперед быстрее, а весь остальной рынок остается, и разрыв увеличивается. То есть это тот вызов, который все компании перед собой имеют, как трансформироваться в такой формат, чтобы действительно оказаться среди лидеров и максимально эффективно внедрять свою технологию, получать из нее пользу. Я поделюсь авторскими преймворками. В качестве опорного кейса я буду использовать кейс по автоматизации ретро-шотоварных фото.
00:11:31 — Это мой предыдущий стартап до присоединения к NVIDIA. И также я буду делиться какими-то другими выученными уроками и фреймворками по нашей лекции.
Спикер ?:
00:11:46 — Пример задач, которую мы решали. Есть какая-то компания, либо это интернет-магазин, либо это какое-то производство,
Спикер 2:
00:11:54 — И они хотят превратить такие страшные картинки, которые появляются из фотостудии, в классные красивые картинки, которые мы привыкли видеть на сайте интернет-магазина какого-нибудь Wildberries, Яндекс. Маркет, Амазон и так далее.
Спикер ?:
00:12:08 — Вот здесь поворотный стол, тени какие-то, блики, различные дефекты.
Спикер 2:
00:12:13 — И нам нужно превратить это на белом фоне, чистый красивый предмет, который покупается. Соответственно, на данный момент, до того, как мы начали заниматься технологией пользователей, Делали это вручную, в фотошопе, это занимало очень много времени, и идея была такая, чтобы избавить людей от этой скучной, повторяющейся работы с помощью искусственного интеллекта и высвободить креативный потенциал людей на какие-то другие, более интересные задачи.
00:12:44 — Вот. И первый блок у нас будет про то, как в целом, значит, трансформация в AI-компании происходит от начала до конца. И, грубо говоря, если делать сравнение между книжками по leadership, да, то есть есть там известные книжки 5-level leadership и так далее, и ввести похожую модель зрелости компании с точки зрения искусственного интеллекта, то мое обещание такое, что мы возьмем кампанию уровня 1−2, и мы превратим ее в кампанию уровня 4.
00:13:17 — Кампанию уровня 5 я считаю, что можно превратить только изнутри, то есть нельзя притискать, вы будете world-class, супер-успешными, и мы вам сейчас научим, как это делать. А если бы был такой рецепт, то все бы были успешными кампаниями уровня 5 или excellent.
00:13:35 — Мое обещание такое, что мы построим процессы, раскрутим маховик до такого уровня, чтобы компания уже потом в какой-то момент сказала, так, мы осознанные как организация, мы понимаем, какая цель есть искусственный интеллект, и мы дальше сами себя попытаемся докрутить до уровня excellent в своей индустрии, используя свои какие-то наработки и уникальное позиционирование. Соответственно, помимо этого, мы поговорим про то, как искать возможности для внедрения искусственного интеллекта. И я думаю, что если проводить сравнение с тем, что мы с Николаем в свое время обсуждали, 5 лет назад надо было, в кавычках, продавать искусственный интеллект.
00:14:20 — Почему им надо заниматься, почему это тренд, почему это будущее, В то время как сейчас у всех людей, так или иначе взаимодействующих с искусственным интеллектом, с разными приложениями в своей личной жизни, сформировалось это понимание, сформировалась вера в то, что это действительно работает, что это полезно. На всех уровнях компании, начиная от флог-менеджеров до управленцев, до каких-то функциональных менеджеров или непосредственно сотрудников, которые делают day-to-day работу, Есть такое понимание, и теперь нужно уже из понимания превратить это в практику и в использование.
00:15:00 — Коротко про искусственный интеллект, что я под этим подразумеваю. То есть это такая достаточно аморфная терминология. Сколько существует экспертов, столько будет и формулировок определения искусственного интеллекта.
00:15:18 — Я хочу простое рабочее определение предложить здесь для того, чтобы мы все понимали приблизительно одно и то же, когда я буду говорить AI. Для меня это значительный термин, который описывает различного рода технологии автоматизации человеческой деятельности. И это все можно смотреть на спектре от автоматизации простых задач до сложных задач.
00:15:45 — Например, если раньше была какая-то веб-форма, и после заполнения веб-формы автоматически отправлял компьютер сообщения или e-mail, можно считать, что это был какой-то в кавычках AI. То есть самая примитивная операция, вместо того, чтобы там был человек, мы могли это автоматизировать с помощью искусственного интеллекта. Дальше по мере развития технологий появились рекомендательные системы на основе правил. В качестве примера, допустим, у нас есть рекомендационная система фильмов.
00:16:15 — То есть фильмы описываются какими-то жанрами, каждый пользователь указывает жанры, какие им нравятся. Кому-то нравится фантастика, кому-то нравится драма, кому-то нравится мелодрама, кому-то комедия. И мы просто считаем, для каждого фильма сколько тегов совпало с предпочтениями пользователей. Если там 3 тега совпало, значит фильм более интересен будет, чем если 2 тега совпало. Самая базовая модель на основе юрисдик и правил работает уже и до какого-то приблизительно 2003 года, это работало очень хорошо.
00:16:48 — Потом в период 2003 по 2008 очень активно развивалось направление коллаборативной фильтрации, различные алгоритмы применения машинного обучения для рекомендательных задач. Netflix Prize был в 2008 году, за который они обещали миллион долларов заплатить, если на 10% улучшить качество рекомендаций.
00:17:11 — И там ключевое отличие такое, что у нас уже не теги и только, а у нас используются 500 параметров, 1000 параметров, которые описывают человека, Какая у него, значит, демографическая категория, какой возраст, какой там оцениваемый доход, значит, в какой стране он живет, какие другие сайты он посетил, какие фильмы посмотрел и так далее, то же самое про фильмы, какой там цветовой спектр, значит, кто режиссер, сколько актеров в целом и так далее. И после этого все это вместе объединяется моделью машинного обучения, и единственной целью которой является предсказать рейтинг максимально точно к тому, как поставлены рейтинги людьми на определенные фирмы исторически.
00:18:01 — Да, это вот машинное обучение в классическом смысле. И дальше, опять же, пять лет назад эта картинка ограничивалась на четырех вехах на этом спектре тест-ьюринга, как механизм, в котором, значит, если человек не сможет отличить,
00:18:19 — общается ли он с другим человеком или с компьютером, то мы назовем такое искусственный интеллект сильным, и скажем, что искусственный интеллект прошел тест-ьюринга, все, значит, конец, круто, значит, мы победили искусственный интеллект. И это, на самом деле, у меня даже мурашки по коже, что в 2024−2025 году И вот незаметно мы преодолели тест Тюринга. То есть те 70 лет мы молились на эту веху и считали, что если это произойдет, все, значит, искусственный интеллект станет супермогучим, и во всем станет сильнее человека.
00:18:54 — Мы это прошли, мы даже это не заметили, и в конечном счете мы просто продвинулись в область еще более сложных когнитивных задач. Да, и вот если смотреть на такую недостижимую оценку, которая чуть-чуть по-другому должна быть переформулирована не как единственный критерий тест, а как общая на качественном уровне концепция, это искусственный интеллект, который превосходит человека во всех направлениях.
00:19:22 — Потому что постоянно с прогрессом технологий, с новыми релизами, качество решения задач каких-то, оно улучшается. И что мы делаем, в частности, вот в фабрике по оценке моделей, мы постоянно улучшаем сам инструментарий оценки умности искусственного интеллекта. То есть эта вещь, она будет продолжаться до тех пор, пока действительно искусственный интеллект не покажет абсолютно доминантные способности по сравнению человека во всех направлениях.
00:19:56 — И почему это важно управленцам, такой именно подход на искусственный интеллект? Мы здесь совсем не говорили про то, какие существуют нейросети, deep neural network, machine learning, random forest, трансформеры и другие вещи, потому что вам как бизнесу, как управленцам надо решать задачи. И мы в первую очередь говорим про решение задач, а при достижении какого-то бизнес-результата технологии должны быть вторичны. И я хочу, чтобы одна из ключевых мыслей, которые вы из этой лекции возьмете, что был бы именно такой подход.
00:20:27 — Да, это очень интересно, да, классно, но решает ли это мою задачу? То есть, в первую очередь, максимально простые подходы нужно использовать и дальше двигаться по спектру к более сложным подходам, если они приносят дополнительную бизнес-ценность, и они возможны в вашей истории. Я здесь паузу сделаю, какие-то комментарии есть? Нет, пока нет.
00:20:53 — Слушай, двигаемся дальше. Переходим к стратегии внедрения. IA Transformation Strategy. Во-первых, нужно определиться с стратегическими целями по внедрению. И, как правило, это три ключевые цели. Первая — это артель проектов по искусственному интеллекту, которые в себе содержат завалидированный return on investment.
00:21:19 — То есть это не просто какие-то подделки, а это действительно успешные проекты, которые кардинальным образом изменили процесс создания ценности в организации. Дальше это платформа как leverage, то есть как рычаг, за счет которого мы повышаем эффективность создания новых AI-продуктов.
00:21:39 — То есть без платформы мы будем тратить на создание еще одного искусственного интеллекта компании X единиц времени с платформой, мы будем делать это два раза быстрее, три раза быстрее, пять раз быстрее, десять раз быстрее, и платформа — это механизм стандартизации процесса создания искусственного интеллекта. Поскольку сейчас технология является сквозной искусственный интеллект, то нам нужно эту технологию иметь как корневую в организации, так же, как раньше это была какая-то ERP-система, так же, как это была какая-то CRM-система, база данных хранения информации про пользователей.
00:22:18 — То есть сейчас в каждой организации должна появляться какая-то компетенция и соответствующие технологические компоненты, которые позволяют построить конвейер создания искусственных интеллектов в компании. Да, и третья вещь — это формирование собственного центра компетенции.
00:22:36 — Здесь ключевое слово не «центр», а «компетенции», Потому что все пытаются создать какую-то организацию и говорят «все, у нас есть искусственный интеллект, мы умеем делать новые технологии». На самом деле надо создать именно компетенцию, правильный пул партнеров, правильные внутренние команды и понимание, куда это развивать.
00:22:58 — То есть это про то, как мы эффективно работаем с человеческими ресурсами и внутри организации имеем возможность работать с искусственным интеллектом без какого-то там активного внешнего, внешней помощи, да, то есть конечная задача не постоянно сидеть на консультантах, на каких-то внешних подрядчиках и надеяться, что ваша компания будет лидером, а через системный подход работы с этими партнерами перейти к финальной точке, когда у нас внутри компании существует центр компетенции, который умеет работать и продолжать улучшать технологию уже собственными силами.
00:23:37 — Тогда это уже называется успех, и эта компания, условно говоря, по нашей модели зрелости, будет четвертого уровня, и у нее есть шанс трансформироваться в лидера, действительно лидера, на пятый уровень перейти собственными силами. Дальше, опять же, про системные изменения. Можно это все разложить на пять ключевых векторов. Стратегия, данные, технологии, таланты и процессы.
00:24:04 — Всего здесь, как вы видите, получается приблизительно 40 модулей. Мы сегодня поговорим с большим фокусом про бизнес-модель, про поиск возможностей, про продукт, про портфель проекта, платформу и обучение, чем мы сейчас занимаемся. И коснемся чуть-чуть пурпурно подкрашенной блоки. Другие вещи мы просто не успеем как говорится, for the sake of time.
00:24:33 — Если разбить это на такой календарный план и ключевые фазы, то трансформация рекомендуется организовать это следующим образом. То есть это не единственная модель проведения трансформации, это то, что я, в свою очередь, внедрял в ряд больших организаций, и это работало успешно.
00:24:55 — Модель работы с партнером, когда партнер Партнер берет на себя в первую очередь ответственность за реализацию первичного пула успешных проектов, используя свой know-how, технологии и таланты, и запуск и структурирование первичной модели AI-платформы. Дальше, фаза 2, происходит расширение первичного портфеля, доработка платформы, И здесь важно co-development, когда команда организации, которая хочет трансформироваться,
00:25:30 — и команда партнера работают вместе в модели blended team, то есть когда две организации работают вместе для того, чтобы максимизировать передачу знаний,
Спикер ?:
00:25:40 — То, что называется knowledge osmosis, от процесса осмоса, который с жидкостями происходит.
Спикер 2:
00:25:48 — И дальше, соответственно, фаза три — это фаза создания центра компетенций, когда у нас полностью внешний партнер, он отходит на второй план, он может совершать, что называется, авторский надзор, где-то помогать, какие-то делать стратегические решения, корректировать траекторию, но в целом организация сама уже может создавать новые проекты, запускать их, успешно масштабировать и управляет полностью бэклогом и спектром всех задач по созданию и доработке своей AI-платформы.
00:26:24 — Дальше давайте чуть-чуть более детально про каждую из вас поговорим. Здесь она разбита еще более подробно. На первом этапе нам нужно запустить AI-трансформацию. Если мы эффективно двигаемся, то это может занимать 4 недели.
00:26:43 — Я немножко лирическое отступление сделаю. Один из принципов, который работает в NVIDIA, мы называем это speed of light, потому что это недостижимый максимум с точки зрения передвижения частиц в пространстве физическом. То есть это какая-то константа нашего мира. И мы всегда пытаемся мерить себя относительно speed of light. То есть мы не хотим себя сравнивать с конкурентами.
00:27:11 — Если мы думаем из basic principles, с какой скоростью максимально круто мы можем двигаться и все процессы, все решения выстраиваем вокруг этого для того, чтобы максимально определиться к этому идеалу. Да, и здесь вот я вам пытаюсь показать, что есть speed of light по-честному для какой-то большой организации пройти трансформацию. Если это организация меньшего размера, то это процесс может быть ускорен, но с учетом определенной инновационности в процессах, в людях и так далее, то для большой организации такого рода таймлайн является реалистичным.
00:27:50 — Я не буду все зачитывать со слайда, ключевые вещи какие-то я подсвечу, которые отмечены красным. То есть очень важно на ранней стадии назначить лидера по яй-трансформации, и это должен быть не просто какой-то активист, который классно яй-технологиями увлекается, а исходить от топ-менеджмента организации для того, чтобы этот человек обладал необходимым социальным весом, административной поддержкой и ресурсами, для того чтобы принимать и быстро разруливать сложные ситуации.
00:28:23 — То есть по мере реализации проектов, особенно в случае, когда это новая технология и все меняется очень быстро, очень важно, чтобы был человек, который может вот эти блокеры, какие-то там барьеры в дальнейшем развитии проекта быстро разрешать, иначе скорость команды будет падать, и мы будем неэффективно двигаться по нашим roadmap.
00:28:50 — Дальше, значит, вторая паза, очень важный, поиск возможностей. Здесь я различные способы поиска возможностей перечисляю. Их надо все использовать, они все легко параллелизируются. Плюс сейчас есть такие вещи, как deep research, агенты, которые за вас могут быстро собрать такой портфель автоматически и тоже ускорить этот процесс. Дальше, соответственно, формирование портфеля.
00:29:18 — Когда мы нагенерировали много различных идей изнутри организации, из внешнего рынка, мы должны создать портфель. И очень важное понятие портфеля. Почему? Потому что когда организация начинает внедрять новые технологии, в частности искусственный интеллект, есть риск сфокусироваться на один проект, его неудачно довести до какого-то состояния,
00:29:45 — Ну, эта технология не для нас, она сложная, давайте подождем еще, значит, какая-то, возможно, стигма появится у людей, которые эту технологию начали делать как каких-то активистов, пионеров, но не серьезных бизнес-деятелей, и в итоге это все может сойти на нет, и потом нужно дополнительные какие-то ресурсы находить внутри организации, мотивацию, чтобы это все перезапустить, в таких случаях иногда меняется лидер всей трансформации и так далее.
00:30:15 — Вместо этого нужно подходить более прагматично, как венчурные инвесторы, собирать портфель различных проектов легкой сложности, которые гарантированно заработают средней сложности, и несколько мундшотов, которые просто выведут компанию на кардинально другой уровень, соответственно, число проектов разного типа, пусть будет по какому-то гауссовскому распределению, сразу же заниматься какими-то мундшотами, опять же, не стоит.
00:30:44 — Также, если здесь посмотреть внимательно на эту картинку, то стоит заметить, что здесь нигде мы не говорим про создание дорожной карты, про искусственный интеллект и о стратегии на первой стадии. Почему? Потому что организация просто не понимает, что с ней делать, куда двигаться и так далее. То есть не сформировалось вообще понимание того, если математическим языком выражаться, Если мы будем дифференцировать эту технологию по определенному направлению нашего бизнеса, у нас какая скорость будет внедрения и эффект? Непонятно.
00:31:18 — Нам надо понять, в каком направлении двигаться, как сориентироваться в этом пространстве возможностей и понять, куда же действительно вкладывать ресурсы с максимальной пользой. И поэтому, я про это скажу позже, это надо вкладывать. Но на первичной стадии нам нужно сбалансированный портфель построить. Дальше мы двигаемся к проработке проектов. Стандартный скоупинг, постоянная постановка бизнес-задач, метрик, описание данных.
00:31:44 — И, опять же, эту фазу не надо пропускать. Всегда можно легко сделать поделку, все равно потом придется делать по-серьезному, если вы хотите делать этот проект масштабировать. И мы формируем требования к AI-платформе на этом этапе. Почему? Потому что еще один важный критерий формирования портфеля — Мы не делаем какие-то рандомные случайные проекты, один в маркетинге, второй в продаже, третий в производстве, четвертый в продукте, пятый в финансах.
00:32:13 — И они все независимые технологии, не пересекаются, и мы не имеем какого-то leverage и cross-project learning. Важно найти такой портфель проектов, который да разнообразный, но при этом у нас есть пересечения, И эти пересечения становятся повторяемыми активностями, которые в свою очередь переходят в AI-платформу.
00:32:36 — И на высоком уровне понимания, что такое AI-платформа, это переиспользуемые модули и какие-то компетенции внутри компании, либо это технологические, либо это на уровне навыков, которые мы можем от проекта к проекту более эффективно применять. Чтобы мы сделали это один раз, выучили уроки один раз, потом максимально эффективно масштабировали. И дальше еще важная вещь — это облачный партнер.
00:33:03 — То есть мое предложение или рекомендация такая, что не надо сразу же закупаться, какую-то сложную инфраструктуру делать, инвестировать вначале в это, а потом смотреть, а как же мы отобьем эти инвестиции. Непонятно как у нас ROI не сходятся. И за счет этого, опять же, все CIO, директора по информатизации, страдают, если они не могут потом это все объяснить. Подход более прагматичный. Давайте мы двигаться будем от ценностей, от проектов, постепенно, максимально быстро и гибко, за счет облачных мощностей.
00:33:37 — Отмасштабируем, создадим первичный успешный портфель, создадим какой-то ряд продуктов, которые, скажем, будут нашим знаменем трансформации, чтобы про это можно было говорить и в паблике, и внутри компании с руководством, и говорить, да, давайте дальше масштабироваться, мы уже чуть-чуть что-то понимаем. И эта гибкость облаков позволяет.
00:33:59 — И дальше мы переходим в реализацию проектов. Проекты делаются в этом случае партнером, и опять же здесь договорка, при отсутствии внутренней экспертизы. То есть если она очень слабая, и нет людей, которые такого уровня проекта могут реализовывать, то это делается успешным партнером для того, чтобы повысить успешность проектов. То есть, чтобы не было у нас этой 95% страшной цифры, чтобы мы сказали, смотрите, а у нас получилось заделиверить проекты и партнер с компетенциями.
00:34:33 — Как правило, значит, какие-то консультанты или бытиковые команды, они чуть-чуть раньше, чем корпоративный рынок начинает понимать эти технологии, и этим надо пользоваться и эффективно заниматься трансфертом технологий. И еще здесь две важные вещи, это запуск AI-образования.
00:34:52 — Соответственно, запуск AI-образования нужно делать по двум направлениям у руководителей и функциональных менеджеров, то есть для того, чтобы они понимали, как вообще работать, как управлять этой технологией, как правильно ставить задачи, как контролировать эффективность внедрения, какие метки смотреть, понимать, что ожидать, а что не ожидать, все вот эти мифы и легенды, чтобы они были правильно поняты и мифы развеяны. И в то же самое время надо начать готовить пул экспертов, которые будут на следующей фазе, на фазе co-development, заниматься вот этой реализацией уже совместно с партнером.
00:35:33 — Перенимать знания, но у них как бы должна быть плодородная почва, они должны уже начать понимать эту технологию. И что еще важно, современный AI настолько сильно повысил уровень абстракции, что сейчас не надо быть Machine Learning инженером. По моим оценкам в мире существует миллион людей, которые по-настоящему умеют делать Machine Learning и AI.
00:35:58 — И есть 100 миллионов software инженеров, которые просто умеют хорошо писать код. И за счет того, что мы повысили уровень абстракции до API спецификации, То есть у нас есть какой-то документ, человек может прочитать этот документ, и он понимает, как этому AI через API закинуть правильные команды, чтобы он уже какую-то деятельность мог серьезно автоматизировать.
00:36:20 — Да, и это могут делать теперь просто программисты, а не обычные специалисты искусственного интеллекта. И это вот демократизация, значит, доступа к технологии, это важный скачок с точки зрения облегчения использования и с точки зрения работы с талантами, которым нужно пользоваться. И нужно вот эту почву максимально эффективно взрывклить до перехода к серьезной разработке самим.
00:36:49 — И, значит, дальше еще одна вещь важная. Эти специалисты, которые будут «играть» в кавычках с технологией искусственного интеллекта, с различными инструментами, они не должны то, что называется, увлекаться в shadow AI. То есть, когда они сами начинают корпоративные документы отправлять в какой-нибудь чат GPT, там DeepSeek или в какие-то другие сервисы, таким образом сливая корпоративные IP,
00:37:16 — и подвергая компании риск, вместо этого надо просто дать возможность сотрудникам компании пользоваться этими технологиями в периметре вашей организации с определенными политиками безопасности и так далее. Чтобы это было, с одной стороны, доступно, с другой стороны, это было безопасно. В частности, у нас в компании есть доступ практически ко всем инструментам искусственного интеллекта без лимита, чтобы все сотрудники могли с этим упражняться, учиться, пробовать создавать какие-то новые для себя инструменты и масштабировать, если это имеет смысл.
00:37:54 — И, соответственно, почему Unlimited? Потому что мы доверяем сотрудникам, и мы не хотим пытаться их талант и креативность ограничивать определенным бюджетом токенов, которые они могут потратить в день, потому что это будет выглядеть бюрократично, то есть надо немножко расслаблять эти границы и двигаться быстрее.
00:38:17 — Соответственно, очень хороший ресурс, и то, что мы с Колей проговаривали, что это такое open record-поступление, чтобы я максимально вам разноплановый взгляд на искусственный интеллект поделился, а не только с позиции нашей компании.
Спикер ?:
00:38:34 — Google выпустил классный набор юзкейсов.
Спикер 2:
00:38:39 — Тысяча один юзкейс, который работает у клиентов с Google. 101 технологическая архитектура, которая уже реализована. Там просто вся диаграмма написана, то есть не надо ничего придумывать. Скачивайте данные отсюда, пользуйтесь таким продуктом, потом его упаковываете в другой продукт, в третий продукт. Очень удобно, да, то есть это один из вот этих вот инструментов и просто эффективно посмотрите и выберите себе по душе, как говорится.
00:39:08 — Дальше двигаемся. Соответственно, у нас есть стратегия внедрения AI фазы 2. Здесь что у нас происходит? На первой фазе мы создали какой-то пулл проектов, и нам нужно передать знания в клиентскую организацию, то есть в компанию, которая проходит трансформацию от партнера.
00:39:28 — Соответственно, мы здесь объясняем, как работает облачная архитектура, какое архитектурное решение, какие алгоритмы, данные, код, все мы это объясняем, передаем внутренним командам, и мы делаем точное расширение команды, то есть здесь мы на предыдущей стадии сделали запуск найма специалистов точечный, не просто нам надо нанять столько специалистов, сколько мы можем, а очень точечно, чтобы закрыть на фазе 2 какие-то ключевые компетенции, которые раньше были реализованы партнером,
00:40:03 — таких лидеров проектов найти, мы их нанимаем и в то же самое время продолжаем использовать внутренние ресурсы компании, максимально их переобучая для того, чтобы они смогли быть ценными, значит, участниками процесса и трансформации. Дальше, значит, у нас происходит ребалансировка портфелей, вот эта важная фаза, почему мы запускали, в свою очередь, здесь образование руководителей и функциональных команд, то есть не технических специалистов.
00:40:33 — Потому что на этом этапе они, посмотря на то, научившись работать с искусственным интеллектом, посмотря на то, как это делается партнером в ограниченном списке проектов, они принесут вам эти идеи, и будет просто внутренняя команда, централизованная на этом этапе, она будет разрываться от входящих заявок. Сделайте мне AI для того, сделайте мне AI для этого, сделайте мне AI для всего.
00:41:00 — И нужно таким образом подготовить, чтобы спрос был. И здесь вот интересное такое получается соотношение двух параллельно развивающихся треков. Первое — это инвестирование в AI-платформу. Если вы в нее инвестировать не будете, то у вас под вот этой волной новых заявок просто компания и трансформация может как бы лопнуть от успеха.
00:41:26 — То есть это хорошая ситуация, в которой надо еще умудриться оказаться, но при правильной реализации предыдущих фаз, про которые я поговорил, может получиться так, что компания просто захлебнется от того, что пришло слишком много идей, и это все разорвало процессы, структуру, все опять превратилось в какой-то хаос. И в то же самое время, если мы этой первичной посадкой зерен в команды функциональной заниматься не будем, то у нас все будет в модели как бы outbound, говоря от позиции команды IA-трансформации.
00:41:58 — Эта команда будет всем приходить и говорить, может, вам IA без дела, может, вам IA без дела, и там будет тратиться лишнее время на то, чтобы с бизнес-стейколдерами это все проговорить, структурировать, и нам нужно вот эти вот обе компетенции одновременно раскачивать, чтобы они в нужный момент, в фазе 2, когда будет происходить расширение по портфелю проектов встретились и друг другу помогли.
00:42:22 — Да, дальше мы опять же прорабатываем эти проекты, начинаем делать реализацию, и здесь важный момент такой, что в модели co-development те проекты, которые уже относительно стабильны, на предыдущем этапе сделаны партнером, они уже показали какой-то потенциал внедрения и начали работать. Мы их передаем в модели co-development, когда мы начинаем сопровождение внутренней команды и командой партнера.
00:42:50 — А новые проекты продолжают делаться партнером, потому что это как бы по-прежнему сложная компетенция, и нам еще пока рано переносить полную разработку на команду. И давайте вот здесь еще один важный момент. Это вот просто на примере одной организации. У меня такой же, в принципе, есть слайд для NVIDIA. Как это растет? То есть если все сделать правильно, экспоненциальный рост технологии.
00:43:17 — Поскольку это один из лидеров рынка, они начали заниматься серьезно яй и машин лернинг 10−15 лет назад. В 2013 году они начали разрабатывать свои чипы, инфраструктуру под это. В 2015 они это выпустили. И вот, посмотрите, как по экспоненте. Это внутренние проекты из Google, как растут. У NVIDIA абсолютно такая же штука. То есть скорость роста экспоненциальная по числу различных агентов, по числу различных механизмов автоматизации.
00:43:45 — И у нас сейчас 100% компьютер-сайенс и программистов используют курсор для написания кода. То есть просто каждый сотрудник пользуется этим каждый день. И то же самое с ситуацией по рынку. Здесь у нас получаются capital expenditures на AI technologies, в частности GPU, networking, interconnect и все другие компоненты инфраструктуры, которые нужны для современного AI.
00:44:13 — Тоже все видно, что растет в экспоненте. Почему? Потому что это с одной стороны инвестиции в долгосрочный рост, но под это есть спрос. То есть это не просто какие-то эфемерные цифры, это то, с чего соответствующие облачные игроки зарабатывают, потому что есть спрос от большого числа интерпрайзов и AI-натив, этих магических стартапов, которые эту емкость вырабатывают.
00:44:42 — И другой пример — это скорость роста и ускорение прогресса в целом внедрения новых технологий. Если мы посмотрим на компании, которые появились меньше, чем три года назад, они достигли 100 миллионов annual recurring revenue, буквально с 100 сотрудниками меньше, чем за 24, иногда 15 месяцев.
00:45:08 — Что это означает? Это означает, что они фокусируются на конкретный кейс. Им надо этот кейс продать большому числу организаций, то есть на это есть спрос. Они продают это в каждую организацию, И виден экспоненциальный рост по числу внедрений. И таких компаний много. Это не единичная история. Почему? Потому что рынок созрел, и скорость проникновения новой технологии быстрее.
00:45:36 — Каждая компания со стороны закупщика смотрит, какие нам нужны новые технологии на базе искусственного интеллекта, и они эти продукты интегрируют. Вот этот, вот этот, вот этот, соответственно, они внедряют это очень быстро по экспоненте, и соответственно у этих вендоров также экспоненциальный рост. Здесь, получается, экспоненты по продажам и экспоненты по внедрению внутри компании.
00:46:03 — Дальше, значит, последняя фаза — это фаза, когда мы запускаем центр компетенции, и только на этом этапе мы уже формируем и есть стратегии. То есть у нас есть понимание платформы, у нас есть понимание того, где она работает, у нас есть успешные кейсы, у нас есть уже частично обученная внутренняя команда, и в этот момент мы говорим, хорошо, давайте мы начинаем пересобирать нашу компанию в AI native формат и перенимать полностью на себя ответственность по дальнейшему развитию и разработке искусственного интеллекта.
00:46:37 — И вот на этом же этапе, когда у нас уже есть понимание юнит-экономики и необходимых вычислительных мощностей на конкретные бизнес-процессы и их автоматизацию, мы можем сказать, хорошо, давайте начнем амортизировать наши технологии на следующие 4−5 лет, то есть это средний цикл жизни какого-то продукта инфраструктурного.
00:47:05 — И мы, соответственно, уже начинаем закупаться, потому что мы не просто аморфно покупаем эту инфраструктуру, мы начинаем покупать, исходя из каких-то четких финансовых показателей и понимать, куда и как это будет использоваться и внедряться. Да, то есть вот такая у нас получается дорожная карта. Я здесь паузу сделаю. Можно параллельно заполнить очень короткий опрос.
00:47:32 — Один вопрос, там напишите, как ваша компания думает про эту трансформацию. И можем сделать небольшой Q&A.
Спикер 7:
00:47:43 — Как раз у нас 10 минут до обеда, мы можем соответственно вопросы, ответы. Сейчас все проходят опрос, видимо, правильно? Микрофон не работает?
Спикер 8:
00:47:56 — Нет, QR не открывает.
Спикер 7:
00:47:57 — А, QR, говорят, не открывается. Не открывается. А, ты можешь… Нет, нет, нет. Это может быть проблема, да. Не связанная с QR. У тебя же, наверное… Я в какой? Ты же в этом. У меня.
Спикер 2:
00:48:17 — Стартап какой-то. Какой это стартап? Стартап должен работать.
Спикер 4:
00:48:49 — Вот это да, у всех эффективность.
Спикер 7:
00:48:53 — На этом проще нажимать, все остальное сложнее. Это якорная была. Повышение эффективности, да, это как бы базово, мы уже это здесь обсуждали. Я пока скажу, что я ввел в вас заблуждение, точнее меня ввели в заблуждение, а я в следствии ввел в вас заблуждение. Перерыв, обед у нас будет в 14.30. Хочешь повезти? И! Большая буква. И что-то еще!
Спикер 2:
00:49:35 — Да, ну в общем это такая рекламная пауза, просто чтобы все участники из аудитории могли посмотреть, кто как, про что думает, где ключевые вещи. Я, соответственно, тоже на это потом посмотрю, когда будет чуть-чуть побольше времени. И всегда интересно посмотреть, значит, кто какие вещи себе ставит в приоритет.
00:50:02 — Давайте двигаться дальше.
Спикер 7:
00:50:04 — Сейчас про дорожную карту. Я еще раз про вопросы спросил. Есть ли вопросы по вот такой уровне дорожной карты? Понятно, да. Да, у меня вопрос. Представляйте, пожалуйста, что бывает. Да, Максим? Да. Есть еще что-то? Нет, нет, нет.
Спикер ?:
00:50:20 — У меня вопрос по обучению топ-менеджмента этим инструментам, то есть насколько глубоко стоит их погружать, ну то есть должны ли они сами уметь работать в инструменте, допустим, изделия какие-то высокие, вы понимаете, как они работают сейчас, либо это просто они должны понимать, как это работает, то есть на какой уровне их погружение.
Спикер 2:
00:50:50 — Чем глубже, тем лучше. То, что мы сегодня будем рассматривать, это минимум. Четыре часа, может быть, до восьми часов экзектив-мастер-класс на день можно делать, чтобы люди погрузились, начали правильно думать. Второй уровень, у меня есть несколько компаний, в которых я инвестировал и являюсь адвайзером.
00:51:18 — Плюс там много друзей, которые свои есть стартапы делают или что-то подобное. И там фаундеры, особенно если это не технические фаундеры, то есть какие-то люди, понимающие определенный бизнес-процесс, они в итоге начали использовать low-code инструменты типа lovable, тот же самый курсор, для того, чтобы быстро создавать прототипы, создавать какие-то версии того, что у них в голове, как у бизонеров появилось, и потом это передавать команде на уже дотачивание, реализацию.
00:51:51 — То есть это такой способ упростить итерацию над продуктом, над первым прототипом. Не на салфетке это рисовать или на хайдборде, а сам человек, который является там визионером, продуктологом, топ-менеджером, он говорит, смотрите, я вот вижу решение вот так вот. С этим и я и поговорил, потратил там, может быть, два вечера, и у тебя уже есть понимание того, как более предметно со своими сотрудниками на эту тему общаться.
00:52:19 — Вторая вещь. Очень важно, чтобы этого не было разрыва между топ-менеджментом и людьми, которые реализуют технологию, даже, может быть, включая лидера по этой трансформации. Они должны пробовать и понимать, а что на самом деле сейчас возможно.
00:52:40 — Буквально неделю назад я выступал для большого сообщества предпринимателей европейских, и там аудитория была очень разношерстная, начиная от людей, которые говорят «я еще не использовал chat. Gmt», и до людей, которые каких-то там своих агентов, будучи управленцами, пишут и с этим хорошо справляются. И надо максимально гармонизировать первый топ-1, CEO-1, CEO-2, CEO-3 внутри компании до того уровня, чтобы они все одинаково про эту технологию мыслили, потому что иначе будет неэффективность коммуникации отчасти возникать.
00:53:23 — То есть один говорит, слушай, это можно сейчас сделать, за два вечера, за две недели сделаем, прототип придумаем, а второй думает, что это три месяца надо делать, например, или полгода. То есть вот эта компетенция должна управляться в конечном счете. Спасибо большое.
Спикер 7:
00:53:41 — Спасибо. Двигаемся? Давайте еще вопрос.
Спикер 8:
00:53:47 — Только представьте, пожалуйста. Меня зовут Виктор. С какого момента стоит показывать первичные бизнес-эффекты на прототипах, на какой-то кусочке?
Спикер 2:
00:53:58 — Ну, то, что с самого начала, очевидно. Ну, как бы мы про это поговорим, да, и про ROI, качественные количественные эффекты от внедрения. Но вот первые 6−9 месяцев, первые фазы, ваш партнер должен быть accountable and responsible to deliver an outcome. То есть мы не можем говорить, что вы такие классные партнеры, вы классные слайды делаете, и давайте вы нам что-нибудь поделаете, пояй, и потом убежите.
00:54:26 — Это неправильный подход, поэтому я делюсь этими преймворками, чтобы вы как раз с этим партнером внешне будете говорить, у вас было четкое понимание, какие KPI поставить, что ожидать, на каких этапах. Первые 6−9 месяцев любой уважающий себя партнер, который реально понимает, что он делает, он должен вам заделивать бизнес-результат на уровне портфеля. Один проект может провалиться, ничего страшного, Там можно делать какой-то рисковый, какие-то кастомизации траектории этого проекта, и это нормально.
00:54:56 — Либо вместе сделать решение на месяц, два или три, взять его и закрыть. Это не должно идти в минус вашему партнеру, если вы ему доверяете, и у вас правильно построены инцентивы. Но по результату 6−9 месяцев первой фазы портфель должен быть с понятными, позитивными результатами. Второй поинт, коротко обсудим, надо на это смотреть как на стартап внутри компании.
00:55:29 — И итерационно смотреть, у нас гипотезы ценности, они реализовались или нет на этом коротеньком промежутке времени, через месяц, через два. Или мы собрали достаточный evidence, чтобы это инвалидировать и закрыть этот проект. То есть постоянно надо на это смотреть. Третья вещь — это про вот эти вот нуншоты. То есть я про это сказал. Как правило, они требуют больших компетенций, они требуют больших инвестиций.
00:55:56 — Это такие долгие деньги, в которые ты вложился, и там конца и края нет. Ты инвестируешь, ничего нету, нету, нету. В конечном счете либо это закрывают, Говорят, куда вы там инвестируете, у нас тут не лаборатория по муншотам, либо слишком долго ждать приходится, ну, опять же, не у всех терпения хватает. Поэтому, как бы, рекомендация — набирать портфель, в котором есть легкие проекты, средние проекты, и, может быть, один-два муншота, или, как бы, подготовка почвы под этот муншот на следующих стадиях.
00:56:32 — Вот. Ну, такая рекомендация. Поехали дальше. Так, хорошо. Теперь говорим про поиск возможностей. Значит, один из фреймворков называется Itaxonomy Canvas. Значит, он заключается в создании пяти простых вопросов. Первый — это какой бизнес-результат мы хотим достигнуть. Либо повышение выручки, либо снижение издержек, либо запуск новой бизнес-модели.
00:57:01 — Соответственно, как правило, запуск новой бизнес-модели не рекомендуется сразу туда бросаться. Туда бросаются всегда молодые стартаперы. Надо смотреть на корневые бизнес-процессы, смотреть, как для них можно повысить эффективность, и это будет менее рискованным на ранних стадиях внедрения инноваций в деятельности. Потом, с пониманием того, в каких направлениях вообще есть интересные ниши и какие есть возможности технологий, можно попытаться запустить новые.
00:57:32 — Но в целом надо пытаться улучшать существующие бизнес-модели и процессы.
Спикер ?:
00:57:38 — Дальше, второй вопрос. Кого мы хотим сделать счастливее? Клиентов, сотрудников или партнеров.
Спикер 2:
00:57:43 — То есть, соответствующая ценность, которая для каждого из типов ролей, может быть создана, перечислена, можно посмотреть. Дальше, значит, какой бизнес-процесс мы хотим сделать эффективнее? В целом любая компания распадается и бизнес-модель распадается на совокупность бизнес-процессов. У всех есть продажи, маркетинг, финансы, продукт и так далее. То есть мы просто смотрим, какие у нас есть бизнес-процессы, какой из них мы хотим приоритизировать на данный момент.
00:58:14 — Хотим увеличить скорость производства товаров и инвестировать в производство. Хотим повысить profitability, значит, инвестируем в продукт или производство. Хотим увеличить долю рынка, инвестируем в продажу. То есть какие-то ключевые бизнес API, которые есть, они будут в свою очередь помогать правильно выбрать ту зону вашей компании, которая является ключевой на первичном этапе.
00:58:39 — Дальше мы задаем вопрос, какие есть у нас данные для анализа. То есть это табличные данные, тексты, картинки, аудио какие-то другие представления вашей продукции, аудитории или механизмов сбыта. И дальше, как выглядит целевая переменная. То есть это, наверное, такая оттенечка, где начинается техническая составляющая. То есть нам просто на данном этапе нужно просто понимать.
00:59:05 — Ну вот это вот такого типа задачи. Здесь применяется классификация, классический machine learning. Это задача, значит, какая-то генеративная, где чат-блока надо создать. Но просто чтобы понимание было того, какая целевая перемена и какой тип IAI-задачи мы решаем. Как ее делать, не обязательно, управленцу на этом этапе нужно просто понимать, что спросить. Дальше мы все это собираем просто в один кианус, и это механизм того, как быстро структурировать и интегрироваться по идеям, заполняя всевозможные комбинации в этом пространстве.
00:59:42 — То есть это у нас комбинаторное пространство. Можно посчитать здесь какой-то, не знаю, 8 умножить на 8, на 8, на 3, на 3. В итоге получается больше тысячи комбинаций, которые можно перебирать и смотреть, на какие проекты мы сфокусируемся. Те же самые тысячи один проект, который Google перечислил, они чуть-чуть из другого подхода, но тоже там проявляются.
01:00:07 — И дальше, как работать с этим Canvas в интерактивном формате, там в воркшопах внутри вашей организации. Рекомендация заполнять его либо из центра, когда у нас есть понимание, вот у нас бизнес-процесс, мы его хотим улучшить, и дальше смотрим, какие у нас в этом процессе задействованы ключевые роли, какие есть данные, какая задача, какой бизнес-результат из этого мы хотим получить. Либо справа налево. Никогда слева направо делать не надо, Это неправильно, это будет начать технологии ради технологий.
01:00:39 — Значит, мы идем справа налево, говорим, какой бизнес-результат мы хотим достигнуть, и что является минимальным набором активности, который мы должны сделать, чтобы этого достичь. Увеличить выручку, кто за это отвечает, клиенты, сотрудники, партнеры, бизнес-процесс, и, соответственно, таким образом заполняем. Давайте для примера посмотрим несколько заполненных кенвисов, и я проговорю как это получилось.
01:01:08 — Как я обещал, процесс автоматизации ретуши товарных фотографий. У нас есть отдел маркетинга. Отдел маркетинга отвечает за онлайн-витрины и создание классно карточек товаров на маппингплейсе. Соответственно, мы говорим, хорошо, в маркетинге есть сотрудники, Они у нас очень много трудятся в фотошопе, это делает их работа неэффективной, дорогой, тяжелой, скучной.
01:01:34 — И мы им платим зарплату. Хотелось бы этот процесс оптимизировать, сделать так, чтобы время на каждую картинку занимало меньше. Это был процесс более дешевый. И вот у нас в эту сторону заполнился набор галочек. Дальше мы работаем с изображениями и видеотоваром, да, то есть ничего другого у нас здесь нет, и у нас решаются две задачи.
01:02:01 — Классификация, то есть какой это товар, если это мех, то там один подход, значит, к обработке этих фотографий будет использоваться. Если это какая-то продукция с жесткими гранями, там, например, у нас есть там какой-нибудь наушники, то у них другой будет подход использоваться. Если это, значит, какие-нибудь ювелирные изделия, или велосипеды, или что-то подобное, у которых много тонких элементов, есть люстры, то это третий подход.
01:02:27 — То есть нам надо определить, классифицировать тип изображения. И потом мы решаем одна из ключевых задач, это семантическая сегментация. В простых терминах это что? Это называется отделение объекта от заднего фона. Чтобы потом подставить белый фон, его как-то сгладить, но в первую очередь нам нужно обтравить объекты, отделить, то есть мы решаем задачу сегментации, потом там много более детальных задач обработки картинок,
01:02:54 — колоризация, какие-то повороты и так далее, но ключевые базовые задачи, которые нам нужно решить, как будем обрабатывать и как отделить задний фон от переднего. Вот мы как бы собрали такой кенвис. Другой пример. У нас есть повышение эффективности продаж. Мы хотим увеличить выручку. У нас есть сотрудники отдела продаж, они постоянно делают какие-то холодные звонки, встречаются с клиентами и так далее.
01:03:21 — И у них есть информация в CRM-системе про клиентов, кому что продали, предыдущие истории коммуникации, возможно, аудиозвонки или их транскрибация, данные по продажам и закупкам, по конкретному клиенту и по сегменту в целом. И, значит, мы эту всю информацию можем использовать для того, чтобы классифицировать клиентов на интересных, значит, спящих и, значит, перспективных.
01:03:52 — Делать задачи регрессии по ценообразованию, кому какую цену предложить, чтобы увеличить общий, значит, объем закопок и конверсия. Кластеризовать их по типам поведения и искать паттерны, да, то есть, если купил такой товар, купи другой товар, да, Такие типовые задачи в продажах возникают. Вот мы собрали, опять же, цепочку, быстро проретерироваясь, поставив галочки в определенных пунктах.
01:04:20 — Другой пример — оптимизация обслуживания и оборудования. Опять же, мы хотим увеличить выручку. Просто представьте, что вот этого ничего нет с левой стороны. Мы говорим, увеличить выручку хотим. Компания хочет увеличить выручку. Кто за это должен отвечать? Кого мы, значит, хотим сделать счастливее? Клиентов. Почему клиенты сейчас несчастные? И как это блокирует выручку? Ну, возможно, у нас продукция не в достаточном объеме продается. У нас большой спрос, у нас нет предложений, нам нужно каким-то образом расширить вот эту вот проблему внутри компании.
01:04:57 — Кто за это отвечает? Производство. Потому что они производят недостаточно продукции, возможно, есть какие-то затыки в производстве. Да, вот мы дошли до этого пункта. Дальше мы говорим, хорошо, в производстве какая проблема ключевая существует? Ну давайте посмотрим вообще данные, какие мы про производство, про наше собираем. Ну мы собираем данные про то, какие у нас есть типы товаров. Значит, мы фотографируем наше устройство, значит, контроль качества этого делаем. У нас есть аудио, как барахлит какой-нибудь, значит, мотор определенного устройства на производстве.
01:05:29 — У нас есть временные ряды, которые собирают температуру, влажность, перегрев, уровень шума, еще какие-то характеристики наших изделий. И мы хотим, что сделать? Поиск аномалий. У нас ломается наш определенный организатор производства, из-за этого производство простаивает, вся линия останавливается, из-за этого мы недопроизводим новый товар на рынок. То есть вот мы собрали цепочку справа налево, первичное нажимание было увеличить выручку, и мы посмотрели, как все это связывается, на какую конечную задачу Machine Learning и ИИ мы можем это замкнуть.
01:06:06 — Абсолютно тот же кейс по оптимизации обслуживания оборудования. То есть вот здесь у нас была задача расшить историю с выручкой, сделать клиентам доступ к продукту более легким. А дальше мы можем сказать чуть-чуть другое. У нас есть сотрудники, которые обслуживают это оборудование, и они по рекламе раз в месяц приходят на завод, по всем этим данным принимают решение, нужно ли его смазать маслом, сделать сервисное обслуживание и так далее.
01:06:44 — И мы, значит, их неэффективно посылаем. Есть какой-то менеджер, отвечающий за сотрудников техобслуживания, и вот он распоряжается этим бюджетом.
01:06:54 — Мы можем к нему прийти и сказать, у нас есть так называемый preventive maintenance, то есть более умный подход к организации вот этих технических отсмотров, когда мы приходим не по рекламе тут, каждый месяц, каждые три месяца, или когда сломается, а мы говорим, так, по нашим датчикам кажется, что вот эта штука начинает барахлить, перегреваться, пока это не случилось, давайте мы заранее придем, масло зальем, что-то починим, подкрутим, и у нас это заработает. Да, и как бы тогда у нас число визитов будет значительно меньше, потому что мы будем приходить только когда надо, а не когда попало.
01:07:35 — И у нас в результате снизится затрата. То есть, в принципе, один и тот же бизнес-процесс, но мы поставили чуть-чуть другую целевую задачу, и это пример того, как можно с этим Canvas-ом работать. И это такой очень простой, абсолютно не претендующий на какую-то академическую изощренность, механизм, как правильно организовать общение между вашими бизнес-стрейкфолдерами про различные кейсы внутри компании.
01:08:01 — Ну и последнего, например, у нас есть голосовой помощник Алиса. Это новый бизнес, новая бизнес-модель. Мы хотим сделать счастливыми клиентов, мы хотим их удивить на момент запуска этой колонки. Это вопрос про продукт. Мы собираем абсолютно новую ценность на рынке. У нас есть какие-то данные про пользователей, у нас есть предпочтение того, какие фильмы, музыку каждый пользователь предпочитает.
01:08:26 — У нас есть аудио, значит, данные про то, как голосовой помощник общается с аудиторией и, соответственно, назад получает аудиотреки разных лингвистических групп с разным акцентом и так далее. И вот мы начинаем решать задачи классификации, регрессии, там, поиск паттернов, подкрутки с помощью reinforcement learning. То есть это вот как может собираться история про новые бизнес-модели.
01:08:53 — Я здесь паузу сделаю, какие-то есть вопросы про эту штуку.
Спикер 9:
01:08:59 — Спасибо большое за информацию. А подскажите, пожалуйста, как среди всех этих фреймворков делать пункт про оценку эффектов?
Спикер ?:
01:09:10 — То есть задачу мы, допустим, определили, для приоритизации того, что мы все-таки будем переходить в первую очередь делать, нужна какая-то эта доценка.
Спикер 2:
01:09:18 — Какой это у нас? Все, супер, следующий фреймворк как раз про это. Мы постепенно, просто чтобы понятно было, у нас такая как бы воронка, мы начинаем максимально широко, тысяча кейсов, которые, ну, понятно, что тысячу не надо обсуждать, слишком много времени будет.
01:09:39 — Мы как-то просто просеяли через этот более структурированный кенвис сказали, вот эти вот дорожки в Canvas, мы приоритизируем, на качественном уровне выглядит как правильно, интересно, все равно бизнес стейкхолдер понимает, где ценность компании заложена. Давай я немножко…
Спикер 7:
01:09:59 — Никита, давай немножко обверни на это, немножко соединю с тем, что мы делали. Это как бы совсем упрощенный вариант того, что мы с вами разбирали. Вот первый модуль, бизнес результат, чего хотим, бизнес-бенефициар, в каком месте мы это будем делать, функция, здесь выбираем, здесь стравные артефакты, о которых мы ранее говорили.
01:10:31 — Это была задача Никиты Васильевны, это была операция, которую нужно с этими артефактами делать. Там была очень большая операция по правилам операции, и можно их отнести в это участие. Количество операций тоже можно решать, тогда у вас получается вся карта.
Спикер 6:
01:10:49 — Здравствуйте. Я хотела бы уточнить один вопрос. Вот у нас есть кейс обслуживания оборудования 1 и 2. Они могут идти как проекты параллельно?
Спикер 2:
01:11:03 — Конечно. И это как раз история с reuse. То, что мы и затраты можем улучшить в нашем кейсе, и выручку. И когда у нас будет структурирование этого кейса, как защита бизнес-кейса на бюджет условно говоря, А мы скажем, смотрите, какой классный кейс. Это не меняется, значит, с левой стороны те же самые данные, те же самые задачи решаем в одном и том же бизнес-процессе.
01:11:29 — А польза двойная. И выручку увеличиваем, и затрат снижаем. Классно-классно, значит, в два раза более интересный кейс. Спасибо. Поехали? Да, двигаемся дальше. То есть мы собрали в копилку много таких цепочек.
01:11:49 — Дальше мы что начинаем делать? Мы описываем бизнес-процесс, то есть если мы говорим про какие-то клиентские истории, то там CGM, то есть Customer Journey Mapping, если это внутренний бизнес-процесс, то это просто анализ операций. Что у нас здесь ключевые вопросы на этом этапе? Мы описываем состояние, которое существует в бизнес-процессе максимально детально.
01:12:16 — Мы описываем логику перехода из одного состояния в другое, сколько требуется времени на переход, какая конверсия, значит, сколько времени проводится в каждом из состояний, какие существуют альтернативные точки входа в этот бизнес-процесс, да, и это достаточно стандартная история. Дальше мы начинаем задавать очень интересные вопросы, который связан с AI в большей степени, чем остальные. 6, 7 и 8. Нам надо понимать, какое требование время отклика системы.
01:12:48 — Мы еще эту систему не разрабатываем, но если мы понимаем, что это мгновенное взаимодействие, то есть есть бизнес-процесс, и нам нужно пользователю AI ответы генерировать мгновенно, то это сложнее будет система, чем если это какая-то offline периодическая обработка. С точки зрения стоимости, Как правило, мгновенные системы более быстрые, более дорогие, чем какая-то заточная обработка оффлайн. Да, и мы на этом этапе уже можем правильный вопрос задать, понять, как у нас устроен этот бизнес-процесс, не писать код, но уже понимать.
01:13:22 — Так, вот проект вроде сложный, здесь у нас мгновенная обработка. Второй вопрос. Какие инструменты используются в бизнес-процессе? Почему? Потому что если вы в этот процесс неправильным образом интегрируетесь, у вас будет резистентность от ваших людей, которые этим процессом управляют. Они будут говорить, что это неудобно, вы сделали яй какое-то, но мы так не работаем, зачем вы из нашего бизнес-процесса и понятного потока решения задач куда-то в другую систему переносите,
01:13:58 — там она изолированная, там ваше яй хорошее работает, но мы не можем его скрестить с тем, чем мы занимаемся, либо это создает дополнительную сложность с переключением контекста. Поэтому нужно описать вот эту вот среду экосистемы, в которой ваш конкретный оператор процесса принимает решение и обычным образом работает. Это снизит риски с точки зрения внедрения и adoption, то есть потребления этого продукта, когда он будет реализован.
01:14:26 — И пример, например, про наш проект по редушированию. Мы, значит, такие айтишники, говорим, вот, сейчас мы сделаем API, на вход картинка, на выходе классная картинка, и все, будем продавать всем этот API, они будут у нас покупать, значит, просто в интеграции, очень быстро и понятно. Мы начали общаться с командами контента, различных маркетплейсов, больших каких-то производственных организаций.
01:14:55 — Они говорят, ну, приходите к нам через три месяца, через полгода. Наша IT-команда полностью oversubscribed, они заняты, они не могут интегрировать этот API. Мы говорим, ну как это, там два дня работы. Они говорят, ну у нас как бы все заняты, мы не можем. А нам как стартапу надо продавать максимально быстро, чтобы эту всю гипотезу проверить, продуктовую ценность, просто с точки зрения роста ревня.
01:15:20 — Соответственно, мы что сделали? Мы за три недели разработали полноценный фронтенд, то есть такой software as a service, в котором человек, который не технический специалист, приходит так же, как и через какой-то Google Cloud, загружает свои картинки, нажимает пять кнопочек, выбирает четыре опции, и получается, значит, обработка картинок полностью без необходимости внедрения какой-то участия IT-команды.
01:15:47 — То есть теперь у тебя чисто общение происходит с функциональной командой, отвечающей за контент, а не с айтишниками. Скорость продаж увеличивается, ценность увеличивается. Следующий этап. Мы сделали эту штуку, они говорят, классно, конечно, очень удобно все стало, айтишников мы не потрогали, но все равно не хотим мы у вас покупать. Мы им говорим, а что сейчас-то у вас не устраивает?
01:16:12 — Они говорят, ну, как бы, у вас же и ошибки там иногда совершают, и иногда мы чуть-чуть по-своему обрабатываем картинки, у нас там определенно есть гайдлайны по бренду, по стилям, а у вас эта система, в общем, для всех обрабатывает. Либо у вас должна быть кастомизация умная с помощью искусственного интеллекта, либо что-нибудь еще придумайте. Кастомная обработка с помощью искусственного интеллекта слишком дорого и сложно пилить, плюс нужны данные, про это мы поговорим.
01:16:43 — Мы им говорим, хорошо, как насчет того, чтобы мы в фотошопе дали вам экспорт, и мы разобьем вот эту всю обработку не как финальная картинка в JPEG или PNG формат, которые вы будете выкидывать на сайт сразу же, одна склеенная картинка. А мы вам давайте будем в первичных исходниках, в PSD формате или в TIFF формате разбивать по слоям всю обработку картинок, начиная с маски, с поворотами,
01:17:09 — со всеми другими трансформациями, которые мы с этой картинки делаем, и ваша команда ретуширования может по этим слоям легко итерироваться и делать, что хотят. Они говорят, о, класс, давайте сделаем. Мы такую штуку сделали, и мы проговорили про то, в какой последовательности они делают разбивку этих операций, и у нас даже была вот эта вот разбивка операций, расположенная под разных клиентов. Но это было достаточно просто сделать, потому что мы могли сказать, так, опция по расслоению, так скажем, картинки у одного клиента чуть-чуть другая, чем у другого, давайте так вот будем это разбивать.
01:17:45 — Очень удобно, и в итоге вот так начало продаваться. Если бы мы были гибким стартапом, быстренько проитерировали, сами все сделали и создали ценность компании. А если бы этого процесса не было, либо мы сделали бы продукт, сказали, ну вот все, мы весь бюджет, который нам выделили на этот год на AI, Мы сделали классный API, масштабируемый, и мы его хотим продавать.
01:18:16 — А следующий бюджет нам надо ждать через полгода будет одобрение в больших компаниях. И что мы будем делать? Непонятно, что мы будем делать. То есть мы деньги заморозили, ценность до конца не создали и проблему не решили. То есть нужно вот это понимание того, как мы интегрируемся в бизнес-процесс, естественного создания ценности операторам и конкретного бизнес-процесса.
01:18:40 — И дальше нам нужно понимать, какие данные о сотрудниках и клиентах собираются в каждом состоянии, то есть чтобы понимать, какая же сложность этой задачи. Это быстрые данные, то есть здесь мы поговорим, объем. Сколько данных порождается в этом бизнес-процессе? Если много данных, соответственно, сложнее задача. Мало данных, проще задача с точки зрения управления этими данными, но мало данных, в свою очередь, сложность создает с точки зрения обучения искусственного интеллекта, потому что для искусственного интеллекта больше данных лучше, он выучится лучше.
01:19:13 — Дальше разнообразие данных, да, то есть какие у нас модальности, у нас есть картинки, текст, еще что-то, да, то есть если разнообразные данные порождаются, тоже, соответственно, нужно про это думать. Скорость порождения данных, да, то есть это может быть какая-то одноразовая пакетная обработка, мы их сохранили в одном месте и потом к ним обращаемся. Либо это может порождаться постоянно с очень большой скоростью, соответственно, Время подклика и время обработки всех этих данных для того, чтобы ценность бизнеса создавать, она должна быть очень быстрой.
01:19:45 — Тоже про этот кейс расскажу. И, значит, достоверность данных, то есть верасити. То есть у нас, допустим, данные с сенсоров в поле собираются, и у нас какой-то сенсор просто батарейки села, перестал собирать эти данные. То есть мы теперь определенный сегмент нашего поля, который мы хотели умными какими-нибудь поливалками поливать.
01:20:07 — Не собираетесь ли данные? Нам нужно подумать, а как сделать покрытие с избыточностью, чтобы число сенсоров, даже если они будут из-за батарейки переставать работать, у нас достаточно было покрытия. И это тоже описывается на стадии данных. Соответственно, вот эти все пункты запомнили, поняли, как у нас этот процесс работает от и до. И еще один важный пункт, который здесь выделен — это вопрос 3, 4 и 5.
01:20:35 — С точки зрения теории операции есть такая теорема о том, что в каждом бизнес-процессе существует bottleneck, и эффективность процесса или его пропускная способность всегда определяется пропускной способностью bottleneck. И очень много, к сожалению, маркетинговых различных исследований, которые говорят, мы внедрили AI для того, чтобы решить задачу A из процесса, который состоит из 5 состояний или 20 состояний.
01:21:08 — И они говорят, вот в этом процессе мы увеличили на 95% производительность. Это же не означает, что в 95% производительность всего процесса повысилась. И вот они вот эти очень точечные маркетинговые какие-то внедрения делают, говорят, смотрите, у нас AI работает, вот здесь повысилось. Но в корневом процессе bottleneck был в другом месте, и мы его не расшили. И поэтому нужно смотреть, где у нас ключевой bottleneck, и фокусироваться на это, где ключевая ценность бизнес-процесса и сложности существует.
01:21:41 — По мере улучшения этого бизнес-процесса bottleneck будет плавать. То есть вы расшили одну точку с неэффективностью, потом появилось новое. Фокусируйтесь на это. Постепенно у вас процесс и его общая пропускная способность, и его скорость работы будет увеличиваться.
01:22:00 — Вот это вот процесс улучшения процесса. Так, если можно сказать. И давайте пример. Кейс по автоматизации. То есть у нас, может быть, это внешний фотограф, у нас, может быть, собственная фотостудия. Они выделяют объект, удаляют фон, потом делают какую-то редушу цветокоррекции, поверхности, потом выворачивается этот продукт на белом фоне и публикует изображение. Соответственно, мы говорим, что у нас на одну фото требуется от 5 до 60 минут, 3−5 фото на товар, столько фото у большого магазина в день.
01:22:34 — Это все офлайн-обработка. Они используют Adobe Photoshop, Adobe Lightroom для того, чтобы делать по-хорошему. Если бы мы сами по своим треймворкам, которые в итоге я создал, знали, мы бы просто сказали, а, вы фотошоп используете, мы не будем делать API, мы сразу же в фотошоп вам будем придумывать, как улучшить. Дальше, значит, по данным, каждая картинка весит 100 мегабайтов, если это TIF, полное разрешение одного продукта.
01:23:07 — Соответственно, если у нас 100−1000 картин в день делается, то это 10−100 гигабайт уже, то есть это уже большие данные. Нам нужны изображения до и после. Часто эти изображения просто команда контента выкидывает. Они говорят, зачем нам? Они очень много весят, мы их просто удаляем. Я говорю, нет, давайте мы вам за эти деньги будем платить и забирать у вас даже эти изображения. То есть это тоже заранее нужно готовить данные, если вы хотите искусственный интеллект внедрять.
01:23:37 — Новые фото каждые 5−60 минут, как бы это достаточная скорость фотоклика, сопоставимая с тем, как человек делает. И этой деятельностью занимаются профессиональные ретушеры, да, то есть мы высоко им доверяем, и они делают это очень качественно. Да, вот мы обстали бизнес-процесс, поняли его, какие-то ключевые данные собрали, которые на следующем этапе мы будем использовать для оценки финансового эффекта.
01:24:02 — Да. Теперь про качественный эффект. И у меня вопрос к аудитории. Чтобы логически завершить какой-то блог, мы можем до трех часов поговорить и отложить на 30 минут обед? Или сейчас сделать перерыв?
Спикер 7:
01:24:21 — Говорят, можно. Половина говорит, можно, а половина говорит нет. Тут, я так понимаю, надо либо сейчас идти, потому что вот смысловый пункт оценки качества. У тебя сколько на оценку качества доложит время?
Спикер 2:
01:24:45 — Но я могу за 30 минут рассказать точно.
Спикер 7:
01:24:48 — А, понятно.
Спикер 2:
01:24:51 — Но не за 3 минуты.
Спикер 7:
01:24:53 — Понятно, не за 3. Давайте по 2 минуты расстроимся. Так, значит, решение принимаем. Придется потерпеть. Давай, 30 минут, Никит, закончим, и пойдем поиграемся.
Спикер 2:
01:25:09 — Хорошо, спасибо. Двигаемся дальше. Соответственно, качественные эффекты. То есть мы просеяли наши возможные проекты, каждый из них описали, детально поняли, какая там цепочка производства, и дальше начинаем говорить про качественные эффекты. Здесь у нас что может быть? У нас принципиально есть три траектории развития этого бизнес-процесса.
01:25:39 — Если мы ограничены спросом, то есть представьте, что у нас есть число задач и сотрудники, то есть у нас есть три условных сотрудника, которые делают одну единицу задач в единицу времени. Мы ограничены спросом, то есть у нас тогда какая есть идея? За счет повышения эффективности одного сотрудника, он будет те же самые три задачи один делать, эти два сотрудника высвобождаются, и они обрабатывают тот же самый объем спроса.
01:26:13 — Дальше, если мы ограничены предложением, то есть у нас процесс недопроизводит то, на что есть спрос на рынке. Тогда мы что говорим? Оставляем трех наших сотрудников, каждого увеличиваем эффективность в три раза, ну или с каким-то коэффициентом за счет искусственного интеллекта, и они делают 9 единиц товара вместо того, чтобы делать 3 единиц товара.
01:26:40 — Да, это модель, когда мы ограничены предложением. И дальше третья траектория — это повышение качества в самом процессе. Мы оставляем тех же самых трех сотрудников, они продолжают делать те задачи, которые они до этого делали, а высовываемое время используется для создания добавочной стойкости поверх того, что было раньше стандарта. Например, есть много всяких страшилок, что искусственный интеллект заменит всех сотрудников, люди потеряют работу и так далее.
01:27:14 — На самом деле, если к этому умно подходить, то такой вопрос не возникает. То есть мы можем тех людей, которые уже существуют внутри компании, для других целей эффективно использовать. При этом они также являются носителями культуры, они понимают все бизнес-процессы и так далее, нам надо просто их реализировать на другие задачи, в которых есть возможность им создать ценность.
01:27:43 — И как мы подошли к резистенции сотрудников отдела контента, когда мы к ним приходили, говорили, у нас есть AI, который вместо вас картинки будет делать, у них первая реакция какая? Нет, мы будем саботировать продажи, мы сейчас все возможное сделаем, скажем, что я не работаю, сохраним свои рабочие места, и, значит, эти ребята от нас отстанут. И мы, значит, что делали? Мы говорили, что мы нашли какое-то исследование от Amazon и Ebay, которое говорит, что если увеличить число картинок на товар, то конверсия в покупку растет, и коэффициент возврата товара на склад из-за того, что купил не тот товар, не так выглядел, не те ожидания, они тоже уменьшаются.
01:28:32 — То есть мы увеличиваем средний чек или объем продаж, и в то же самое время мы уменьшаем ценность по логистике, по обоспратам. И там график такой, что он начинает замедляться, по логарифмической шкале, чем больше картинок, тем выше продажа, но потихонечку он замедляется. И где-то на уровне 14 картинок, но, по сути дела, если в 3D-пространстве любой продукт фотографирует, на этом можно только 14 разных ракурсов найти, там, слева, направо, фронтально, с угла, издалека, близко, там, какая-то текстура, еще что-то там, и до 14 картинок это монотонно растет.
01:29:14 — Соответственно, если сейчас стоимость создания одной картинки товара определенную цену имеет, то в среднем на рынке 3−6 картинок делают и говорят, что достаточно, как у всех, двигаемся дальше, и это верхняя грань. Ну, а мы говорим, смотрите, мы увеличиваем ценность, уменьшаем стоимость создания одной картинки.
01:29:40 — Теперь вместо создания 3−6 картинок мы можем делать 6−12 картинок, поскольку мы, допустим, на 50% увеличили эффективность этого бизнес-процесса. Классно, классно. И таким образом мы говорим, что у нас есть возможность расшить этот бизнес-процесс, добавочную сумму создать, которую вы раньше просто не могли чисто экономически открыть для себя, потому что у вас были определенные ограничения по стоимости и конкуренция среднего пары требовала хотя бы трех-шести картинок.
01:30:14 — Другая история такая, что есть помимо то, что называется product shot photography, когда у тебя есть товар на белом фоне, классическая фотография, есть еще lifestyle photography, когда у тебя есть товар в интерьере, товар, используемый каким-то человеком и так далее, часто это генеративно и прекрасно делает.
01:30:41 — На тот момент такой возможности не было, надо было дополнительные фотки генерировать, фотографировать, обрабатывать, и, опять же, такие картинки увеличивают конверсию, если они присутствуют, они для определенной целевой аудитории вызывают больше резонанс, и раньше эти картинки никто не делал. Мы опять же приходили и говорили, смотрите, вот эту вот рутину, очень скучные, однотипные картинки на белом фоне мы забираем на себя.
01:31:08 — А теперь у вас, как у бренда, появляется новая возможность, особенно для direct-to-consumer брендов, которые напрямую продают и очень сильно на бренде, на социальных сетях, например, работают. У вас есть возможность дополнительно инвестировать высокого пожилейного бюджета в креативные лайфстайл-фотографии и использовать тех же самых сотрудников, не увольнять их, дайте им новую работу, которую они раньше просто делать не могли. Вот такой у нас был как бы питч разговор о том, чтобы никого не уволнять, но создавать дополнительную ценность.
01:31:40 — Но в целом как бы реальность такова, что в каких-то случаях сокращения нужны, Если компания находится в ситуации с кризисом, ограничение спросом и так далее, то это вот те траектории, по которым я и могу двигаться. Второй качественный эффект, значит, фреймворк по качественному эффекту заключается в перечне типовых явлений, которые искусственный интеллект может привнести в бизнес.
01:32:12 — Искусственный интеллект увеличивает скорость решения задач. Искусственный интеллект может работать 24 на 7, то есть увеличивает доступность к определенным операциям. Искусственный интеллект может масштабировать качество решения данных. То есть по такой модели работы различны современные модели диагностики по радиологии, по другим снимкам, катетрии, рентгену и так далее.
01:32:39 — Искусственный интеллект может повысить безопасность бизнес-процесса. То есть есть такая штука, как Vision Zero. Все предприятия, которые, значит, тяжелые промышленности, в целом с высоким коэффициентом риска для людей, у них есть необходимый KPI сделать так, чтобы на производстве не было летальных случаев. Соответственно, там, где искусственный интеллект может взять на себя часть сложных рисковых операций, это нужно делать.
01:33:08 — Пример, какие-то дроны, которые облетают, сканируют лопасти для ветряков, или дроны, которые сканируют шахты, что-то подобное. То есть это пример применения яйц безопасности. Предсказуемость. Человек через 6−8 часов рутинной деятельности утомляется и качество падает.
01:33:34 — В то время как искусственный интеллект может стабильно работать с одним и тем же качеством. И дальше, значит, прозрачность. То есть искусственный интеллект не имеет какой-то адженды. То есть человек может сказать, так, я сейчас в этом процессе немножко что-то напридумываю, и у нас, значит, появится возможность какой-то недобросовестную частичную получить выгоду личную.
01:34:07 — Искусственный интеллект не имеет таких задач личных, то есть он просто будет максимально открыто работать и объективно принимать решения согласно логике,
Спикер ?:
01:34:18 — А не личной адженте, то есть в случае недобросовестности каких-то сотрудников.
Спикер 2:
01:34:25 — И происходит упрощение бизнес-процесса, это тоже одна из важных вещей. Если у вас сейчас в бизнес-процессе работают профессионалы, то после внедрения искусственного интеллекта часть сложных задач мог перейти на искусственный интеллект и понизится планка к талантам. То есть у вас открывается доступ к значительно большему числу специалистов, которые могут в этом бизнес-процессе быть полезными.
01:34:55 — Два примера. Один это, уже мы проговаривали, программирование. То есть у нас раньше были только профессиональные машин-лирик-инженеры, которые могли делать искусственный интеллект. Сейчас каждый софт-инженер с доступом к какому-нибудь гига-чат или открытой модели может создать чат-бота и искусственный интеллект, чисто прочитав tutorial и спецификацию API.
01:35:22 — Другой пример — это, соответственно, у нас в ретишировании, когда были картинки, профессиональный ретишер набивает руку, работает по ретишированию большого числа картинок, в какой-то момент они становятся способными сложные какие-то делать задачи по ретушированию.
01:35:48 — Если мы упрощаем механизм взаимодействия, механизм ретуширования, то есть вот сейчас, грубо говоря, чтобы отредактировать личную фотографию для соцсетей, ты просто загружаешь фотку, говоришь, сделай задний фон чуть-чуть блер, значит, фокус на лицо, значит, ну и определенные как бы задачей по трансформации закладываешь, и это искусственный интеллект сделает блестяще.
01:36:16 — В то время, как раньше надо было идти в фотошоп, накладывать маску, какие-то сложные операции проводить, соответственно, теперь, по сути дела, каждый человек стал, тяг или нячей, профессиональным ретушером для определенного подкласса задач, на которые искусственный интеллект был натренирован. И к чему это все как фреймворк? То есть мы каждый раз, когда защищаем кейс, нам нужно понимать, какая ценность от этого происходит, и вот на качественном уровне это перечень тех улучшений, которые мы можем привнести в бизнес-процесс.
01:36:49 — Все они, понятное дело, неприменимы к конкретному бизнес-процессу, но это как бы меню, из которого вы можете выбирать, И уже не надо думать, а что же еще искусственный интеллект мне может создать в моем бизнес-процессе на качественном уровне.
01:37:08 — Пример, по автоматизации ретуши.
Спикер 9:
01:37:11 — Пока далеко не ушли, а качественный эффект вы в деньги оцениваете, как-то перекладываете, или этого достаточно уже для аргументации запуска какой-то АИ-инициативы?
Спикер 2:
01:37:23 — Все считать надо. Но здесь я отвечу так на этот вопрос, что все считать надо, но моя задача здесь какая? Снабдить вас набором фреймворков, которые позволят максимально далеко продвинуться без запроса о помощи от других специалистов.
01:37:48 — То есть, грубо говоря, если сейчас я вот эти праймворки вам расскажу, вы скажете, так, я все приблизительно понимаю, как мне отранжировать портфели, как реализировать кейсы, какая приблизительно сложность будет, и мне не надо общаться со специалистом по машин-лернингу, который мне будет говорить, о, вот это сложная задача, это легкая задача. То есть я дам такую методичку, которая скажет, приблизительно вот так вот сложность проекта устроена.
01:38:14 — Соответственно, на качественном уровне, в этих story points, мы сможем оценить, насколько этот проект сложнее, чем тот, и дальше сравнить это с количественной характеристикой, и комбинация оценочных вещей позволит приоритизировать портфель и сверху вниз идти по ценности и где-то поставить отсечение.
Спикер 7:
01:38:41 — У тебя только один кружочек с предсказуемостью, с приходом генеи, будет немножечко страдать, скажем так.
Спикер 2:
01:38:50 — Ну там есть, значит, галлюцинации, но мы же сейчас говорим, соответственно, про искусственный интеллект в целом, то есть не только генеративный. Согласен, хороший комментарий. То есть, грубо говоря, их надо перекладывать в деньги, но потом как-нибудь. Я думаю, что надо будет делать набор тезисов и quantitative, то есть количественный для финансистов, людей, которые любят считать бюджеты, и качественный для каких-нибудь маркетологов и других.
01:39:31 — То есть у тебя есть большой набор стейколдеров, тебе со всеми этими стейколдерами нужно правильно уметь общаться и обосновывать ценности своей инициативы, как-либо функционального менеджера, который пытается получить бюджет от общего кулла AI-трансформации, либо как от AI-лидера, который говорит «так, вот смотрите, здесь у этого проекта такая ценность, у этого такая ценность».
01:39:54 — Но это все является частью упаковки кейса. Двигаемся дальше, соответственно, вот как раз перешли мы про деньги. У нас 17 минут осталось до обеда. Метод декомпозиции, значит, мы имеем какое-то число сотрудников, вовлеченных в определенный бизнес-процесс. Мы знаем, сколько клиентов на сотрудника, мы знаем, сколько товаров на одного клиента покупается, то есть размер казины.
01:40:25 — Мы знаем, значит, средний объем на один товар, и мы знаем конверсии клиента купить конкретный товар, добавить его в корзину. Соответственно, мы хотим, значит, и общая там выручка у нас вот считается как число сотрудников, и набор всех вот этих компонентов перемножается в итоге в общую выручку.
01:40:47 — Мы хотим увеличить каждый из этих показателей. Примеры какие существуют? Стимулирование продаж, директ-маркетинг, таргетированная реклама, предсказание спроса более аккуратно, оптимизация маршрутов, кросс-продажи, контроль запасов, повышение урожайности. Это просто какой-то перечень проектов, в которых мы можем увеличить выручку за счет внедрения AI в определенный бизнес-процесс.
01:41:18 — Если есть желание, можем какое-то проговорить, чтобы было понятно. Может быть, предсказание спроса, если никто не против? Давайте поговорим про предсказание. У нас есть, например, склад, и у нас есть товары на полке.
01:41:44 — То есть, как правило, эта логистическая цепочка состоит из нескольких звеньев. У нас есть конечная точка, которая близка к потребителю, то есть магазин, там на полке лежит несколько единиц товара. Потом у нас есть на складе в магазине еще какое-то число единиц товара, потом у нас есть распредельный центр, из которого происходит развоз диспетчерской службой по розничным точкам, потом есть у нас какой-то мега-верхаус, который продукция доставляется, и конечный узел — это производство.
01:42:19 — Может быть, в той же самой стране, может быть, в другой стране. И у нас происходит распределение товара по всем узлам этой цепочки. Теперь пример какой. У нас есть, допустим, клиент, он пришел в магазин, и он видит, что на конкретной полке у нас не существует товара.
01:42:40 — Соответственно, это потеря выручки, то есть он бы купил, если бы было, но у нас этого товара почему-то не оказалось, потому что-либо не дозавезли, либо не сделали replenishment из склада на магазине на полку. То есть в каждом из этих узлов нужно, чтобы нужный объем товара был доступен. Соответственно, у нас есть сотрудник, который отвечает за репленишмент определенного товара, то есть за каждым сотрудником какая-нибудь стойка товара, гигиена товара, соусы, товары мучные, товары молочные.
01:43:24 — И вот человек за этот спектр товаров в ассортиментной матрице отвечает, он ходит, проверяет, фотографирует и перевыполняет эти нужные товары. Соответственно, мы должны оценить, сколько товаров будет куплено каждого типа максимально точно. И сделать так, чтобы когда товар у человека будет желание купить, чтобы этот товар был.
01:43:47 — В то же самое время у нас вторая переменная существует, которая говорит о том, что если у нас определённых товаров слишком много на складе, то мы замораживаем все эти деньги, они у нас не откручиваются в бизнесе на какие-то другие товары, и мы замораживаем площадь хранения на складе под этот товар, который никто не покупает, то есть он застаивается, возможно, он и срок годности истекает и так далее.
01:44:16 — И нам, исповедуя концепцию lean supply chain, нужно сделать так, чтобы в каждом узле вот этой вот цепочки было столько товара, сколько минимальное число товара, но в то же самое время достаточно для того, чтобы удовлетворить все потребление вот этого узла и дальше ближе к потребителю. И вот мы, соответственно, смотрим, то есть мы предсказываем, сколько у нас покупают там томатной пасты. Сколько людей уникальных покупают, сколько томатной пасты покупают, значит, средний объем конкретной пасты, значит, и вероятность купить.
01:44:59 — Сколько людей в этом бизнес-процессе замешано для того, чтобы обслуживать постоянные пополнения. И мы можем оценить, если мы увеличим доступность нашего товара, и там всякие модели эластичности можно построить, как доступность товара влияет на выручку за счет экспериментов, и мы начинаем понимать, как вот эта кривая себя ведет.
01:45:22 — Соответственно, мы говорим, хорошо, если мы разошьем этот проект с помощью искусственного интеллекта, то есть, во-первых, мы будем более аккуратно прогнозировать, когда какой товар нужен, это первая вещь, а вторая история — это, в свою очередь, говоря про затраты, мы, как правило, эти штуки идут вместе в таких операционных процессах. Мы можем более эффективно использовать сотрудников так, чтобы он не одну стойку молочных продуктов обрабатывал, а еще и лучшую продукцию параллельно, потому что
01:45:52 — Мы эффективность этого сотрудника повысили, и мы знаем, как его эффективно просить нужные товары высполнять, не просто глупо сканируя каждую стойку товара, а предиктивно говорить, вот этот товар поменяй, вот этот товар поменяй, вот этот товар поменяй, плюс мобильное приложение, которое ему будет эти инструкции давать. Но вот пример то, как думать про такую задачу.
01:46:30 — Давайте дальше. Теперь про снижение затрат. У нас есть сотрудники, есть число операций на сотрудника, есть средняя зарплата сотрудника, время на операцию и успешность автоматизации. Соответственно, какие-то из этих вещей мы хотим увеличить, какие-то из этих вещей мы хотим уменьшить, чтобы в целом снизить затраты. Соответственно, перемножение всех факторов — это общий бюджет стоимости или издержек, которые мы хотим оптимизировать.
01:46:58 — И, соответственно, пример каких-то, как правило, back office процессов, которые существуют, в которых мы можем понизить стоимость процесса за счет внедрения искусственного интеллекта. Я думаю, самое простое — это, как правило, анализ истории с издержками. То есть это самые легко обосновываемые проекты, где нужно внедрять искусственный интеллект. Другая вещь, могу сказать, как, значит, человек, который занимался продажей таких решений, продавать сокращение сдержек очень сложно.
01:47:37 — Почему? Потому что у тебя есть менеджер, который сейчас обладает бюджетом X. А ты говоришь, что в следующем году у тебя будет бюджет X делить пополам, просто потому что ты купишь у меня искусственный интеллект. Ну и плюс за искусственный интеллект еще заплатишь там 0.1 единица, то есть у тебя будет 0.6х бюджет по сравнению с 1х в прошлом году. И люди начинают говорить, а мне вообще это надо? Я, может быть, не буду, соответственно, внедрять искусственный интеллект, потому что я хочу, я свою успешность связываю с размером бюджета, которым я управляю в организации.
01:48:12 — То есть это неправильно поставленные мотивации сотрудников, это решается повышая уровень лица покупающего продукт на один уровень выше, потому что тот менеджер будет руководствоваться интересами компаний и эффективностью конкретных бизнес-процессов, в то время как на следующем уровне в организации, возможно, может быть такой конфликт интересов.
01:48:37 — Но в целом это правильная история, потому что мы за счет искусственного интеллекта какие-то скучные операции заменяем. Данный кейс, про который мы уже говорили, это автоматизация фотографии.
Спикер ?:
01:48:54 — Там бизнес-процесс построен сильно на ручном труде, и мы заменяем это с помощью искусственного интеллекта.
Спикер 2:
01:49:04 — Дальше давайте продвинемся по структуре затрат в AI-проектах. То есть мы как бы вот здесь оценили upside, то есть суммарный объем средств, которые мы можем высвободить по сравнению с текущим состоянием дел за счет внедрения искусственного интеллекта. Давайте посмотрим, сколько за это придется заплатить, чтобы у нас полная была формула финансовой модели, То есть там вырыжка, минус затраты.
01:49:31 — Соответственно, затраты в искусственном интеллекте складываются в принципе из двух компонентов. Это фиксированные затраты на разработку и запуск. И дальше переменные операционные затраты. Надо всегда понимать, что проект в искусственном интеллекте, в отличие от какого-то неживого продукта, он всегда требует сопровождения. То есть наивно рассчитывать, что вот мы сейчас искусственный интеллект сделали, И все, мы про него забыли, он 5−10 лет у нас будет работать.
01:50:00 — База данных, например, плюс-минус, они как бы не сильно изменились за последние 40 лет. То есть появились новые классы баз данных для различных задач. Но вот эта классическая реляционная база данных, в которой хранятся данные у клиентов в табличной форме, она плюс-минус как была база данных, такая она и была. Искусственный интеллект — очень много таких динамических элементов, дрифт по данным, изменение каких-то привычек, и под это под все нужно подправиться.
01:50:31 — То есть поэтому переменные операционные затраты — это ключевая часть общей финансовой модели. Если мы посмотрим на разливку внутри каждого типа, то на уровне фиксированных затрат — это зарплата команды на разработку. Что произошло в целом за последние три-четыре года после появления фаундэйшн-модул, то есть этих огромных умных моделей, которые типа умеют все делать.
01:51:00 — Они в каком-то плане создали новую платформу, в которой не надо создавать модели искусственного интеллекта на каждый кейс. Мы создаем одну суперумную модель, которая сразу же много чего умеет. И мы ее чуть-чуть потом подкручим под каждый конкретный кейс. Поэтому мы таким образом сделаем нашу экономику значительно более удобной для пользователей.
01:51:25 — Один раз OpenAI, Meta, DeepSeek, Anthropic или какое-то другое там видео обучает модель, выкладывает это либо в публичный доступ, либо выставляет API, и мы этот API можем использовать уже чисто для своего кейса, чуть-чуть подкручиваем, но мы не платим первичную цену создания вот этой вот умной модели. Раньше такое было невозможно. Раньше каждый тратил ресурсы на то, чтобы обучить свою модель.
01:51:51 — То есть там есть нюансы, но это одно из ключевых новых окон возможностей, которые технологически появились. И дальше, когда мы делаем операционные затраты, то у нас есть облачное вычисление на использование модели, то, что называется EI inference, когда у нас есть большая использование этого продукта на масштабе. То есть представьте, что у вас пользователи могут быть миллиард пользователей, то создав одну модель, обучив ее, докрутив до конкретного есть кейса, потом вы должны обслуживать миллиард пользователей.
01:52:25 — Конечно, тогда у нас число серверов, число реплик этой модели, которая будет крутиться в облаке, оно будет большое, и это будет большая часть бюджета. И эвристические поддержание продукта уже после введения в промышленную эксплуатацию надо закладывать 20−25% размера команды на разработку.
01:52:46 — Если у вас здесь использовалось 10 инженеров, то здесь 2−3 инженера фуллтайм будут работать на сопровождении этой модели. Тоже наивно думать, что мы можем просто разработать и потом сказать, все, теперь передвигайтесь все 10 человек на новый проект, а этот будет сам по себе жить. Мы 2−3 человека, мы их фиксируем, и они живут с этим проектом до тех пор, пока этот проект не перестанет создавать бизнес-ценности.
01:53:17 — И какие-то, значит, сложности. Я вот здесь сказал про foundation модели и обучение своей модели, которая сейчас меньше стала необходима. То есть для определенного числа AI-кейсов мы можем использовать уже готовые большие модели. Но если мы серьезно работаем над каким-то уникальным искусственным интеллектом, который имеет смысл только в вашей компании, то в любом случае нужны размеченные данные.
01:53:45 — То есть вот эти пары размеченных картинок, плохая картинка, красивая картинка, которую мы использовали в ретешировании, они нам нужны были для того, чтобы дообучить модель и сделать ее способной решать такую задачу. Другая вещь, про которую нужно думать, это юнит экономика, которая напрямую зависит от ценных вычислений.
01:54:05 — Да, и вот здесь-то я просто посчитал на салфетке, сколько будет приблизительно зарплата современного чипа NVIDIA BAT200, если этот чип будет работать 8-часовой рабочий день. То есть это получается приблизительно 80 тысяч рублей в месяц. Понятное дело то, что искусственный интеллект большее число операций может делать, но в целом это величина сопоставимая с человеческой оплатой труда.
01:54:28 — И дальше, что важно, это сколько вызовов к искусственному интеллекту мы должны сделать, чтобы конечную задачу решить. И по нашим современным каким-то оценкам, если это какой-то сложный API-чатбот, то это может быть от 20 до 50 запросов. Одно LLM, второе LLM какому-то API, потом это все объединить, сэмолизовать, и поэтому там экономика начинает быть сопоставимой в каких-то случаях с ценой труда,
Спикер ?:
01:55:03 — особенно в каких-то offshore странах, где стоимость труда в час ниже, чем в странах развитого мира. И вот какой качественного количественного характера инсайд,
Спикер 2:
01:55:19 — Что у вас может быть сегодня, экономика не сходится, если вы посчитаете, а через год, через два, когда новое поколение чипов выйдет или повысится эффективность софтвера, и мы про это поговорим после обеда,
Спикер ?:
01:55:35 — Она станет работать.
Спикер 2:
01:55:37 — То есть важно то, что, как говорится, один из ключевых вопросов инвесторов в долине — это why now? Почему ты над этим проектом хочешь работать именно сейчас? Потому что у тебя юнит экономика стала работать, и ты будешь одним из первых стартапов, который в нужный момент начал заниматься этой задачей на базе этой технологии. Если ты на один-два года опаздываешь — все, мимо кассы. На два года опоздал поиск, после уже появились конкуренты.
01:56:06 — На два года раньше экономика не сойдется, закроешься, потому что сожжешь все финансирование раньше времени. То есть это вот ключевая вещь в быстро меняющемся мире. Дальше, частный случай из длинного хвоста. Когда мы выводим AI в продакшн, то есть у нас легко решить задачу на 70%. Но когда мы начинаем дотачивать до каких-то очень своеобразных кейсов, Здесь просто пример, что распознай собаку, то есть там такие собаки есть, которые больше на кошку похожи, или собаки там в каком-то ракурсе непонятном.
01:56:40 — Если мы хотим сделать распознаватель собак, то есть это просто такой шуточный пример, то нам нужно очень четко работать с кейсами с длинным хвостом. И последняя история — это про гибридный интеллект и как это влияет на экономику. То есть у нас был процесс в итоге построен таким образом. На вход приходит картинка из фотостудии, мы удаляем задний фон, делаем обтравку, потом мы делаем обработку с помощью искусственного интеллекта.
01:57:11 — Вот эта вот картинка — это финальная версия искусственного интеллекта. То есть она выглядит супер классно. И потом, если сделать зум, то вот здесь вот в одном месте какая-то немножко она съела часть изделия. И профессиональный ретушер, который классно тренированный, он это может определить. Не профессионал скажет, да это и так классно, я и так куплю. Соответственно, профессионал скачивает это в Photoshop и чуть-чуть доделывает маску для того, чтобы откалибровать качество работы искусственного интеллекта.
01:57:41 — Но при этом профессиональный ретушер не начинает с нуля эту всю фотку делать, а он чуть-чуть подтачивает небольшой нюанс и деталь в финальной картинке. И в итоге у нас получается автоматизация вот на этом уровне, вплоть до красной черты. Мы для FMCG сегмента 80% делали автоматизацию под ключ. То есть просто все сделано классно.
01:58:05 — 20% кейсов дорабатывались профессиональными летушорами. Соответственно, 20% это там, где используется человек и искусственный интеллект вместе, но поскольку вы человека как бы в периметре задачи держите, то вам, соответственно, нужно платить и искусственному интеллекту, и человеку одновременно на финальное решение. И у вас, получается, стоимость состоит из стоимости искусственного интеллекта плюс вероятность быть успешно автоматизированной на стоимость человека.
01:58:37 — Да, и вот эта вот была не цена, она чуть-чуть будет выше, чем цена просто искусственного интеллекта, когда у вас 100% автоматизация. Вот, и это тоже нужно учитывать при подсчете вашего кейса. На этом давайте мы сделаем паузу. Я желаю вам приятного аппетита.
Спикер 7:
01:58:53 — Спасибо. Мы перерывимся на час до обеда, ровно до 16.00.
Спикер 9:
01:59:05 — Все, доехало.
Спикер 8:
01:59:14 — Можем начинать. Продолжайте.
Спикер 2:
01:59:19 — Да, все хорошо, тогда давайте дальше будем двигаться. Мы здесь остановились, чтобы у всех было continuity. Соответственно, следующий блок — это про управление затратами и рисками. И здесь дополнительные фреймворки, которые на качественном уровне позволят упорядочить проекты по сложности. Опять же, задача такая, чтобы вы стали максимально независимыми и не требовало вовлечения технических специалистов как можно дольше перед тем, как будет построена портфель проекта.
01:59:59 — Соответственно, расширенный Taxonomy Canvas по сложности реализации. Первый вопрос — это какого типа продукта мы хотим делать, то есть это интеграция через ABI, это облачный SAS, либо это собственный R&D, соответственно, по сложности с мультипликаторами они приблизительно таким образом располагаются на спектре.
02:00:26 — Дальше второй вопрос. Какой у нас формат конечного продукта? Здесь у нас либо это статичный отчет, либо это разработка модели на предсказание из консоли, либо из какого-то Jupyter ноутбука. Дальше у нас разработка модели на предсказание по API, то есть у нас есть действительный API, с которым можно программным образом взаимодействовать.
02:00:48 — Дальше это разработка модели для мобильного устройства. То есть там, возможно, потребуется какое-то дополнительное сжатие модели для того, чтобы оно могло исполняться с ограничениями мобильного устройства. И дополнительная переупаковка этой модели под мобильную среду. Дальше разработка модели на предсказание по API. По сути дела то же самое, что и здесь, но уже API, который масштабируется, который может обрабатывать большой трафик.
02:01:16 — И дальше разработка модели для конечного устройства, то есть это какая-то колонка, умная камера или что-то подобное. Да, то есть вот эти вот последние три блока — это в основном изменение типов пользовательского взаимодействия. Здесь больше такие внутренние технические вопросы либо прототипов. Дальше частота обработки. Как мы уже обсуждали, если это оплайново, один раз надо сгенерировать статичный анализ или отчет, то, соответственно, это максимально простой тип проекта.
02:01:46 — Если это пакетная обработка данных offline периодически, то нам нужно чуть-чуть более серьезно подойти к написанию кода для того, чтобы он был более легко поддерживаемым. Если у нас мгновенная обработка без прямой обратной связи, но все равно взаимодействие происходит в реальном времени, то в отличие от offline-обработки, у нас дополнительный API возникает в скорости от экосистемы.
02:02:10 — То есть не просто нам нужно обработать это, а нам нужно обрабатывать каждый отдельный запрос быстро. То есть это чуть-чуть посложнее с точки зрения реализации. И если у нас мгновенная обработка с прямой обратной связью, что это максимально сложно, то есть в реальном времени модель должна чуть-чуть перестраиваться в зависимости от предпочтений пользователей.
02:02:30 — Нам нужно держать какой-то кэш, обращаться в память к этой модели и так далее, то есть это максимально сложный вариант по чистоте обработки. Дальше, значит, вычислительные ресурсы можно сделать на ноутбуке. Нужен мощный компьютер, но по-прежнему это не облачные ресурсы. Нам нужны облачные ресурсы и нужны масштабные облачные ресурсы, то есть кластер с большим числом распределенных машин взаимодействия между ними.
02:02:58 — Соответственно, сложность выглядит приблизительно таким образом. И последний вопрос. С каким объемом данных мы имеем дело? Если это пайлик или архив, который легко передается пересылкой телеграм сообщения, почтой или что-то подобное, то это минимальная простота. Дальше, если нам действительно требуется какая-то база данных для хранения, чтобы эти все связи между различными таблицами ваших данных проследить и описать, то это уже чуть-чуть посложнее, но по-прежнему не так сложно.
02:03:29 — И самая сложная версия — это распределенная базовая система Волгаки, то есть это либо объектное хранение, либо это распределенная база данных, или что-то подобное. Соответственно, еще раз я вот так вот пройдусь,
Спикер ?:
02:03:42 — То есть получается сложности реализации, формат конечного продукта,
Спикер 2:
02:03:48 — Частота обработки, вычислительные ресурсы и объем данных. Все это вместе собирается в расширенный canvas, и, соответственно, здесь мы просто, опять же, на качественном уровне поставим галочку и говорим, что мой проект — это проект такого типа. Что мы из этого получаем? Чем фронт глубже, то есть чем у нас сложнее по каждому из измерений проект, либо это больше данных, либо необходимость к большому доступу к большому числу выселительных ресурсов,
02:04:20 — то, соответственно, сложность такого проекта будет выше, то есть он ближе будет похож на какой-то муншот-проект, нежели чем на какую-то инкрементальную интеграцию уже проверенного и работающего ИИ. И на примере, если мы говорим про тот проект, который мы делали, у нас был собственный R&D, мы свои делали кастомные модельки по обработке картинок, у нас была модель API,
02:04:46 — И у нас была мгновенная обработка без обратной связи, нужны облачные ресурсы, потому что картинок было много, но не настолько много, чтобы много серверов крутилось, и требования были такие, что все хранится в облаке для того, чтобы эти данные не потерять и реплицировать и все подобное. Соответственно, следующий шаг развития у нас в проекте был возможен какой?
02:05:13 — Можно было бы сделать добавку обработку с обратной связью. Представьте, что мы бы начали делать, что сейчас уже существует, что-то типа фотошопа онлайн, который построен на принципах AI. То есть сейчас и такие инструменты, как Figma и многие другие позволяют это делать, та же самая NanoBanana. У нас была статичная модель, и она умела определенный набор действий совершать, и все остальное дорабатывалось в фотошопе в нативной среде для профессиональных продюсеров.
02:05:42 — А если бы мы хотели как бы дальше продвинуться, то можно было бы расширить сложности этой системы, сделав модель, реагирующей на интеракцию с пользователем и, соответственно, дорабатывать это на каждый клик или действие. И сразу же дообучать ее на следующих данных, чтобы она работала чуть-чуть лучше. То есть это идеальная история, ну и, соответственно, конечный фронт не для всех проектов, это зависит от задач, но если это действительно какой-то production-grade сложный инновационный проект, то он, как правило, доходит до самого конечного уровня по всем направлениям.
02:06:19 — И мы можем использовать это для ранжирования проектов, опять же, не обращаясь к техническим специалистам. Эти оценки, они, понятное дело, не научно обоснованные, то есть это чисто юристические какие-то цифры, которыми я с вами делюсь на основе собственного опыта и в зависимости от того, где находятся на данный момент эти технологии.
02:06:40 — И какие-то из этих направлений более сложные, то есть там спектр более дискретный и широкий. В каких-то случаях, например, с данными проблема практически решена. То есть там есть возможность хранить файлы, хранить базы данных в распределенной файловой системе, но это не из 10 по сложности, то есть приблизительно все в рамках разумного располагается. В то время как если мы говорим про сложность реализации, то здесь расспрос большой, и собственно R&D нужно делать, если мы к этому готовы и понимаем, что там большой выхлоп будет, и мы сможем дотуда дойти.
02:07:19 — Пример собственного R&D, это какая-то self-driving машина, которую могут финансировать либо мега-стартапы, либо какие-то большие корпорации за счет реинвестирования своих существующих приборов. Вот. Дальше чуть-чуть коротко дополнительно про экономику. То есть вот эти вот мультипликаторы, которые есть, они могут быть сдуты еще больше при наличии развитой яй-платформы.
02:07:49 — То есть если у нас есть текущая стоимость даже в условных единицах проекта, то при наличии платформы, здесь я привожу тоже какие-то юристические коэффициенты, Если у нас это проект средней сложности, то мы можем 50−80 проектов эффективности дополнительно за счет платформы создать. То есть укоротить там скорость, укоротить сроки и стоимость создания такого решения.
02:08:18 — Если это проект сложного уровня, то 30−50 процентов эффективности. Если это какой-то кастомный R&D, то да, у нас это будет на 10−20% эффективнее за счет самых низкого уровня каких-то примитивов с точки зрения распределенного обучения или распределенной оценки моделей. Но в целом в R&D проектах очень сложно создать возобновляемые какие-то процессы, поскольку это по естеству деятельности.
02:08:49 — Как бы R&D, всегда мы что-то новое делаем. Да, но в целом ключевой тезис, который AI-платформа добавляет в компанию, в AI-трансформацию, это что без платформы мы тратим время на создание алгоритма, на инфраструктуру и потом уже под конкретный кейс задачу пишем кастомный код, который оптимизирует AI для решения этой конкретной задачи.
02:09:15 — В то время как при наличии платформы мы мы практически сводим до нуля получение доступа к каким-то повторяющимся компонентам и фокусируемся максимально на добавочную стоимость в новом бизнес-процессе. То есть это тезис платформизации. И как можно больше компонентов в течение времени мы должны перевести в платформенные компоненты, чтобы у нас была максимальная эффективность создания самого IE.
02:09:42 — Соответственно, что мы в итоге получаем? У нас есть проекты, проекты все прописаны с точки зрения процесса, мы знаем, где у них узкие части, мы знаем периметр интеграции этого проекта. Дальше мы начинаем оценивать качественные эффекты, у нас есть качественный эффект по скорости отклика и другим вещам, которые мы обсуждали. У нас есть качественное понимание, куда мы хотим развиваться как компания, ограниченным спросом, ограниченным предложением, или мы хотим создать добавочную стоимость за счет высвобожденного с помощью и времени.
02:10:21 — Дальше у нас есть количественная оценка качественного характера, то есть не до запятой рассчитана вся экономика, но, по крайней мере, в условных единицах мы понимаем, какой проект сложнее, какой проект легче, где зарыты ключевые точки стоимости, где зарыты ключевые точки роста, и мы понимаем, если мы дальше уже будем переходить по реализацию, где приблизительно на спектре по совокупной сложности у нас проект располагается.
02:10:52 — Это достаточно большой пакет решений, опять же, которые при правильном применении этих фреймворков вы способны сделать, не привлекая никаких внешних специалистов, чисто в рамках функциональной команды, то есть вы отвечаете за закупки, вы отвечаете за контент,
02:11:09 — вы отвечаете за маркетинг, за продажи, вы вот это в своей команде можете эффективно проитерировать и нащупать интересные точки входа, а уже дальше потом вдумчиво формулировать запрос на разработку к инженерам команды. Вот, плюс даже то, что у нас дополнительно был вопрос по поводу того, насколько глубоко управленцы должны в это все привлекаться. Опять же, поскольку произошла демократизация, и как технологии все вот эти chatbot, они по сути дела каждого человека, каждого пользователя превратили так или иначе в промпт-инженера.
02:11:47 — То есть все, когда говорят, нам надо нанять каких-то там магических промпт-инженеров, если вы пользуетесь чат-ботами, вы на естественном языке с ними разговариваете, то, по сути дела, вы уже владеете навыком промпт-инжиниринга, и это первый этап к созданию кастомных И.
02:12:08 — Что делает промпт-инжинер? Он просто вот этот вот набор текста команд на естественном языке чуть-чуть оборачивает в код, и после этого это становится первичной версией продукта. Поэтому сами команды, и есть тренд на это, то есть по оценкам Гартнера и IDC, как одних из репутационных аналитических агентств про технологии, они говорят, что в 2026 году
02:12:37 — переместиться центр компетенции IT, как официальный центр компетенции, который отвечает за разработку новых IT-решений, он станет децентрализованным, то есть каждый отдельный функциональный лидер и специалист будет способен современными инструментами для себя, по крайней мере, прототипы решений создавать сам.
02:13:02 — И это, опять же, качественного характера переход. Да, и там оценки даются, соответственно, что порядка 40−45% дополнительной высвободится продуктивности за счет того, что сотрудники сами себя будут снабжать этими инструментами, заточенными под очень точно свой бизнес-процесс. И конкретный пример здесь я приведу. У меня в команде один из product-менеджеров, он отвечает за дашборды по нашим операционным платформам.
02:13:35 — И мы другую команду инженерную просили помочь разработать нам дашборды по определенным спецификациям с определенными кипениями API, форматом визуализации этих всех графиков.
02:13:49 — И чуть-чуть это было не настолько быстро, насколько нам хотелось бы, и не настолько это был гибкий процесс вынесения новых требований, потому что компания Emedia очень живая, и когда даже микропотрясения на рынке происходят, мы сразу же максимально пытаемся под это подстроиться, включая изменение дашбордов, чтобы они подсвечивали нужные для нас показатели. И в итоге мы просто сели с этим продакт-менеджером и сказали, что почему бы тебе самому не разобраться с курсором и с лавабол и написать себе эти дашборды самостоятельно.
02:14:28 — И в итоге получилось то, что он стал одним из, в целом, внутренним экспертом по построению дэшбордов для различных операционных процессов без обращения к IT-командам. И пример того, как человек озадаченный и определенной задачей в своем процессе может быть максимально самодостаточным для реализации, по крайней мере, каких-то первичных продуктов.
02:15:00 — Что потом произошло, мы просто вот эти дашборды со всем кодом, который там курсоры лавл пункс генерировали, мы их передали нашей настоящей инженерной команде, которая это все поддерживает и уже развернула в качестве такого постоянно обновляемого дашборда вместо того, чтобы генерировать это каждый раз по запросу, когда нам нужно было сделать определенный отчет или посмотреть на определенные показатели. Вот. Такая микроистория.
02:15:30 — Дальше давайте быстро пройдем по AI project loop. Мы подробнее поговорим про это на базе конкретных технологий, которые применяются сейчас. А здесь чуть более управленческий взгляд на то, как выстроен процесс создания AI проекта с нуля. Это запутанная диаграмма. Давайте я ее по шагам вам разложу.
02:15:58 — Сначала мы делаем бизнес-анализ понимания проблемы, и опять же всегда надо начинать с понимания проблемы, а не с технологии. Дальше мы занимаемся сбором необходимых данных. Дальше у нас происходит какой-то на коленке анализ этих данных в джупайтер-ноутбуке, визуализация данных, очистка и понимание того, вообще с этими данными и с этим кейсом можно работать, существует ли у нас достаточный объем необходимых данных.
02:16:27 — Дальше, значит, мы пересходим в разработку первичной модели и прототипирование. Дальше, значит, мы оцениваем качество этой модели. И у нас возникает цикл итерационной доработки этой модели, чтобы удовлетворить определенные показатели по качеству. То есть в этом цикле мы начинаем крутиться.
02:16:47 — И дальше, если мы в какой-то момент понимаем, что у нас качество модели не улучшается, то есть такая задача сложная или у нас выборка не репрезентативная или еще какие-то другие проблемы, то мы, соответственно, можем пойти вплоть до уровня запуска нового проекта, потому что мы поняли, что здесь мы не продвигаемся к нужным показателям либо вообще, либо достаточно быстро. Дальше, значит, следующий периметр — это вот полный процесс модели создания.
02:17:16 — Мы тоже здесь продолжаем интеллироваться. Вот здесь стрелочка появилась. И финальный этап. Мы выводим в итоге нашу модель после оценки качества в промышленную эксплуатацию. Делаем там AB-тесты и смотрим, приживается ли она и есть ли у нас хорошая экономика на масштабе.
02:17:38 — Первичная гипотеза у нас была такая, что да, у нас потребуется определенное число серверов, Мы возьмем модель такой архитектуры, и у нас она будет стоить столько-то денег, чтобы эту проблему решить, и у нас среднее число вызовов такой модели на решение конечного цель этого кейса будет 10 на задачу или на какой-то инкрементальный бизнес-шаг, который мы пытаемся автоматизировать. А потом в процессе реализации может получиться так, что не 10 запросов надо сделать, а 50 запросов к разным моделям, чтобы в итоге это собралась цепочка, и автоматизация нужного уровня была достигнута.
02:18:16 — Либо мы сделали ABTest, а по результатам ABTest у нас какие-то не очень хорошие метрики с продуктовой точки зрения были. Тогда опять же мы можем из этой точки пойти на первое состояние, закрыть проект и сказать, да, к сожалению, мы это все разработали, но в итоге по результатам экспериментов мы поняли, что это не работает или не работает, как мы хотели.
02:18:40 — И зачем я это все рассказываю? Потому что, первое, чтобы вы приблизительно представляли, из каких узлов состоит разработка иай-решения настоящего, то есть не просто взять какую-то умную модельку и ее с помощью промпт инжиниринга научить делать какие-то базовые операции, а пройти полный цикл и уже как-то системно подойти к разработке конкретного иай-проекта.
02:19:06 — Тогда это будет выглядеть так с оценками на каждый этап. Вторая вещь какая, то что процесс, он именно итерационный, да, поэтому это project loop. И из каждого состояния в этом процессе, по сути дела, мы можем сделать шаг назад и вернуться к предыдущему состоянию, и это должно восприниматься как норма.
02:19:30 — И чуть-чуть более философски, то есть глобально в IT, в AI, но и в целом существует два типа проектов всегда. Есть проекты, которые направлены на delivery, то есть мы знаем, что и как делать до запятой, нам надо просто взять это и сделать. Никаких инноваций нет, если нам надо взять и разгрузить машину на складе. То есть мы просто знаем, что надо коробки из одного места в другое перенести.
02:19:57 — Это просто механическая простая операция. Вторая вещь — это Discovery. Проекты типа Discovery. Когда мы заранее не знаем всех ответов, и нам нужно как можно быстрее проитерироваться по этому циклу и нащупать все вот эти сложности, какие-то сложности решить, какие-то сложности деприоритизировать и продвинуться дальше. Как правило, когда мы делаем внедрение новых технологий, включая E, у нас вот эта модальность discovery проекта, нежели, чем просто delivery.
02:20:31 — И задача как можно быстрее превратить наш новый E-проект в проект delivery типа. То есть превратить это в операционку, максимально понятную, управляемую и скучную, и потом, соответственно, сфокусироваться на какие-то другие новые проекты внедрения.
02:20:53 — То есть таким образом каждый проектор рано или поздно из стадии discovery переходит в стадию delivery, если мы там все понимаем. И дальше здесь последнее состояние, если мы все-таки их в production вывели, на масштабе развернули, то, как мы уже с вами говорили, есть поддержание модели после вывода в промышленную эксплуатацию, постоянная доработка и улучшение, здесь цикл, получается, получение модели в зависимости от изменяющихся параметров среды.
02:21:21 — То есть изменился спрос, перекосило какую-то ассортиментную матрицу, появился ковид, появились какие-то другие ограничения, цепочки закупок надо перестраивать. Соответственно, это все AI сам из коробки сделать не сможет. Нам нужно пересобирать данные, докручивать показатели моделей и так далее. Это неизбежность динамически меняющихся проектов.
02:21:46 — И дальше перечень рисков, которые возникают, типовые риски на каждом из этапов, и примеры решения. Клиентам это неинтересно. Это самая базовая история. Опять же, молодые стартаперы, как правило, идут и делают какую-то очень инновационную, классную идею, но она никому не нужна. Вместо этого, перед тем, как писать код, нам нужно пообщаться с пользователями, с целевой аудиторией, сделать customer discovery и этот проект как можно быстрее инвалидировать, то есть фокусироваться на правильной проблеме.
02:22:19 — Внутри компании, когда мы занимаемся оптимизацией внутренних бизнес-процессов, как правило, такого вреда встречается меньше, но тем не менее какие-то исторические истории тоже люди предлагают. Дальше значит, что недостаточно или мало данных. Например, кейсы, в которых это бывает, это превентивная аналитика или детектирование дефектов.
02:22:43 — Если у нас классно настроен процесс производства, то дефект может быть один на миллион. Но и как мы будем ловить вот этот плохой элемент нашего конвейера продукции? Там, жестяная банка какая-нибудь Pepsi Cola, они просто со скоростью меньше, чем 10 банок в секунду пролетают по этому конвейеру, очень огромный объем, и нам нужно найти иголку в стоге сена, которую мы добавим в наши обучающие данные.
02:23:18 — «О, смотрите, а вот так вот она может быть дефектной, у нас погнулось там что-то, и каждый дефект такой своеобразный». Как раз-таки мы очень мало будем иметь данных такого типа, поскольку, к счастью, конвейерная линия на масштабе качественно производит продукцию.
02:23:38 — Или превентивная аналитика. То есть по-хорошему устройства не должны так часто работать, если мы их купили у хороших производителей. И, соответственно, когда это происходит, нам нужно идти в копилочку и это все сохранять для того, чтобы в будущем использовать для обучения новой модели превентивной аналитики оборудования. Вот, соответственно, как это решается? Есть синтетические данные, то есть у нас есть небольшое множество данных, на которых мы научились что-то делать, и мы говорим, а теперь ИАИ, другой ИАИ, посмотри на вот эти вот примеры и попробуй создать много похожих на которых мы потом можем дообучиться.
02:24:14 — Мы использовали в свое время это при разработке наших моделей по редактированию картинок. У меня, получается, компаундер был один из первых людей, который сделал фотореалистик Ray Tracing на графических процессорах NVIDIA.
02:24:32 — И в какой-то момент я ему говорю, ну ты умеешь картинки классные визуальные генерировать, фотореалистичные. На генерировании миллион картинок, где у меня продукт под одним углом, под вторым углом, тень, задний фон, фокусное расстояние, освещение, какие-то другие параметры. Поскольку у меня реальных клиентских данных не так много, у нас было 300 тысяч картинок собрано от всех наших партнеров, с помощью синтетических данных и фотореалистичного ray tracing мы могли генерировать просто бесконечное число разных комбинаций параметров.
02:25:05 — И на этих кейсах, даже если мы их не встретили в реальных данных, тоже обучаться. А потом, когда мы встречали их в реальных данных, я понимал, как реагировать. Или то же самое с дефектами. Мы можем взять какую-то консервную банку и на ней трещину сгенерировать. Одна трещина будет влево идти, вторая вправо идти, другая, третья будет вмятина глубокая, тарапина. И все вот эти штуки можно тоже с помощью ИИ генерировать.
02:25:33 — И будет эти штуки учиться эффективно обрабатывать. Дальше, значит, нет известных методов решения, и это тоже история, которая временная, в конкретный период времени. То есть, как мы уже обсуждали, если мы раньше рынка начали каким-то проектом заниматься, то мы просто упрёмся в стену. Если позже, то мы уже опоздали.
02:25:58 — И пример, который я привожу с премиум-клиентами, сотрудники отдела поддержки. В принципе, сейчас современная генеративная ИИ уже может эту задачу решать, но буквально пару лет назад это было практически невозможно. Дальше. Низкое качество прототипа с низкими шансами на улучшение. То есть мы насобирали данных, но они настолько шумные. То есть представьте, например, если мы насобирали данные по разговорам между сотрудниками в каком-то цеху.
02:26:32 — То есть там все жужжит, какие-то звуки раздаются, звук моторов, и параллельно с этим люди что-то обсуждают. И они сказали, а может быть вы можете сделать способ автоматической записи голоса и превращение это в meeting notes. То, что в классических звонках, как вот сейчас у нас конференция, оно работает идеально, потому что нет никакого внешнего шума, есть четкий голос, направленный в микрофон и так далее.
02:27:01 — А если у тебя много каких-то есть шумовых факторов, то точности решения не хватит, да, и мы попробуем какой-то и в этом направлении поделать, но чтобы 95% и выше error rate был на уровне слов, то есть это современный уровень speech-to-text-систем, мы до этого уровня просто дойти не сможем, потому что, естественным образом, есть шум в данных.
02:27:33 — Соответственно, здесь, возможно, будет необходимость пообщаться с какими-то доменными экспертами, профессионалами, которые занимаются обработкой сигналов, речи, и спросить у них, а вообще такие кейсы решаются, либо посмотреть на индустрии, либо на научные исследования, посмотреть, где сейчас находится фронтир технологий.
02:27:56 — Если мы опять же там скрестить два предыдущих комментария, например, посмотрим опять же на языковые модели, которые общаются с премиум клиентами про каким-то сложным финансовым кейсом оптимизации налогов в большом числе юрисдикции. Допустим, сейчас искусственный интеллект может хорошо решать задачу обычной клиентской поддержки, возврат товара в интернет-магазине, восстановление пароля или еще что-то. Но какие-то сложные кейсы, все равно профессионалы, аккаунтанты или такс-оптимизационные эксперты будут заниматься.
02:28:30 — Тем более, если мы фокусируемся на премию клиентов, они ожидают очень высокий уровень качества, и мы просто автоматизированным решением их не хотим обслуживать. И с течением времени, может быть, год мы подождем, то есть я никаких конкретных прогнозов не делаю, но технология дойдет до такого уровня, когда мы сможем построить агента, который специально заточен на работу с премиальными клиентами, и он сможет пересобирать вот эти все ответы даже в сложных случаях.
02:29:03 — То есть технологии постепенно до этого уровня дойдут, но на данном этапе это невозможно. Дальше. Низкое качество прототипа из-за предвзятости данных. То есть похожая история, мы про это поговорили. Плохие технические результаты после вывода решения на рынок. Тоже вот интересный есть use case, когда компания Zillow сказала, давайте мы будем делать прайс домов с помощью AI.
02:29:32 — И это публичный кейс стадии. Они потратили на это 500 миллионов долларов. В целом сделали какие-то сложные пайплайны подготовки данных, очистки данных, различные модели по ценообразованию. И альтернативой этому были просто какие-то локальные риелторы и специалисты недвижимости, которые могут выставлять цены на дома в зависимости от конкретного региона.
02:29:57 — То есть это просто распределялось по сети таких экспертов. И за счет того, что рынок последние несколько лет был достаточно волатилен, то необходимо было постоянно пересобирать цену на каждый новый дом и пересчитывать это буквально каждый день, условно говоря.
02:30:20 — В итоге получалось так, что суммарная стоимость перещённых всех этих моделей, дополнительная переобработка всех этих данных, Она в общей сложности оказалась не настолько точной и значительно более дорогой, чем профессиональные риэлторы, которые в каждом из своих регионов четко могли присвоить цену за очень короткий период времени. И они в итоге закрыли эту инициативу. Опять же, это не тезис о том, что этот кризис больше делать не надо. Это тезис о том, что на данном витке технологий при определенной стоимости вычислений у них экономика не сошлась на масштабе.
02:30:59 — Другой пример — это селф-драйвинг, когда в 2022−2020 годы приблизительно достаточное число селф-драйвинг-компаний закрылось и осталось только некоторое число еще более финансово устойчивых игроков, То есть такие как Bayma, Avirite и еще несколько игроков на этом рынке. И если, соответственно, первоначально, когда этот виток развития self-driving в 2014−2015 году появился, все надеялись, что через 5 лет по прогнозу развития технологий мы дойдем до уровня, когда self-driving действительно заработает.
02:31:44 — А оказалось, что мы чуть-чуть недооценили, то есть они недооценили приблизительно x2, то есть через 10 лет, в 2023−2025 году селл-драйв действительно начал работать. Сейчас в Сан-Франциско больше половины машин, например, они в фуле селл-драйвинга в AIMA ездят.
02:32:02 — Но те игроки, которые не смогли доинвестировать до этого этапа, и у них просто закончились средства, то они вынуждены были закрыть. То есть это более сложные проекты. И финальная вещь — это AB-тесты. То есть это больше продуктовая история. То есть мы можем сделать много интересных API-решений перед тем, как выложить это в продакшн. Например, персонализированные ленты в твиттерах.
02:32:30 — То есть нужно было сделать какие-то рекомендательные алгоритмы, API, которые работают на масштабе, вместо текущей хронологической сортировки, которые, в принципе, всем пользователям понятно и удобно. И когда они делали API-тесты перед раскаткой этого продукта на всю свою аудиторию, то есть очень большие негативные отзывы получили, потому что пользователи привыкли использовать Twitter как экономически упорядоченную ленту новостей.
02:32:58 — Да, и, соответственно, в каждом из этих кейсов, чем быстрее мы понимаем, что это не работает, тем лучше, потому что это сэкономит бюджет, сэкономит лишние старания и позволит релаксировать ресурсы на какую-то другую инициативу в портфеле. И дальше, да, то есть вопрос, про который тоже мы коротко поговорили, как происходит финансирование этих проектов, оно происходит поэтапно.
02:33:27 — И на каждом этапе мы смотрим какие-то ключевые показатели, удовлетворяет ли наш проект целевым показателем на данном этапе или нет. Если нет, мы его закрываем, это нормально. Если удовлетворяет, мы продолжаем дальше. И четыре ключевые фазы — discovery and scoping, proof of value, когда какую-то первичную ценность мы создаем, дальше MVP — это первичная полностью работающая версия продукта, и дальше раскатка этого продукта на масштабе.
02:34:02 — Здесь интересная вещь — это больше про качество. Когда мы представим, что у нас есть какое-то таргетное значение качества, которое мы должны достичь для того, чтобы наш проект заработал. Дальше, соответственно, на самой ранней стадии у нас 60−70% может подходить к заданному уровню качества, и я показываю.
02:34:26 — Потом мы постепенно инвестируем, тратим больше времени и усилий. У нас качество увеличивается, и, значит, в какой-то момент мы доходим до точки 80−90 процентов, там, грубо говоря, практически мы дошли. Когда мы достигаем, соответственно, оценки 100 процентов от текущего уровня качества, то мы можем раскатывать этот продакшен.
02:34:50 — И дальше, когда мы раскатываем этот продакшен на всем масштабе нашей компании и на все события, которые в конкретном бизнес-процессе происходят, там есть интересный эффект, когда мы начинаем сталкиваться с edge-кейсами, которые отсутствовали в первоначальном обучающем дата-сете, на котором этот AI разрабатывался. То есть мы сколько смогли, максимально репрезентативную выборку кейсов собрали, на них обучили AI и говорим, у нас работает, по всем тестам проходит на нашем ограниченном размере данных.
02:35:26 — А потом мы в открытый мир запустили этот искусственный интеллект, и этот искусственный интеллект начал встречать какие-то кейсы очень редкие, которые раньше не попадались на данных, на которых мы обучались. И здесь качество может просесть, ну и, соответственно, начинает возникать процесс итерационного обучения.
02:35:50 — И до введения искусственного интеллекта, до того уровня, когда он действительно на масштабе работает, и порог, частотность новых кейсов, на которых он выдает некорректный результат, он держится в разумных пределах. То есть это приблизительно такая жизнь проекта и определенные сроки. Последний слайд на эту тему, да, и дальше мы перейдем уже к техническим вопросам, трендам, и, значит, поговорим про то, как на данный момент разрабатывается проект.
02:36:28 — По поводу портфеля, да, то есть мы уже про это говорили, идея абсолютно простая, мы создаем первичный пул проектов с разным уровнем сложности, Постепенно по вот этому род мэпу их проводим и оцениваем вероятность успеха на каждом этапе.
02:36:47 — Какие-то проекты заворачиваем, какие-то проекты продолжают дальше развиваться, и в конечном счете подмножество этих проектов доходит до успеха, и эти проекты становятся первичной группой проектов, которые становятся таким знамением трансформации, И мы на основе этого начинаем строить дальнейшее развитие и трансформации этой компании.
Спикер 7:
02:37:11 — Можно я тебе немножко прокану не в вопросах, а в комментариях. В целом можно себе такую штучку заполнить, ну, я имею в виду для себя, потому что у вас может быть начальный уровень, и там только те, которые там на самом верхнем, ну, то есть у маленьких проектов из 20, правильно? Мы на них тренируемся, учимся, набиваем року, что называется.
02:37:32 — Потом мы можем перейти на второй уровень и делать какие-то более комплексные проекты, но там без 100%, поэтому уже, когда мы уверены, когда у нас есть команды, когда у нас есть доказанные экономические эффекты, мы можем перейти на уровень, типа давайте замахнемся на все, раскатим на 100%, и это можно, мне кажется, двигаться в рамках одной функции или одного предназначения, и можно двигаться в основе всей компании. Но логика будет вся та же самая, сверху вниз. Мы об этом примерно и говорим. Тезис, что заходить сразу в сотку, мне кажется, что это большие риски ошибиться, потратить много денег, не получить эффектов и получить большие затраты на внедрение.
02:38:20 — Слайд очень простенький, очень удобный, его можно использовать как кому-то себе. У меня есть верхний уровень, на нем что-то уже зафиксировано. Если еще нет, то давай продолжим туда. Может быть так, что у нас есть, в смысле верхний уровень не пропадает, у нас там все время идет какой-то апдейт, проекты вращаются, а на среднем уровне он просто комплексируется. Объединяем какие-нибудь три верхних, делим, делим единого, не знаю, агента, какой-то помощь маркетингу, например.
02:38:46 — А до этого это был агент анализа коммерческих предложений, агент генерации текстов каких-то. Потом мы его объединили. Это общая каскадная логика сверху вниз, кажется, наиболее удобная, Анатолий, ты хотел… Нет, надо включить. Ладно, хорошо. Никит, согласен с тем, что я…
Спикер 2:
02:39:11 — Да, согласен полностью. То есть это можно смотреть как по жизни одного конкретного проекта, так и по… По портфелю в целом.
Спикер 7:
02:39:23 — Это можно смотреть по жизни отдельного конкретного проекта, но давайте сейчас, чтобы совсем стало ясно, прости, пожалуйста, что я здесь запаркован, но это прям близко совсем к нам. Вот у вас есть карта размеченная. Карта размеченная. Это какой уровень? Он может быть и первый, и второй, и может быть даже третий. То есть можно сказать, размеченная карта, почему я всех толкаю, ребята, прототип, прототип, сделайте прототип.
02:39:50 — Прототип это маленький кусочек, вон там 20 процентов. А их там у вас 5. Как только мы поняли по всем прототипам, что все работает, что все соединяется, мы можем взять весь процесс так, раз его, и типа две-три плотные группы. Ну у нас там типа они объединяются, агент там например управляющий, агент, который по процессу идет. Вот эту штуку сделали. Получилось ли это? Еще вниз и давайте перевернем. То, что ты, Никита, говоришь, давай платформу развернем, давай автотест, давай поддержим то, что будет обновляться, потому что мы знаем, что выезжать.
02:40:27 — То есть давай будем за системную поддержку всего этого осуществлять, и там уже другие затраты, но мы уже хотя бы на верхних этажах поняли, что все работает, все объединяется, и мы можем туда выходить. Вот в текущей ситуации эта перевернутая пирамида, мне кажется, недооценивается, но она суперважная, потому что пирамиду, если ее обратно поставить, будет вот… Ну, я просто видел это конкретно. Сначала защитили стратегию. Пошли делать комплексные продукты. Вот там поняли, что ничего не получается.
02:41:00 — Деньги-то уже потрачены были, поэтому как бы стараемся выдать желаемое за действительное, говорим, что все так, как должно, и потом подгоняем цифры под комплексную стратегию, которую защитили в конце. Значит, и в итоге никто не счастлив. Поэтому мне вот переворачивать пирамида, как ты нарисовал, кажется очень ценной логикой реализации наших проектов, и у вас в заготовке ее все есть уже очень какая-то.
Спикер ?:
02:41:27 — Все, Никита, спасибо.
Спикер 2:
02:41:28 — Я помню, я в одном бизнес-школе читал лекцию. Ты не только у нас читаешь лекции. Будучи компьютер-сайдчеством, я говорил, давайте нарисуем дерево. Для меня дерево, как программист, есть корень, у него ветки, потом листочки, и в итоге дерево растет сверху вниз. Потом мне задают вопрос, почему у вас дерево растет как бы сверху вниз, я говорю, ну не знаю, всю жизнь так рисовал, меня так научили, они говорят, нет, но деревья же растут снизу вверх, я говорю, ну хорошо, давайте перерисуем, просто чтобы у них когнитивная картина мира была расслаблена в правильном направлении.
02:42:10 — Но я согласен с тем, что Николай сказал, что действительно стратегия first, и потом уже оправдание этой стратегии всеми возможными способами, это неправильный подход, который, как правило, приводит к большому числу разочарований, задержки с точки зрения правильных инноваций и неправильному распоряжению бюджетом.
02:42:39 — И более при такой скорости изменения, да, при такой скорости изменения, конечно, да. Невозможно предсказать, что будет в следующие полгода, да, на самом деле, это я помню, когда мы в своей истории стратегические какие-то мы на видео обсуждаем, горизонт планирования, окей, 6 месяцев максимум, да, то есть, да, у нас есть стратегическая какая-то история, которая основана на вижене и на ценностях, в которые мы верим,
02:43:07 — что Accelerated Computing как подход к вычислениям, это правильный подход, и больше задач будут, конечно, с помощью Accelerated Computing оптимизированы. Но по-честному написать OCR, KPIs, какие-то истории запланировать, это 6 месяцев вперед максимум, потому что произойдет очередной какой-то шок на рынке, либо это будет какая-то новая технология, какой-то будет новый подход к обучению моделей, инференс и так далее, и нужно будет пересобирать всю цепочку.
02:43:43 — Поэтому адаптивность, на мой взгляд, это один из самых ключевых навыков. Соответственно, стратегия тоже должна быть адаптивной, то, что называется управляемый хаос.
02:43:54 — Давайте, значит, еще один короткий момент, который важно сказать перед тем, как мы про технологии будем говорить, Это про бизнес-модели и flywheel-эффекты, которые просто повсеместно появляются в AI-проектах, и это одна из таких ключевых подходов к построению.
Спикер ?:
02:44:16 — То, что называется mode.
Спикер 2:
02:44:20 — То есть диверсификации и создания какого-то долгосрочного конкурентного преимущества. Есть конструктор бизнес-моделей, быстренько пробежимся. Есть облачные приложения, мобильные приложения и умные устройства. Там везде я может добавлен быть, и это новые бизнес-оппортунити.
02:44:46 — Облачные сервисы и дальше много различных компонентов по созданию современного ИИ, то есть все бизнес-модели, которые сейчас в экосистеме ИИ существуют, их так или иначе по этим 8 блокам можно Я быстренько пролистаю, это не так критически важно. Пример.
02:45:06 — То есть того, как компания внутри себя нашла конкретный бизнес-процесс, мониторинга транзакций и поиска фро, а после этого, решив проблему для себя, вывела проект на рынок и заработала на этом еще больше, чем только решая проблему для себя. Есть как бы бизнес-процесс мониторинга транзакций. С чем это связано? С тем, что кредитные карточки попадают в тортнет, злоумышленники используют эти карточки, чтобы покупать какие-то дорогие товары, потом их перепродавать.
02:45:43 — И, соответственно, как это выглядит? Если мы отклоняем транзакцию, то как ритейлер или онлайн-магазин мы теряем выручку. То есть нам в принципе все честные транзакции по-хорошему нужно обрабатывать, и мы здесь попытаемся принять решение, пропустить транзакцию или не пропустить.
02:46:05 — И если мы пропускаем транзакцию, которая была мошенническая, и все-таки продаем товар злоумышленнику, то дальше мы, получается, попадаем на определенные штрафы от регулятора, который работает в области кредитных карт и онлайн транзакций. Мы должны, соответственно, за это штраф заплатить. И еще клиент, владелец настоящей кредитной карточки, может оскорбить транзакцию и попросить вернуть средства, тогда, соответственно, продавец должен покрыть цену товара.
02:46:41 — Поскольку злоумышленники получили этот товар, то уже вернуть этот товар нельзя, и получается дырка в бюджете ритейлера. Так вот выглядит экономика всей этой истории. И данные выглядят следующим образом. То есть у нас есть транзакция, у нас есть страна, у нас есть время транзакции и флаг.
02:47:04 — Фрод или не фрод. На самом деле это упрощенная картинка, там 500 разных признаков используется, и все замешивается в модели машинного обучения. Stripe решил для себя такую проблему, поскольку это платежная сеть, им важно мониторить качество транзакций внутри своей сети.
02:47:22 — А потом, в какой-то момент они сказали, а как насчет того, чтобы мы свое решение, которое мы для себя разработали, внедрили, и у нас хорошо работает Machine Learning Based Fraud Detection, сможем лицензировать большому числу игроков на рынке банком, каким-то большим другим ритейлером или людям, которые обслуживают онлайн-операции. И в итоге, что у них получилось? У них, значит, за счет того, что большое число существует клиентов, помимо тех, которые уже в нетворке Stripe, то они генерируют дополнительные данные.
02:48:00 — Соответственно, эти данные мы все собираем, мы их обрабатываем, и у нас большее число разных кейсов по фроду и не по фроду. То есть вместо того, чтобы только Страйк для искусственного интеллекта данные собирал, на котором можно его научить, мы собираем это со всего нетворка расширенного, включая клиентов этого Страйк-радар-продукта. После этого Страйк на всех этих данных обучается и создает более качественную модель детектирования мошенничества.
02:48:29 — Соответственно, эта лучшая модель, собранная, обученная на всех данных, со всей экосистемы, выкатывается в продакшен. Качество детектирования мошенничества выше, упущенные выручки у ритейлеров ниже, штрафов регуляторам меньше. В итоге ритейлеры счастье, более счастливые, покупатели тоже более счастливые, в нетворк добавляются новые клиенты, И мы постепенно улучшаем AI по этой спиралеподобной истории, то, что называется Flywheel или Network Impact.
02:49:05 — И задача какая? Здесь две ключевые мысли. Первое. Разрабатывайте проект сначала на основе своего бизнес-процесса и не пытайтесь создать AI без какого-то фаундейшн.
02:49:20 — Либо это история про данные, когда у вас есть уникальные внутри данные, на которых вы можете создать новую ценность с помощью ИИ, а потом предложить эту рынку. Либо, если у вас существует колоссальный distribution потенциал. То есть пусть у вас нет никаких данных, но если ваши каналы, существующие в дистрибьюции, встроят ИИ, то сразу же будет мультипликативный эффект и хорошая выручка.
02:49:46 — В этих двух случаях имеет смысл что-то подобное делать и пытаться запустить и собрать новую бизнес-модель. А дальше второй этап — это как эту бизнес-модель защитить с течением времени. И если у вас есть, а как правило в AI-проектах, которые вертикализируются на конкретных дискейсах, такое есть, flywheel-эффект. Потому что с течением времени, чем больше клиентов вы проинфиксировали, тем больше данных вы собрали, тем лучше ваши алгоритмы, тем больше ценностей, тем больше клиентов и так далее.
02:50:18 — Таким образом запускаются и выстраиваются нишевые, то, что называется Vertical AI SaaS Companies или Vertical AI Companies. Примеры я приводил, которые просто растут по экспоненте, потому что они максимально defensible и построены на этих принципах. Соответственно, смотрите на такие возможности в вашей компании.
02:50:40 — Если у вас нету уникальных данных либо distribution potential, как правило, эта история с точки зрения запуска нового бизнеса очень рисковая, и лучше фокусироваться на решении внутренних задач посредством просто внедрения технологии, автоматизации своих процессов не на внешний рынок.
02:51:00 — То есть если опять же вернуться к этой пирамиде перевернутой, то запуск нового бизнеса и вывод его за периметр своей организации нужно делать, когда есть действительно и уникальная ценность,
Спикер ?:
02:51:14 — И возможность удержать эту ценность через сетевые эффекты.
Спикер 2:
02:51:18 — Или другие методы защиты бизнеса с течением времени. Так, давайте здесь коротко опросик сделаем, и перейдем дальше.
Спикер 9:
02:51:39 — Можно вопрос? Можно только микрофон,
Спикер 5:
02:51:52 — Как можно защитить, допустим, собрал ты свою модель, собрал схему, структуру, хороший дистрибьюторский потенциал, как можно защитить на уровне интеллектуальной собственности?
Спикер 2:
02:52:08 — Ну, всегда есть патенты. Я не очень верю в патенты, потому что это такой механизм старого мира, мне кажется, когда было достаточно механистическое производство, когда один товар мог на рынке существовать 40 лет без особых изменений, то, что называется mass manufacturing, как бы виток развития общества. А сейчас скорость итераций, способность подстраиваться под какие-то новые тренды, плюс возможность наращивать ценность вашего решения — это самый ключевой механизм построения защиты вашего бизнеса.
02:52:52 — То есть я больше исповедую такую честную игру, в которой вы лучше других делаете свое дело на базе открытых технологий, это делать только проще.
Спикер ?:
02:53:05 — И сейчас Open Source играет очень большую роль, поскольку в противном случае невозможно было бы создать стопроценности стартапам нового поколения,
Спикер 2:
02:53:16 — Поскольку у них просто нет сток-бюджетов. А здесь, как мы уже обсуждали, несколько больших игроков инвестируют, выкладывают в открытый доступ современные умные модели, и вся индустрия поверх этих моделей строит какие-то нишевые решения, понимая специфику бизнес-процесса конкретной ниши.
Спикер 7:
02:53:44 — Спасибо. Так, у тебя на экране кто смог добежать? Добежал, подчекин. Что у нас? Эгентик дата инженер. Какие данные на базе внутренней вашей компании могут быть полезны рынку? Тут надо было про данные решить. Соответственно, поговорить?
Спикер 2:
02:54:11 — Нормально.
Спикер 7:
02:54:13 — Давайте двигаться дальше, а то у нас совсем забыли.
Спикер 2:
02:54:16 — Давайте двигаться дальше. Теперь давайте вторую часть откроем. Про технические моменты. Очень коротко, по поводу того, как за последние 10−15 лет искусственный интеллект изменился. В 2012 году первый раз моделька на основе нейронных сетей стала работать лучше, чем какой-то классический машин-лернинг.
02:54:51 — Дальше Perception AI. Здесь у нас появилась возможность… первый раз человек и искусственный интеллект сравнялись. Искусственный интеллект стал работать лучше для распознавания картинок сначала, потом для распознавания речи, а потом для медицинской диагностики каких-то вещей, связанных с радиологией сети сканами. И здесь по-прежнему на этом этапе требовались профессиональные машинные микроразработчики для того, чтобы разрабатывать AI-системы.
02:55:23 — Когда появились фаундейшн-модели, я уже объяснял ключевое различие, что, по сути дела, мы скачиваем весь интернет, засовываем этот интернет в процесс обучения большой foundation модели, которая просто учится предсказывать следующее слово.
02:55:41 — Потом чуть-чуть ее алайним на то, как люди рассуждают и предпочитают определенный тип текстов другим текстам, то есть чтобы они были стилистически правильно сгенерированы, чтобы искусственный интеллект правильно следовала инструкциям, и у нас получается генеративный AI. И ключевая история генеративного IAI про то, что мы демократизировали интерфейс взаимодействия, а также создание новых IAI-систем. От профессиональных разработчиков до, по сути дела, любого пользователя.
02:56:14 — Сейчас можно на естественном языке с этими моделями разговаривать, они будут понимать и дальше использовать для автоматизации процессов. Следующий переход между генеративным ИАИ и агентским ИАИ. Какая ключевая разница возникает? В генеративном ИАИ мы используем, как бы, человек находится в периметре принятия решения. Человек, ну, то, что называется, является оператором этого процесса, и control loop, то есть управление процессом принадлежит человеку.
02:56:49 — Искусственный интеллект, в первую очередь, модели ассистента используется, копайлота, для того, чтобы помочь повысить эффективность человека, как оператора этого процесса. В агентском AI мы полностью или частично на время передаем контрол-лук агенту, и агентский AI уже сам решает, какое следующее действие в бизнес-процессе сделать.
02:57:14 — Логика не жестко прописана, а искусственный интеллект анализирует собранную информацию, и говорит, следующее свое действие я сделаю такое. Это ключевое отличие между генеративным IA и агентским IA. Агентский IA использует все предыдущие доступные ранней технологии машинного обучения, но поверх этого есть вот эта мета-составляющая, какой следующий шаг принять в решении задачи, как ее правильно декомпозировать, и, соответственно, контрол-лук, который принадлежит им.
02:57:48 — Следующий виток — это робототехника, я совсем в конце про это коротко упомяну, но идея такая, что мы будем стирать границу между полностью цифровым миром и когнитивными функциями, и битами, и атомами, как бы, соответственно, товарами и объектами реального мира.
02:58:12 — Дальше, значит, по поводу того, как мы разрабатываем новый проект с нуля. Да, то есть задача с вами сейчас буквально там за час сорок пять минут прожить полный цикл создания искусственного интеллекта от самого базового прототипа до максимально развитой инфраструктуры,
02:58:38 — которые используют все возможности современной технологии, чтобы вам показать, где находится край современной индустрии и какие технологии доступны для того, чтобы, соответственно, создавать максимальную ценность и делать это максимально дешево. Три ключевые метрики, которые нужно определить, и это, опять же, возвращаясь к началу нашей лекции, что мы не делаем технологии ради технологий.
02:59:06 — Мы делаем технологии ради решения бизнес-задач. И мы определяем сначала метрики, по которым мы будем оценивать качество нашего искусственного интеллекта. Соответственно, как правило, это три ключевые метрики. Точность решения задачи или качества, скорость отклика и throughput. То есть throughput — это число операций в единицу времени. Почему именно в таком порядке?
02:59:31 — То есть это ранжированный список, их переставлять местами лучше не стоит. В первую очередь нам нужно качество и точность. Почему? Потому что если у нас искусственный интеллект не решает задачу, то насколько быстро идешь, и он работает, никому не интересно. То есть в первую очередь нам нужно завалидировать ценности этого искусственного интеллекта. Вторая вещь — это скорость отвертка. Если искусственный интеллект работает бесконечно долго, то понятное дело, что мы не будем ждать этот ответ, даже если он очень хороший.
03:00:04 — Нам нужно какую-то адекватную скорость отлика закладывать в наше решение. Существует процесс, в котором мы можем подождать сутки, неделю, даже месяц, если это какой-то обсчет погоды в суперкомпьютере. Но в целом нам нужна скорость отлика, чтобы была низкая.
03:00:25 — Скорость отлика высокая, задержка низкая. И третья вещь, число операций в единицу времени, она напрямую зависит, связана со стоимостью. То есть мы хотим, чтобы наш умный и быстрый ИИ работал дешево. Да, и это, соответственно, throughput, число, общее число операций, которые сможет ваш искусственный интеллект сделать за единицу времени, оно пропорционально бюджету на инфраструктуру, и мы хотим ее оптимизировать.
03:00:54 — Дальше, соответственно, с чего мы начинаем? Мы начинаем просто с фаундэйшн-модели в облаке. То есть мы можем использовать Яндекс-языковую модель в России, мы можем использовать, значит, Гигачат как API. И, значит, они доступны по API. Нам не нужно поддерживать какую-то собственную инфраструктуру, нам не нужно нанимать инженеров, которые занимаются поддерживать это все в работающем состоянии.
03:01:25 — То есть мы просто отправляем запросы, прочитали методическую API-спецификацию конкретного API и с ним взаимодействуем. Это достаточно для того, чтобы на базе Prompt Engineering собрать какое-то решение. Очень простая картинка. Дальше, значит, что происходит? Какую модель мы выбираем? Здесь очень интересный вопрос.
03:01:47 — Я сделал скриншот. Существует более 2 миллиона моделей, открытых, которые можно использовать для создания современных решений.
Спикер 1:
03:01:57 — Соответственно, в этом.
Спикер 2:
03:01:57 — Очень просто заблудиться, и это сложная задача. То есть, какие-то модельки, они публичные, какие-то модельки проприетарные, но в целом это 2 миллиона с лишним моделей, которые мы должны отсмотреть и выбрать лучше. Для того, чтобы отсеять, существует много различных лидер-бордов, то есть это одна из задач, которую мы решаем внутри, с фабрикой по оценке моделей.
03:02:27 — Соответственно, мы смотрим на общие знания, мы смотрим на способности размышлять логически, способность смотреть, исследовать инструкцию из промта, способность взаимодействовать с внешними инструментами, значит, писать корректный код, безопасность этих моделей, длина контекста одного, который они могут обрабатывать, и многие другие. И в итоге есть несколько работников, которые являются общепринятыми и популярными, которым доверяется общество, плюс у нас есть внутринезависимая оценка моделей по набору критерий.
03:03:05 — Как мы уже обсуждали, это качество, скорость и цена или труп. То же самое используется здесь, на лидерборде. Один из популярных лидербордов — это Artificial Analysis. Вы можете зайти по ссылочке посмотреть.
03:03:22 — И они с появлением новых моделей быстро их прогоняют по набору своих бенчмарков и ставят ее в ряд, чтобы можно было всем легко выбирать самые лучшие модели в ходу различной задачи. Другой лидер бот — это LM Arena или Chatbot Arena. То же самое происходит здесь. И отличие Artificial Analysis от LM Arena в том, что LM Arena построена на модели краудсорсинга.
03:03:52 — Когда у нас показываются две версии ответа, одна модель генерирует один ответ, вторая — второй. И люди, анонимизированные пользователи, заходят на определенный сайт и голосуют. Я люблю, значит, ответ номер два, вторые говорят, я люблю ответ номер один. Они потом это все усредняют и делают такой ранжированный лидерборд моделей в зависимости от того, как люди оценили качество этих моделей.
03:04:23 — Соответственно, у нас получается аналог шахматного турнира между моделями. И если посмотреть на определение самого бенчмарка, то есть если архитектурный анализ, посмотреть на перечень определенных задач, которые решают, то есть это приблизительно так же, как ЕГЭ или какие-то выпускные вступительные экзамены,
03:04:46 — которые студенты сдают, мы искусственный интеллект говорим, хорошо, давай мы тебе дадим тысячу задач по математике, тысячу задач по географии, тысячу задач по другим каким-то вопросам и все вот эти направления проверим. Соответственно, когда у нас формируется вот этот набор бенчмарков, то есть мы их просто взвешиваем с какими-то весами в зависимости от важности, здесь показано то, что каждый бенчмарк взвешен с вероятностью одна десятая, и всего 10 ключевых петч-марков используется.
03:05:19 — Соответственно, потом мы это все усредняем, и у нас получается такой индекс умности нашей модели. И по этим индексам все модели ранжируются. Так, соответственно, выбираются современные модели.
03:05:32 — И к чему я это говорю? То есть самый высокоуровневый подход к выбору нужной модели — это обратиться к этим лидербандам, выбрать все то, что сверху этой модели на данный момент лидерборда находится, и использовать у себя в своих AI задачах. Но эти лидерборды, они усредняют по очень большому числу различных бенчмарков, и в среднем говорят, как модель одна лучше, чем другой. Если же у вас определенный сегмент, например, вы говорите, что я работаю в сфере healthcare, И мне нужно найти бенчмарк, который оценивает знания модели в доменной области healthcare.
03:06:15 — То, соответственно, существуют под различные индустрии, типы задач и так далее свои нишевые бенчмарки. И это вот следующий виток, который уже каждая из отдельных команд делает для себя, чтобы выбрать нужную модель. Третий этап — это создание своих бенчмарков непосредственно в вашей компании.
03:06:39 — Потому что у вас бизнес-процесс будет отличаться от компаний-конкурентов в вашей индустрии, и вам нужно понять, как у вас конкретно AI работает. В конечном счете вы от этого не уйдете и должны будете создать собственный бенчмарк, по которому вы будете постоянно оперироваться, постепенно улучшая свою систему. То есть это как происходит современная разработка. Дальше, опять же, возвращаясь к нашей простой архитектуре, мы из этого всего списка моделей по различным бетчмаркам и лидербордам выбрали хорошую модель.
03:07:14 — Она у нас в качестве облачного API используется. И мы хотим теперь эту модель запустить в периметре организации. Почему это важно? Потому что мы, значит, не хотим быть зависимыми от внешнего облачного провайдера, мы не хотим туда отправлять какие-то конституциальные или стратегические данные о нашей компании,
03:07:36 — либо это регулированная индустрия, либо это политически какая-то, значит, неразрешенная история по политике компании, либо на основании соображений геополитики и суверенности. Соответственно, мы просто не хотим во внешний периметр отдавать данные наших пользователей и нашей компании. Поэтому мы должны взять этот искусственный интеллект, модель, и развернуть ее в периметре нашей организации. Соответственно, эта задача сразу же возникает. Очень большое число различных вопросов архитектурного, инженерного характера.
03:08:11 — Соответственно, чтобы во всей этой истории не запутаться, я поделюсь какими-то ключевыми принципами, которые позволяют навигировать в пространстве этого поиска. Первая история — то, что с каждым новым поколением у вас падает стоимость вычислений, и эффективность следующего поколения растет.
03:08:37 — Это, понятное дело, история ожидаемая, но что интересно, то что скорость удешевления, она просто экспоненциальная. То есть она как бы не какие-то инкрементальные 20−30 процентов, которые прогнозируются законом Мура, а она в десятки раз за одно поколение. И здесь я вот просто привожу, если мы возьмем в качестве базы А100, это два поколения назад NVIDIA чип плагматский был, и мы сравним с H100, это предыдущее поколение, то уже 2.6х скорости.
03:09:13 — Потом мы используем определенную технологию под названием Tensor RTLLM, которая поверх чипа H100 чуть-чуть более умным образом взаимодействует на уровне софтвер с аппаратными возможностями чипа H100. И мы берем и ускоряем процесс до 4,6х, просто включив вот эту библиотеку аппаратного ускорения.
03:09:37 — Потом мы используем вот эту вот вещь как базу в следующее поколение. Если мы говорим, что вот это вот H100, тензор RTLLM, это будет наш бейслайн. И мы сравним новый чип B200 тоже с включенной библиотекой аппаратного ускорения. И мы, получается, сравниваем, получается, что 4х умножаем на 4,6х в общей сложности, это 18х за два поколения. На модели лама-2, 70 миллиардов параметров.
03:10:07 — То есть мы, получается, с A100 до B100 с аппаратным ускорением 18х скорости создали, или, в других терминах, 18х экономии бюджета за счет перехода. И одна из фраз, которую наш CEO Дженксон любит говорить, это «the more you buy, the more you save». Почему? Потому что эффективность следующего поколения просто на стоимость денег становится выше.
Спикер ?:
03:10:35 — То есть выгоднее переходить на следующее поколение, поскольку в этом бизнес-процессе атомарная цена операции становится дешевле.
Спикер 2:
03:10:44 — Следующая история интересная. Это история про большие языковые модели. Я люблю говорить про то, что large language model a large, что является очевидным. И мы должны эти большие модели распиливать на несколько кусков, если мы хотим ускорить скорость отклика этой модели. Представьте, что у нас есть такая огромная модель, и у нас есть один GPU.
03:11:10 — И мы можем взять и распилить эту модель на четыре или на восемь и сказать, обсчитывай под множество нейронов этой сети, используя всю мощность этого компьютера. Понятное дело, что если мы в четыре раза или в восемь раз больше вычислительных мощностей используем, то скорость отклика у нас будет в восемь раз быстрее. Не линейная зависимость, но будет ускорение скорости отклика.
03:11:38 — Цена вычислений, понятное дело, будет расти пропорционально числу вычислительных ресурсов, на которых мы развернули эту модель. И дальше, в зависимости от вашего бизнес API, помните, которые три ключевых API мы обсуждали, качество мы не меняем, то есть это та же самая умная модель, и мы дальше говорим, мы хотим приоритизировать больше скорость отклика или стоимость. И если у нас скорость все-таки супер важна, то мы как бы распиливаем ее на большое число GPUs, и оно одновременно работает в параллеле.
03:12:11 — Если мы говорим нет, мы хотим максимально дешево решать эту задачу, мы используем минимальное число GPU на одну реплику этой модели, и чуть-чуть процесс медленнее, но понятное дело, что он будет более дешевым. Соответственно, мы помогаем для разных кейсов выбирать разную балансировку этих параметров. И последний бенчмарк, который называется Inference Max Benchmark, здесь как раз-таки это показывается.
03:12:39 — То есть у нас по одной оси получается общее число токенов, которые мы генерируем, или операции в единицу времени, а здесь скорость отклика на одну операцию на одного пользователя. И здесь видно, что если максимальная производительность, максимальная стоимость, когда у нас один GPU используется, максимальная скорость отклика, когда у нас восемь GPU, они вот так располагаются у нас на спектре.
03:13:07 — Мы не можем выбрать обе перемены и их максимизировать. И каждое следующее поколение чипов двигается от точки 0,0 до какой-то недостижимой точки,
Спикер ?:
03:13:20 — Которая максимизирует по всем направлениям.
Спикер 2:
03:13:24 — И вот этот фронт, то, что называется Pareto-фронт, с каждым поколением он отодвигается, становится больше и больше и больше. Ну и задача на hardware и на software уровне максимально оптимизировать скорость вычислений. Дальше вся эта история сложная по распиливанию моделей, по аппаратной акселерации, по использованию всех возможностей каждого поколения чипов.
03:13:54 — Мы в NVIDIA упаковываем контейнеры, которые называются NIMI. Это третья фабрика, за которую я отвечаю. И что здесь примечательно, что мы фокусируемся как компания на открытой технологии, то есть open-source, на открытые модели, и мы пытаемся помочь энтерпрайзам максимально легко потреблять эти технологии в упакованном формате.
03:14:18 — И вот здесь, в контексте всех историй геополитического характера, это на самом деле максимально близкая модель к тому, что можно на территории России делать, потому что open-source технологии доступны всем, их можно аналогичным образом их переубаковывать в контейнеры и потом распределять между энтерпрайзами для того, чтобы это было максимально удобно и просто в внедрении.
03:14:52 — То есть один раз мы инвестируем в то, чтобы оптимизировать весь software stack, проверить то, что модель не потеряла в качестве, проверить, что она максимально правильно распилена на определенное число GPU, а после этого уже, значит, каждая компания, которая вынедряет искусственный интеллект, закупая, лицензируя такие контейнеры у вендора, может значительно быстрее это в своем периметре организации развернуть.
03:15:23 — Соответственно… Вопрос, да.
Спикер 4:
03:15:26 — Контейнер и программно-правный комплекс в нашей советской технологии это одно и то же, или контейнеры что-то отличаются?
Спикер 2:
03:15:35 — Контейнер — это определенный термин, который связан с упаковкой софтвера. В 2014 году Docker эту историю популяризировал, Идея в том, что это новые механизмы виртуализации софтвера. Раньше были как контейнеры.
Спикер 4:
03:16:04 — Я думал, что это публика.
Спикер 9:
03:16:07 — Еще вопрос можно? Контейнеры как есть. Я правильно понимаю, что эта технология NIM позволяет взять некую большую модель, как-то оптимальным образом ее, в зависимости от того, что мы оптимизируем, побить на кусочки и разместить на том количестве видеокарт, которые будут оптимальны для выполнения некой бизнес-задачи. Или нет?
Спикер 2:
03:16:33 — Все верно, да. То есть, грубо говоря, простой способ такой. Если мы хотим развернуть в периметре своей организации максимально эффективно и правильно какую-то открытую модель, то ним это простой способ это сделать за пять минут. Прямо честно, за пять минут. Давайте двигаться дальше.
03:17:02 — Это просто пример. Задача у меня не показать какие-то маркетинговые материалы, а показать скорость улучшения технологий за какой-то период времени. То есть если мы посмотрим четвертый квартал 24-го года, год назад, и сейчас, то есть это в два и один раз выросло за год, И это поверх того, что уже мы с вами обсудили с точки зрения смены поколений чипов и библиотек аппаратного ускорения на каком-то системном уровне.
03:17:35 — То есть поверх этого еще мы добавили 2.1.X ускорения на уровне только NIMA. За счет правильных механизмов распиливания нейросетей, оптимизации определенных параметров. Дальше, соответственно, мы это делаем, хорошие новости, не только для лингвистических моделей, мы это делаем для биологии, мы это делаем для картинах, мы это делаем для поиска и большого числа других задач.
03:18:03 — То есть под каждой из этих задач существует своя большая модель, и мы также упаковываем их в контейнеры, которые удобно развертываются в периметре организации. Соответственно, дальше. Мы запустили модель успешно в периметре организации. По-прежнему наша архитектура не изменилась. Мы используем Prompt Engineering, мы используем модельку для того, чтобы создать прототип нашего решения.
Спикер ?:
03:18:32 — Что дальше? Мы быстро упрёмся в стену, когда мы начнём менять наш Prompt.
Спикер 2:
03:18:38 — То есть один пришёл сотрудник, говорит, так, давайте добавим какие-то вот такие комментарии в Prompt. Другой пришел, третий пришел, и очень сложно понять, какие изменения сохранить в этом промте, какие изменения приводят к регрессии качества модели, на каких кейсах это проявляется. Нам нужен какой-то качественный механизм, объективный механизм оценки качества модели. Я уже упоминал, нам нужно зафиксировать оценку качества моделей в бенчмарке.
03:19:12 — Соответственно, методология — это как происходит оценка современных моделей, и приблизительно выглядит из вот таких двух колонок. Первая — это бенчмарки академические или кастомные датасеты, то есть это мы выбираем данные, на которых мы будем оцениваться. И три подхода к оценке на этих данных. Автоматическая оценка с помощью каких-то таких традиционных метрик, грубо говоря, есть ответы от машины, есть ответы экономические, И мы сравнили, насколько они друг на друга похожи.
03:19:45 — Если они похожи, то мы сказали, что ответы системы удовлетворительного качества. Другой подход. Мы показываем ответы экспертам. Эксперты на это смотрят и говорят, да, хороший ответ, плюс один. Второй ответ неправильный, минус один. И в итоге мы делаем человеческую оценку.
03:20:07 — И подход посередине, который объединяет плюсы и автоматического подхода, и человеческого подхода — это использовать AI для того, чтобы оценивать другой AI. То есть это называется Lullaby for Church. Представьте, что мы разрабатываем искусственный интеллект по написанию хороших summary. У нас есть эксперты, которые прочитали 50 или 100 summary и подставили оценки в summary, которые сгенерированы были машиной.
03:20:38 — Потом мы, значит, summary и оценки. На этом мы создали другую модель искусственного интеллекта, которая лучше фокусируется именно на задачу оценки. То есть она знает, как хорошо, по каким критериям посмотреть на summary, сказать, это хороший summary или плохое. Грубо говоря, мы в промот вот этой второй модели оценщику скажем summary должно быть коротким, но должно учитывать все ключевые факты большого текста.
03:21:07 — Summary должно быть грамматически там связанным, не упуская важные факты, использовать то-то-то-то-то-то. В итоге мы создадим оценщика, модель оценщика, и используя ее будем уже разрабатывать качественную большую модель с суммаризацией, у которой первая задача будет пройти тесты по модели оценщика. То есть, получается, у нас один яй помогает разрабатывать другой. И дальше, если это совсем в космические корабли увести, так происходят инновации в целом в сфере foundation моделей.
03:21:36 — То есть, у нас есть текущая версия модели. Мы говорим, хорошо, ты умная, но ты не настолько умная, чтобы решать новый класс задач. Мы тебя будем использовать только как оценщика. И таких моделей оценщиков много по разным нишевым навыкам, которые эта foundation модель обладает. И мы создаем новую модель, которая теперь должна убедить всех оценщиков, что она все это знает, но она одна, вместо каждой из них, которая не жива. Мы ее такой научили, потом на следующем витке мы ее используем как оценщика, а как бы создаем еще более умную модель, то есть такой получается цикл, когда постепенно мы увеличиваем уровень абстракции и когнитивных способностей модели.
03:22:15 — Возвращаясь к практическим историям, у нас есть данные, у нас есть подходы к оценке, и мы на этих данных оцениваем наш ER. Научились, приблизительно так это выглядит, у нас есть различные кандидаты нашей модели или разные промпты, у нас есть набор бенчмарков, мы рисуем диаграммы, которые показывают, какой продукт, где лучше работать.
03:22:40 — И выбираем ту модель, в которой по большему числу критериев оно лучше, чем альтернатива. Дальше, значит, продолжаем двигаться по нашей траектории. До этого, как вы помните, у нас была только история с языковой моделью. Но проблема в языковых моделях какая? В том, что они знают про мир только до того этапа, когда закончили обучение.
03:23:07 — То есть мы скачали интернет 2022 года, и языковая модель будет знать все про мир до 2022 года. Нам нужно создать новую модель 2023−2024, постепенно дообучать ее с новыми событиями. Но, помимо этого, еще в вашей организации есть данные, которые принадлежат только вашей компании, которая эта модель никогда не видела. И если мы их никак этой модели не покажем, то и ответы у вас тоже будут неактуальными и устаревшими.
03:23:34 — Поэтому мы должны научиться подмешивать ваши данные корпоративные в момент ответа. Это называется Retrieval Augmented Generation. Что это в простых терминах?
Спикер 7:
03:23:46 — Мы немножко разбирались, так что это можно совсем просто. Разбирались просто в следующие дни.
Спикер 2:
03:23:55 — То есть мы просто в момент вопроса к этому AI мы в контекст фронта подставляем еще ваши корпоративные данные. И в итоге ответ уже становится обогащенным данными из Enterprise. Существует много различных подходов извлечь эти данные из ваших хранилищ данных. Может использоваться классический SQL-запрос, может быть просто обращение к файлу, может быть какой-то Elasticsearch, keyword search и так далее.
03:24:24 — Если мы более продвинутую версию этой штуки рассматриваем, то мы начинаем использовать векторные базы данных. Что это такое? У нас есть данные в классическом представлении, т.е. просто текст, который человек умеет прочитать. Потом эти все данные, вместо того, чтобы строить инвертированный индекс на ключевых словах, т.е. грубо говоря, картошка, и там переселяются все документы, в которых слово «картошка». Там «солнце», все документы, в которых «солнце», потом там «солнце, которое созрело», там «картошка, которая созрела под солнцем».
03:24:57 — И оно тебе пересекает все эти документы и выдает ответ. Так работает поисковая система типа Google. А мы им говорим, а теперь давайте использовать технологии ИИ для того, чтобы индексировать саму вот эту коллекцию наших данных. Тогда мы все данные засовываем уже не в классический индекс, а в индекс на основе векторной базы данных. Да, и это работает лучше, точнее, быстрее. Соответственно, мы таким образом строим вот эту архитектуру нашего RAC-решения.
03:25:26 — Дальше что мы делаем? Мы говорим, но если мы будем по всем нашим данным в индексе искать релевантные, это, наверное, слишком дорого. Давайте мы будем одну модель, которую попроще использовать для поиска в индексе, а когда у нас там первые тысячи результатов появились уже из первичного индекса, мы их будем переранжировать еще более умной моделью, которая будет выбирать только это топ-100, и это топ-100 подставлять в контекст нашей языковой модели.
03:25:56 — Тогда у нас получается комбинация имбеддинга, который генерируется первичным обращением к индексу, и модель переранжирования, которая умнее, она работает чуть-чуть дольше, но она более точная. Для того, чтобы у этой языковой модели был более богатый контекст. Соответственно, так выглядит современная архитектура RAGA решения. Двигаемся дальше. Здесь процесс про ускорение, что если эти штуки…
Спикер 9:
03:26:23 — Почему вначале стоит self-hosted, до векторизации? Как это работает?
Спикер 2:
03:26:30 — У нас есть модель, допустим, у нас есть DeepSeq. Мы его засунули в коробку. И вот этот self-hosted DeepSeq теперь у нас крутится в периметре. У DeepSeek есть контекст, память, и она пустая по определению. Теперь есть интерфайс данные, мы используем другой ним для модели, которая занимается индексацией. Она превращает документ в набор векторов, которые мы складываем в векторную базу данных.
03:27:00 — То есть это индексация, а это переранжирование. Вот это вот, просто чтобы понятно было, конвенция, когда я вот такую квантовую штуку показываю, это одна модель, то есть у нас здесь три модели уже используются, они разные, да, и дальше что происходит, мы, значит, это все можем ускорять, поскольку каждый из них это ним, который по-своему свою определенную модель, значит, упаковывает.
03:27:34 — Дальше, значит, мы еще хотим улучшить качество нашего решения. То есть мы уже ее обогатили контекстом, все актуально нашей компании. Следующий момент какой? Мы хотим дообучить эти модели работать лучше с нашими данными. То есть у нас теперь self-hosted и еще и fine-tuned версия этих моделей становится. И существует много подходов к кастомизации моделей.
03:28:09 — Все сейчас уже и каждый раз, когда обращаешься к этой модели, не просто обращаться, а копипастить промпт, вставлять в него какие-то дополнительные вещи, и это, по сути дела, промпт инжиниринг. Начинать надо всегда с этого. Любой человек, даже инженер, это может сделать. И постепенно, опять же, по философии, что мы не делаем сложные задачи ради сложных задач, Постепенно увеличивать сложность нашей системы и подход к fine-tuning модели слева-направо.
03:28:42 — То есть мы начинаем с промпт инженерика, это требует минимальных вычислительных ресурсов, минимального навыка и уже делает нашу модель лучше. Потом мы доходим до промпта, параметра efficient fine-tuning. Когда у нас есть большая нейросеть, мы в этой нейросети заморозили 99% весов, То есть мы ее практически не поменяли. Она все, что знала, она будет знать. И мы говорим, ну теперь вот чуть-чуть, давайте ее под наш бизнес-процесс дообучим.
03:29:11 — И мы меняем 1% весов этой нейросети и потом, соответственно, используем для предсказания. Это параметр efficient fine-tuning. Он требует, соответственно, 1 сотую вычислительных мощностей по сравнению с тем, если мы переобучаем всю нейросеть, потому что мы только один процент этой сети разморозили. Требуются какие-то навыки программирования, но, в принципе, это тоже достаточно уже автоматизировано, и, соответственно, нам нужны уже данные для того, чтобы на них дообучать.
03:29:45 — В случае промтоинженеринга данные не нужны. И потом, когда уже совсем понимаем, что есть экономика масштаба, и дополнительные несколько процентов уменьшения качества нашего решения приведут к большому результату, Мы говорим, ну хорошо, давайте всю нейросеть переобучим на наших данных, для этого требуются профессиональные IA-специалисты, очень большие выселительные мощности и много данных, чтобы это произошло, но это тоже можно делать, и соответственно немногие организации до этого доходят, но когда доходят, то результат получается очень хороший и серьезный.
03:30:19 — Пример того, когда нужно строить языковую модель кастомную. Когда у нас есть большая фаундэйшн-модель, допустим, мы возьмем квен, дипсик, пламу, нематрон, они обучены на определенном множестве языков. Там, грубо говоря, представление русского языка, допустим, 1% из общего набора данных. Какой-нибудь итальянский — 1%, испанский — 1%, английский там 75 процентов.
03:30:50 — Соответственно, оно не всю культуру в себя впитает, не все особенности данных, может быть, у нее какой-то селектив кролик интернета, не полностью весь русский интернет представить, а как бы только какие-то самые сектируемые источники. А мы говорим, мы хотим создать русскоязычную языковую модель, чтобы она классно на русском работала именно, понимала русский язык, понимало русскую морфологию и так далее.
03:31:17 — Мы тогда берем эту модель как базу, собираем весь русский интернет, у Яндекса такие ресурсы есть. Соответственно, потом подмешиваем ее в обучающее множество и полностью всю нейросеть на основе уже существующей архитектуры дообучаем на этот язык с пример того, когда это имеет смысл.
03:31:36 — Или, если мы говорим про индустриальные истории, мы хотим сделать модель, которая супер-классно разбирается в здравоохранении или в страховых делах, или в финансах, то мы собираем очень много данных, которые по этой индустрии, все книжки, учебники, статьи и так далее, и на них обучаем, то есть, например, Bloomberg пару лет назад свою модель финансовую делал, и, в принципе, игроки есть, которые подобные истории делают.
03:32:04 — Как правило, это делается для того, чтобы потом раздавать эту модель через API игрокам в этой нише, чтобы они это не создавали с нуля, да, то есть и как бы общая концепция, мы постепенно увеличиваем уровень абстракции, каждый раз переупаковываем повторяемую компоненту, значит, в какой-то сервис или решение, для того, чтобы игроки более высшего уровня абстракции могли это все использовать очень простым способом. И та самая идея платформы, про которую мы поговорили внутри компании, она ту же самую задачу решает.
03:32:39 — Вместо того, чтобы каждый раз пересобирать это все с нуля на базе открытого хода, мы просто говорим, давайте мы просто в контейнер это все засунем, и теперь следующие команды, которые будут внедрять новую модель, они просто будут употреблять этот контейнер и не разбираться с какими-то более низко уровнями задачи. Двигаемся дальше. Вот этот слайд интересный бизнесу. Про файнтюнинг и его эффективность. Смотрите, что здесь находится.
03:33:11 — У нас есть лама 3.1, 70 миллиардов. Она решает задачу на уровне 96% автоматизации. По какому-то критерию качества, который мы определили в 96%. Египет, а можно вопрос?
Спикер 4:
03:33:25 — Да. Предназначенные модели информационной безопасности выпускаются потом у себя, или вы пользуетесь методами диагностики, которые ты раньше показал?
Спикер 2:
03:33:40 — Конечно, проходят. У нас, когда контейнер выпускается, официальный, то есть ним, у него есть механизм сертификации, который мы определили. И один из ключевых критериев — это число security vulnerabilities и safety. И мы, соответственно, по опционному набору критериев его прогоняем, и там есть статический код-анализ, там есть black-box-тестинг, red-teaming и другие технологии, которые позволяют нам этот контейнер
03:34:09 — обезопасить уже для конечного пользователя.
Спикер 4:
03:34:11 — Спасибо. А каталог NEMO есть у вас в публичном?
Спикер 2:
03:34:16 — Да, можно зайти на сайт build. Nvidia. Com и там все объяснится. Так, давайте вернемся к этому слайду. То есть у нас есть Lama 3.1, 70 миллиардов параметров. Она решает задачи на 96%. Что произошло дальше? Мы заменили 3.1, 70 миллиардов параметров на 8 миллиардов параметров. То есть это приблизительно в 10 раз модель меньше по размеру.
03:34:44 — Качество упало до 14%. При этом мы используем существующий промпт. Соответственно, для вас какая практическая польза? Промпт, который работает для одной LLM, хорошо. Для другой LLM не работает. То есть его надо адаптировать. И что мы сделали дальше? Мы ту же самую ламу 3.1, 8 миллиардов параметров, мы оригинальный промпт, который работал для 70 миллиардов, мы его адаптировали для 8 миллиардов параметров.
03:35:18 — И мы воскресили до 86% наше, значит, качество. 10% мы потеряли, потому что у нас здесь был Prompt для маленькой модели, а здесь для большой. Но все равно качество выросло за счет адаптации Prompt. Дальше мы говорим, хорошо, давайте мы будем делать теперь не просто Prompt Engineering, а мы будем делать fine-tuning, уже чуть-чуть написав кода.
03:35:44 — И мы восстанавливаем за счет fine-tuning до 96% качества. Это уже очень классный результат. То есть у нас что произошло? Модель стала в 10 раз приблизительно меньше, скорость отклика этой модели упала с 260 миллисекунд до 80 миллисекунд, то есть в три раза практически упала, а качество не поменялось.
03:36:11 — То есть мы взяли модель, которая стоит дешевле, работает быстрее и за счет чуть-чуть небольшой инженерии просто улучшили экономику этого юзкейса. Дальше мы еще двигаемся до экстрима. Мы говорим, давайте мы еще заменим модель 8 миллиардов на 3 миллиарда или на 1 миллиард. И тоже сделаем fine-tuning и все остальные механизмы кастомизации.
03:36:35 — Тогда у нас получается до 94%, к сожалению, падает качество кейса. И если это приемлемо в рамках этого кейса, то мы потеряем 2%, но в свою очередь мы ускорим процесс интервенса в 13 раз, то есть у нас опять же эта цифра превращается в 20 миллисекунд, и размер модели у нас в 70 раз уменьшился. То есть представьте, что произошло. Мы всего лишь променяли два процента качества решения на уменьшение модели в 70 раз, то есть это в деньги не в 70 раз бьется приблизительно, но сопоставимо.
03:37:13 — И скорость отклика увеличилась в 13 раз. За счет того, что мы просто умным подходом fine-тюнинга эту модель адаптировали для нашего конкретного кейса.
Спикер 3:
03:37:27 — Скажите, что это было, ну, хотя бы примерно за кейс, на котором проинтюнили? Почему спрашиваю, ведь… Классификация текста. Ну, каких? Потому что, скажем так, чем уже кейс, на котором используем, тем легче сохранить до исходного качества. Если более широкое будет применение, то как на исходное не выйдем, если сопротивление.
Спикер 2:
03:37:47 — Все верно. Абсолютно справедливый комментарий. И, соответственно, я здесь не обещаю, что в каждом use case будет такое поведение, но на качественном уровне он будет вести именно так. И просто колоссальное число виз-кейсов каких-то, что если мы берем из коробки большую фаундэйшн-модель с промптом и потом в качестве альтернативы берем значительно меньшую модель и пайнтюним на своем кейсе, то она будет показывать сопоставимые качества.
03:38:19 — Либо, в обратную сторону аргумент, если мы берем фаундейшн модель, с помощью промта показываем какое-то качество, после этого такую же огромную модель понтенем, то качество еще растет, то есть как бы мы уже здесь выбираем, либо мы хотим удешевить стоимость, либо мы хотим, не изменяя размера модели, повысить качество, да, и понтенем в любом случае он улучшает один из параметров.
03:38:50 — Так, двигаемся дальше. Если у нас как бы есть необходимость сделать fine-tune, нам нужны данные. Если данных мало, то нужны синтетические данные. Я про это коротко упоминал и рассказывал, как мы это решали с помощью фотоалистичного рейтрейсинга для картинок. Технология синтетических данных также существует для текстов. Представьте, что нам на вход приходит 100 каких-то там фронтов и ответов от эксперта, который является оператором бизнес-процесса.
03:39:21 — Потом мы его прогоняем через синтетический генератор данных, и на выходе получаем значительно больший объем, который по всем статистическим свойствам сопостоим с тем, что было оригинально, плюс искусственный интеллект добавляет туда какие-то интересные нюансы, которые очень правдоподобно могут встретиться в реальных данных, но в оригинальных данных их не было. И мы уже потом на вот этом расширенном дата-сети обучаем искусственный интеллект и качество лучше.
03:39:48 — У нас это ценность синтетических данных. Соответственно, вот сейчас интересный кейс стали.
Спикер 1:
03:40:13 — В специфические индивидуалы или группы. Эти э-майлы обеспечивают личную или профессиональную информацию, найденную в интернете, и тендуют быть экстремально доверяющими и, поэтому, успешными. Вместе с тем, что атакующие уже используют генеративную АИ, мы еще не полностью обеспечили ее для защиты. Детектор, основанный на АИ, в теории, может легко определить такие персонализированные атаки. Но для того, чтобы эффективно тренировать такой модель, вам понадобится сотни тысяч тысячи уникальных тренировочных эмейлов.
03:40:44 — Это место, где комбинация инфидио-морфея и генеративного АИ создает игровое изменение в работе. Мы использовали генеративное АИ, чтобы производить более 1 миллиона реалистичных, симулированных эмейлами, которые включают аутентичные выглядящие файлы и соединения.
Спикер ?:
03:41:05 — Эти синтетически генерированные эмейлы потом использовались, чтобы тренировать.
Спикер 1:
03:41:08 — Ай-базовый детектор, построенный на инфидио-морфее, чтобы защищаться от софистичных реального мира атак на флаги. Модель Morpheus и Generative AI продолжает изучать и улучшать способность пользователей дать фидбэк на флаговые э-майлы, постоянно улучшая фалско-позитивный уровень, чем больше его используется.
03:41:31 — Используя Generative AI, мы смогли улучшить удостоверение э-майлов на флагах от 70% до 90%, A result that required less than 24 hours of training.
Спикер 2:
03:41:43 — Соответственно, в чем здесь фишка? Что у нас много разных имейлов под злоумышленников прилетают, всю их креативность мы в исходных данных зафиксировать не можем. И мы использовали синтетические данные для того, чтобы сгенерировать огромное число различных вариаций. До обучили искусственный интеллект, с учетом этих синтетических данных, качество системы выросло 70% до 90% и потребовалось всего лишь 24 часа на до обучение этой модельки.
03:42:17 — Соответственно, это тезис, почему синтетические данные дополнительно помогают в решении задач и решают задачу холодного старта, когда данных вообще нет. Дальше, значит, двигаемся. Мы это пропустим. Сразу поговорим про то, что такое reasoning модели и почему они важны. И как это связано с агентским поведением.
03:42:42 — То есть в классической истории, когда мы создаем какую-то AI-систему, у нас есть команда инженеров, которая говорит, сначала сделай вызов к этой модели, потом к этой, потом к этой, потом объедини их все результаты и сделать финальный ответ пользователю. В случае с reasoning моделями или агентскими моделями у нас появляется возможность, когда мы говорим у нас есть вместо этого инженера AI, и эта модель сама решает, каким другим моделям из библиотеки она может обратиться для того, чтобы решить эту задачу.
03:43:20 — И вот эта модель, ей как бы агентские модели, reasoning модели, ей на вход подается задача и еще перечень ресурсов или других моделей, с которыми она может взаимодействовать. То есть ей говорят, у тебя есть в распоряжении подчиненный, который умеет healthcare, у тебя есть подчиненный, который умеет обращаться в базу данных с пользователями,
03:43:43 — У тебя есть подчиненный, который умеет делать поиск по интернету, и, как хочешь, ими пользуйся, надо решить задачу, ответить клиенту на какой-то вопрос. Соответственно, это вот что современные агентские системы делают, и что здесь интересного происходит? Чем умнее модель, которая управляет процессом решения задачи, то есть является главным агентом и оператором процесса, тем она более эффективно будет задачу решать.
03:44:17 — То есть у нас получается умность или способность вот этой ключевой модели декомпозировать сложную задачу на подзадачу. Способность обращаться к каким-то другим моделям, как для решения подзадач. Объединение ответов от большого числа подзадач в единый ответ.
03:44:39 — Это все навыки, которыми должна вот эта метамодель обладать. И на слайде я показываю то, как в логарифмической шкале, то есть это просто экспоненциально разные уровни интеллекта, мы постепенно двигались. Буквально за три года мы увеличили на 70 пунктов интеллект открытых моделей.
03:45:08 — То есть здесь есть закрытые модели, также OpenAI, игрок, которые доступны по API. Но если посмотреть на DeepSeek, если посмотреть на Meto, то они приблизительно находятся на сопоставимом уровне с тем, где сейчас находится фронтир модели. Да, и в целом мы можем на базе открытых технологий строить абсолютно конкурентоспособные решения для и даже сложных агентских процессов.
03:45:37 — Второй, как бы, интересный слайд. Давайте это пропустим. Второй интересный слайд — это слайд про то, как меняется стоимость вычислений с течением времени. Этот непосредственно сказывается на вашей юнит-экономике. То есть если мы посмотрим GPT-4, цена за один миллион токенов была 32 доллара, получается, в марте 23-го года.
03:46:04 — И в течение времени, за два года, чуть меньше, чем два года, она упала до отсечки 125 центов за миллион токенов.
Спикер ?:
03:46:20 — .
Спикер 2:
03:46:20 — Есть, модель эволюционирует, это не та же самая GPT-4 модель. GPT-4 на тот момент и новая модель, которая сейчас стоит значительно меньше денег, но сопоставимая по когнитивным навыкам, как та модель, она может быть меньше по размеру, она может быть более эффективно обучена, она может быть построена на каких-то более быстрых механизмах предсказаний. Но тот факт, что для бизнеса конечный результат, что мы покупаем интеллект за значительно меньшие деньги, это ключевая составляющая.
03:46:55 — И дальше у нас, как бы то, что мы с Николаем обсуждали перед выступлением, у нас две интересные экспоненты есть. Первый экспонент по интеллекту, то есть у нас intelligence растет просто в космос, и каждый виток релиз модели он добавляет какие-то новые когнитивные навыки, мета-ризнинга и других вещей. А вторая экспонента — это стоимость. Intelligence тоже по экспоненте падает.
03:47:23 — Это то, что современный тренд задает и почему AI находится в такой фазе гиперроста. Мы продолжаем, как я уже показал, оптимизировать стек на уровне hardware, на уровне software, и все это позволяет нам сделать технологию более доступной и более эффективной для решения различных процессов и задач.
03:47:52 — И давайте последний пункт. Значит, я замкну комментариями по поводу того, как мы все это замыкаем опять на процессе ядерной информации внутри компании и на EI-платформах. То есть наша конечная задача — это максимизировать эффективность и стоимость принимаемых решений, удешевить их стоимость на уровне компании.
03:48:20 — И у нас в компании могут быть человечки принимать эти решения, у нас может быть искусственный интеллект принимать эти решения. И в конечном счете современные организации будут построены на базе гибридных сущностей, когда и человечки, и искусственный интеллект будут сосуществовать для решения задач. Соответственно, какая ключевая компетенция внутри компании существует?
03:48:48 — Это создание AI. Это сам по себе процесс, также как процесс продаж, процесс маркетинга, процесс производства. В каждой компании должен появиться или уже существует бизнес-процесс создания искусственного интеллекта. И AI-платформа, или AI-фабрика — это то, что позволяет этот процесс индустриализировать и удешевить.
03:49:11 — Как он выглядит? То есть мы собираем данные, мы их чистим, мы потом обучаем модель, мы делаем оценку, мы упаковываем ее, все вот эти истории, которые я рассказал, связанные с разрезанием на большое число процессов, и в конечном счете мы ее выкладываем в промышленную эксплуатацию. Соответственно, этот процесс, так же как и любой процесс, он расписывается по процесс-маппинг-фреймворку, который мы обсудили с вами. В нем обнаруживаются какие-то боттлнеки, и мы фокусируемся на конкретный какой-то элемент неэффективности, расшиваем этот боттлнек за счет разработки определенной компоненты яйц платформы.
03:49:51 — И таким образом мы оптимизируем процесс создания самого яйца. Презумирую, что это уже у нас существует, у нас классная платформа существует. Что следующее? Мы через этот процесс начинаем прогонять очень большое число проектов. То есть у нас есть AI для маркетинга, AI для сейлз, все другие бизнес-процессы.
03:50:13 — Начинаем накладывать на этот бизнес-процесс создание AI для других бизнес-процессов. И поскольку у нас максимально эффективный процесс этих экспериментов быстрый, То есть мы можем большое число таких экспериментов провести, то есть у нас появляется фабрика, то, что мы называем AI Factory, по созданию AI. И ключевые показатели такие же, как и в любой фабрике, это цикл, то есть длина цикла, насколько много времени требуется у нас слева-направо пройти все состояния,
03:50:45 — число проектов на единицу времени, которые наша фабрика AI может поддерживать, и качество или успех отдельного проекта, который мы через эту фабрику выпускаем и доводим до конца. Примерно такая же история, как и на уровне одного AI-проекта мы оптимизируем эти показатели, так и на уровне всей компании, только теперь мы делаем это на мета-уровне, оптимизируя каждый отдельный процесс, а не какой-то там шаг.
03:51:13 — И дальше что происходит? Для этого нужна платформа, которая служит плечом, за счет которого мы эти все процессы можем делать значительно быстрее и эффективнее, и обладает там нужным набором компонентов на разных уровнях abstraction. Какие-то из них я пропустил, какие-то из них я рассказал, но ключевая вещь — существует такая платформа, через которую все проекты прогоняются и доводятся до production. И дальше организация выглядит у вас приблизительно следующим образом.
03:51:43 — У вас есть бизнес-функция, бизнес-девелопмент, сейлс. Есть функция маркетинга, есть функция операторов, кастомных саппорт. И они там все друг с другом взаимодействуют по текущему набору контрактов и межфункционально взаимодействуют. Потом мы, представьте, внедряем искусственный интеллект в каждую из этих функций. И давайте представим, как было до и как будет после.
03:52:11 — Как было до. Sales отправляет запрос в отдел маркетинга и говорит, нам нужна помощь с какими-то брошюрами для клиента, для того, чтобы встретиться с клиентом и сделать его эффективной презентацией. Отдел маркетинга зашит, у них Новый год, они делают какие-то новые материалы для того, чтобы сделать промо-акцию, и они не отвечают на этот запрос Sales в течение месяца.
03:52:34 — Потом они, значит, отдел маркетинга дошли руки до этого запроса, они через месяц отвечают, говорят, слушайте, но мы не можем вам эту брошюру выпустить, нам нужно обратиться к Customer Support и узнать, как вообще обслуживание этого клиента было, и на основе уже этой информации слепить классный кейс станет. Хорошо. Они отправляют запрос в Customer Support, ждут месяц, Customer Support занят, у них активно там все поддержки, клиенты звонят, все жалуются, нужно оказывать поддержку, помогать. Через месяц доходят руки, они этому отделу маркетинга дают ответ.
03:53:07 — В итоге сейлс-команда enabled прошло 2−3 месяца, пока вот это взаимодействие произошло. Теперь, если мы внедряем в этот бизнес-процесс искусственный интеллект на каждом из узлов, то у нас скорость отклика в одном бизнес-процессе падает с 30 дней до 2 минут. Поскольку у нас теоретически падает множество задач, особенно если мы говорим про агентские, может быть полностью автоматизирована.
03:53:33 — То есть теперь у нас только так, то, что называется задача, является compute-bound, а не human-bound. Нам нужно просто добавить дополнительные вычислительные ресурсы, которые легко масштабируются, апеллируя ко всем качественным эффектам от внедрения AI. И мы можем просто вот эту скорость отклика сделать очень быстрой. И таким образом мы как бы раскачиваем маховик внутри всей компании, чтобы чтобы все процессы вместе работали быстрее.
03:53:59 — И помните, я говорил о том, что в каждой цепочке существует bottleneck. Соответственно, bottleneck будет команда, которая не внедрила IE. Другие команды становятся максимально эффективными. Число таких цепочек может быть очень много в вашей организации. Можем начать от Human Resources, потом до Information Technology, потом Operations.
03:54:24 — Каждый из таких цепочек будет существовать своеобразный bottleneck. Каждый из цепочек bottleneck будет разным. Мы будем это находить и на уровне ценности создания, как бы ценности всей компании будем эти штуки оптимизировать. Но вот эта вот задача управленцев будущего, она заключается именно в этом.
03:54:43 — Понять, как расшить узлы внутри конкретного бизнес-процесса, а потом как расшить узлы взаимодействия бизнес-процессов между собой, находя вот эти bottlenecks и строят какие-то уже сквозные мета-агентские системы, которые действительно оптимизируют процессы на уровне всей бизнес-модели. И последняя вещь, я вам расскажу про еще одно видео.
03:55:36 — Какие есть у людей гипотезы, что это такое?
Спикер 4:
03:55:43 — Обучение стабилизации.
Спикер 2:
03:55:48 — Да, все верно.
Спикер ?:
03:56:04 — Тоже, да.
Спикер 2:
03:56:06 — Давайте я расскажу, поскольку у нас ограниченное время. Что здесь сделано, почему это круто. Мы собаку, эту не трогали, робо-собаку, мы ее вообще не трогали. Мы сделали модель этой собаки в виртуальной среде, то есть робо-собаку цифрового двойника. Мы создали все возможные законы Ньютона, Шрёдингера и другая вещь, которая описывает современное понимание физических процессов в виртуальной среде, то есть полностью physically grounded simulation.
03:56:42 — И мы собаку миллионы раз заставили на этом шаре стоять. Потом, так же, как в фильме «Матрица», когда Нел говорит «Я хочу выучить кунг-фу», и он скачивает программу, и он через 9 часов тренировок в этом виртуальном джиме научается навык кунг-фу.
03:57:01 — Собака также, мы настоящие теперь физические собаки, робособаки в реальном мире, скачали эту программу и сказали, собака, иди теперь вставай на настоящий мяч и ходи на этом мяче в реальном мире. И не потратили ни одного цикла обучения в реальном мире. И собака научилась это делать. И дальше, представьте, какое разнообразие различных юзкейсов, породы робототехники можно таким образом совершить.
03:57:31 — То есть мы полностью в виртуальной среде тренируем робота делать какую-то задачу, и после этого выпускаем его в реальный мир, и он начинает там эту задачу выполнять, либо дальше еще адаптироваться, когда мы начинаем скрещивать агентские системы и робототехнику вместе. Вот это то, куда будущее двигается на следующем веке технологии.
03:57:56 — Вот, я здесь оставлю слайд с контактами, пожалуйста, сосканируйте, а также заполните форму, вот, и какие-то, если финальные вопросы есть.
Спикер 7:
03:58:14 — Вопросы, да, Александр, потом Михаил.
Спикер ?:
03:58:18 — Вопрос такой, смотрите, есть конкурирующая технология, которая, понятно, конкурирует с следующим подходом, она не очень сейчас развита, это про децентрализованное обучение LLM и вообще сеточек.
Спикер 9:
03:58:32 — Телеграм вот недавно кокон выпустила, еще есть такие open-source-ные фреймворки. Про них что-то знаете, как-то можете прокомментировать?
Спикер 2:
03:58:41 — У нас тоже есть такой фреймворк, называется NVIDIA Flare. Это интересная технология, у нее свои сложности существуют. Почему? Потому что когда мы треним какую-то большую сеть, то важна синхронизация всех элементов вычислительной платформы и минимизация latency между всеми узлами этой вычислительной сети.
03:59:09 — Когда мы начинаем говорить про хитрогения сплит, то есть какие попаловые вычислительные ресурсы используются, плюс они взаимодействуют через сетевые протоколы с большим latency. Допустим, 40 миллисекунд, если мы с одной части Америки на вторую будем перегонять данные, а данные там очень большого объема. То есть это не какие-то там сообщения уровня обычного сообщения. Соответственно, поэтому дата-центры построены на основе хомогения сплит с очень быстрыми интерконнектами.
03:59:41 — И вот этот network stack, который у нашей компании есть, он именно для этих целей помогает максимизировать пропускную способность для обучения. Если мы говорим про какие-то кейсы, где размер модели меньше, и время взаимодействия не критично, то есть у нас ресурсы все равно простаивают, абсолютно бесполезные, как мебель.
04:00:10 — Тогда почему нет? И есть как бы вот эти платформы, там Гидр, там еще нескольких платформ, 20 лет назад еще их запускали, они похожие штуки решают. И мы про это тоже думаем, но для текущих задач, и чтобы вот этот вот как бы фронтир в технологии двигать, ну это только история про дата-центр.
04:00:32 — Когда мы говорим про inference, например, а не про обучение, это уже может быть более разумно, потому что там не нужно делать взаимодействие между большим числом GPU, ты начинаешь просто это распределенные использовать как, ну, inference, и тогда задача возникает другая. Как правильно с сохранением всех политик безопасности, запросов клиента, зараутить на нужный вычислительный узел, получить от него ответ и обратно показать это клиенту.
04:01:05 — Но эта задача на порядке проще, чем обучение. Обучение, скорее всего, никогда в такую штуку не превратится, а инференс для каких-то оффлайн задач, почему нет?
Спикер ?:
04:01:19 — А есть ли у вас какие-то технические решения, чтобы инференс разворачивать?
Спикер 2:
04:01:25 — Ну вот я бы говорил, что мы похожие штуки исследуем. Я думаю, что пока это такая достаточно историческая история, но в то же самое время, я думаю, что это в крипто-мире, Есть лет проектов, которые подобную штуку запускали, то есть у меня один из близких знакомых рендер токен запустил, то есть это история про децентрализованный рендеринг.
04:01:55 — Ну, а почему не делать децентрализованный яй? То же самое концепция, только чуть-чуть другой тип вычисления. И вот то, что команда Telegram сделали, это похожая вещь.
Спикер 8:
04:02:10 — Слышно меня? Включите, пожалуйста, сайт, вот твой слайд, который 65, где про процессы вы говорили. Вопрос, собственно, решается же, есть не процессы, а есть количество задач, которые нужно решить. И может ли, по вашему мнению, сократиться само количество процессов? Вам же нужно решать задачи фактически.
Спикер 4:
04:02:40 — Понятно, что я имею ввиду? Ну, да, я сейчас думаю, просто.
Спикер 7:
04:02:49 — Мне пока кажется,
Спикер 8:
04:02:52 — Что они же в рамках процессов возникают. У нас процессы образуются для того, чтобы управлять где-то. То есть мы дадим компанию с учетом управляемости 5−7 человек и так далее, но фактически есть задачи. И происходит передача от одного процесса к другому. Хотя, по факту, он уже результат. Для чего тогда некоторые процессы?
Спикер 2:
04:03:21 — Ну, да, я, в общем, здесь, и это очень интересный вопрос, на самом деле, это важный вопрос. Когда мы начинаем вот эту историю с агентами делать, приблизительно это будет выглядеть, на самом деле, как история с организацией из людей. То есть у нас будет этот мета-агент, который умеет управлять своими подчиненными и давать им правильные подзадачи.
04:03:48 — Они будут делать и объединять их результаты вместе. Но на самом деле никто не сказал, что это будет один такой мета-агент, CEO-агент, который будет за всю компанию отвечать. В конечном счете да, будет и такой CEO, но на каждом узле принятия решений должно использовать максимально умного, но не умнее агента. Почему? Потому что стоимость такого агента будет дешевле, чем суперумного каждому узле держать.
04:04:14 — Правильно? То есть мы не хотим, условно говоря, взять какой-нибудь GPT-5 и сказать, ты решаешь задачу на самом базовом уровне, и на всех уровнях выше ты тоже принимаешь решение. Мы говорим, а почему бы нам GPT-5 на GPT-4, условно говоря, не заменить на предпоследних узлах. Вот задачи будут решаться еще более глупыми моделями. Объединение их результатов будет делать GPT-4, и они будут репортить модели GPT-5 в конечном счете.
04:04:43 — Да, будет преобразование этих процессов, но упаковка будет дальше не связана с когнитивной способностью человека 3, 5, 7 переменных в голове держать, А она будет связана с тем, насколько эффективно на этом узле и по стоимости какая модель нужна. И как она потом может интерфейсить с человеком делать. Что я слышу, например, по собственному опыту, современные программисты как работают?
04:05:13 — Они работают так же, как шахматисты-красмейстеры, но если это хорошие программисты. Они дают задачи AI, они говорят, пиши код здесь, пиши код здесь, пиши код здесь, И у них есть когнитивный объем контекста, который человек может держать. Но если он умнее и опытнее, он больше таких EIs может обслуживать. И в итоге программист современный дает задачу EI, проверяет результаты работы EI, и все вместе это сводит.
04:05:44 — И вот как мы построили… Нам надо теперь строить две иерархии. Одну иерархию EI, вторую иерархию человечков, и как они друг с другом взаимодействуют, с каким соотношением между яйцами.
Спикер 7:
04:05:55 — Тут концепт такой, по мере роста иерархии яиц должна уменьшаться иерархия человеческой. Обратная пропорция, то есть мы растили иерархию человеческую, что в процессе все больше задач, чем больше задач передается человеческой, должна уменьшаться, по идее, иерархия человеческая. Так, коллеги, финальный, давайте.
Спикер 3:
04:06:20 — Спасибо, вопрос. Классно сейчас стали говорить про программистов, которые управляют своими подчиненными, но если смотреть на эту картинку, то все из этих людей, кто на нее расположены, должны превратиться в таких программистов, которые управляют своими подчиненными. И как будто бы. И вот вопрос, что как будто бы сегодня, Например, среда CodeCode или GitHub Compiler, это прообраз будущей цифровой компании.
04:06:47 — Но только там интерфейс, наверное, станет чуть получше. Но, по сути, мы, как руководители, превратимся в тех, кто будет, в том числе, иметь вот такой интерфейс, чтобы ставить задачи, проверять, что они сделали. И, в общем, там, где процессы будут крутиться с нашими документами, со всем. То есть там уже и так все документы, у программиста его документы, кодовая база, в реальности артефактов больше, равно те же самые документы. И вот хочется спросить, что вы думаете в этом отношении, как вы смотрите на то, куда будет развиваться, и вот если вы видите планы, сюда заходите, там становиться конкурентами.
04:07:19 — Ну потому что если сюда придет, то как бы тот, кто придумает среду, в которой новая операционная система для цифровых компаний, тот как бы будет в топе. Потому что он соберет весь трафик, как бы организация бизнеса будет как бы, если сейчас клауд найти, потом модели мы хостим, а потом мы будем хостить вот это. То есть тот, кто сможет это процессить у себя, тот как бы станет королем будущего бизнеса.
04:07:39 — Вот есть ли планы в этом виде идти в эту сторону? Я не знаю, секретные секреты поделиться или просто ваше личное мнение.
Спикер 2:
04:07:46 — Я думаю, что это правильная мысль. Рано или поздно, скорее всего, раньше, чем мы ожидаем, каждая профессия будет иметь интерфейс подобного рода. Они будут отличаться, потому что в каких-то случаях в визуалке, то, что мы разрабатывали для обработки картинок, там чуть-чуть другой механизм построения интерфейса был.
04:08:15 — Но у всех будет так или иначе чат с AI, какое-то визуальное представление твоего Canvas, где-то у тебя будут картинки, где-то у тебя будет ход, где-то у тебя будут какие-то здания нарисованы или кубики, и у тебя будет набор документов, с которыми ты взаимодействуешь. То есть это все неизбежно. С точки зрения того, будете делать это в виде или нет, даже если бы я знал, я бы не сказал, потому что это, в принципе, очень стратегически важная информация.
04:08:53 — Вторая вещь. У нас стратегия очень другая, по крайней мере, из того, что я могу рассказывать. Мы пытаемся помогать экосистеме решать задачи снизу, от инфраструктуры. Мы помогаем повышать уровень абстракции в каких-то повторяющихся кейсах.
04:09:14 — Мы меньше смотрим на сторону приложений и сверху абстракции, конкретный юзкейс. Наверное, лучше компаний существует, которые понимают этот рынок, чем мы. Какой-нибудь ServiceNow, SAP, Salesforce и так далее. Сейчас я могу немного перечислять. Они решают конкретную задачу их клиентов, как управленцы бизнес-процесса, лучше, чем NVIDIA.
04:09:42 — Давайте мы будем свою решать задачу и дадим возможность решать задачи другие, тем, кто эти задачи умеет решать. И дальше получается, у нас какая история. Мы собираем full stack, полностью вот эти все слои, которые я здесь показываю, мы референс архитектуры собираем сами, чтобы делать то, что называется extreme co-optimization, чтобы на всех уровнях максимальная вертикальность stack была, и мы все это понимали на своих проектах.
04:10:11 — Потом мы этот весь стек разделяем на куски, и мы можем, как NVIDIA, как Vendor, взаимодействовать с экосистемой на всех уровнях абстракции. Хотите купить только сервера? Пожалуйста. Хотите купить сервера плюс инфраструктурный уровень? Пожалуйста. Хотите купить микросервис? Покупайте. Хотите купить только 2 из 5? Покупайте только 2 из 5. И у нас полная открытая сквозная архитектура компании, и мы таким образом с большим числом игроков на всех уровнях абстракции можем взаимодействовать.
04:10:44 — В этом сила экосистемной модели.
Спикер 7:
04:10:50 — Благодарим докладчика, спасибо большое. Никита, спасибо большое, что ты смог присоединиться, сколько времени прошло, и мы снова восстановили наше взаимодействие, пока. Все, пока! Хорошего дня, спасибо!


Распознано с использованием https://speech2text.ru